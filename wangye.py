import streamlit as st
import pandas as pd
import os
import logging
import re
import streamlit.components.v1 as components
from difflib import SequenceMatcher
from concurrent.futures import ThreadPoolExecutor, as_completed
import openpyxl
from openpyxl.styles import PatternFill, Alignment
from openpyxl.styles import numbers
import base64
import sys
from io import BytesIO
import requests
import tempfile
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from PIL import Image
import io

# ============================
# åˆå§‹åŒ–è®¾ç½®
# ============================
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("å¯åŠ¨æ•°æ®å¤„ç†å·¥å…·ã€‚")


# ============================
# å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°
# ============================

# ======== è·¯å¾„å…¼å®¹å‡½æ•° =========
def resource_path(relative_path):
    """å…¼å®¹ PyCharm å¼€å‘ç¯å¢ƒ å’Œ PyInstaller æ‰“åŒ…åçš„è·¯å¾„"""
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)


# ======== åŠ è½½å­¦æ ¡æ•°æ® =========
try:
    school_data_path = resource_path("school_data.xlsx")
    school_df = pd.read_excel(school_data_path)
    VALID_SCHOOL_NAMES = set(school_df['å­¦æ ¡åç§°'].dropna().str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_SCHOOL_NAMES)} ä¸ªæœ‰æ•ˆå­¦æ ¡åç§°")
except Exception as e:
    logging.error(f"è¯»å– school_data.xlsx å‡ºé”™ï¼š{e}")
    VALID_SCHOOL_NAMES = set()
    st.warning("å­¦æ ¡æ•°æ®åŠ è½½å¤±è´¥ï¼Œå­¦æ ¡åç§°æ£€æŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨")

# ======== åŠ è½½æ‹›ç”Ÿä¸“ä¸šæ•°æ® =========
try:
    major_data_path = resource_path("æ‹›ç”Ÿä¸“ä¸š.xlsx")
    major_df = pd.read_excel(major_data_path)
    VALID_MAJOR_COMBOS = set(major_df['æ‹›ç”Ÿä¸“ä¸š'].dropna().astype(str).str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_MAJOR_COMBOS)} ä¸ªæœ‰æ•ˆä¸“ä¸šç»„åˆ")
except Exception as e:
    logging.error(f"è¯»å– æ‹›ç”Ÿä¸“ä¸š.xlsx å‡ºé”™ï¼š{e}")
    VALID_MAJOR_COMBOS = set()
    st.warning("ä¸“ä¸šæ•°æ®åŠ è½½å¤±è´¥ï¼Œä¸“ä¸šåŒ¹é…åŠŸèƒ½å°†ä¸å¯ç”¨")


def check_school_name(name):
    if pd.isna(name) or not str(name).strip():
        return 'å­¦æ ¡åç§°ä¸ºç©º'
    return 'åŒ¹é…' if name.strip() in VALID_SCHOOL_NAMES else 'ä¸åŒ¹é…'


def check_major_combo(major, level):
    if pd.isna(major) or pd.isna(level):
        return "æ•°æ®ç¼ºå¤±"
    combo = f"{str(major).strip()}{str(level).strip()}"
    return "åŒ¹é…" if combo in VALID_MAJOR_COMBOS else "ä¸åŒ¹é…"


def convert_selection_requirement_from_requirement(req):
    """
    ä¾æ®ä¸Šä¼ æ–‡ä»¶ä¸­çš„æŠ¥è€ƒè¦æ±‚è½¬æ¢ä¸ºé€‰ç§‘è¦æ±‚è¯´æ˜ä¸æ¬¡é€‰ç§‘ç›®ï¼ˆä¸ docx è§„èŒƒä¸€è‡´ï¼‰ã€‚
    1. æŠ¥è€ƒè¦æ±‚ï¼šä¸é™ â†’ é€‰ç§‘è¦æ±‚è¯´æ˜ï¼šä¸é™ç§‘ç›®ä¸“ä¸šç»„ï¼Œæ¬¡é€‰ç§‘ç›®ï¼šç©ºç™½
    2. æŠ¥è€ƒè¦æ±‚ä»…ä¸ºå•ä¸ªå­—ï¼ˆå¦‚"åŒ–""æ”¿"ï¼‰â†’ é€‰ç§‘è¦æ±‚è¯´æ˜ï¼šå•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒï¼Œæ¬¡é€‰ç§‘ç›®=æŠ¥è€ƒè¦æ±‚
    3. æŠ¥è€ƒè¦æ±‚ä¸­åŒ…å«"ä¸”"ï¼ˆå¦‚"ç‰©ä¸”åŒ–"ã€"ç‰©ä¸”åŒ–ä¸”ç”Ÿ"ï¼‰â†’ é€‰ç§‘è¦æ±‚è¯´æ˜ï¼šå•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒï¼Œæ¬¡é€‰ç§‘ç›®ä¸ºå»æ‰"ä¸”"
    4. æŠ¥è€ƒè¦æ±‚ä¸­åŒ…å«"æˆ–"ï¼ˆå¦‚"ç‰©æˆ–åŒ–"ã€"ç‰©æˆ–åŒ–æˆ–ç”Ÿ"ï¼‰â†’ é€‰ç§‘è¦æ±‚è¯´æ˜ï¼šå¤šé—¨é€‰è€ƒï¼Œæ¬¡é€‰ç§‘ç›®ä¸ºå»æ‰"æˆ–"
    """
    if pd.isna(req) or not str(req).strip():
        return "ä¸é™ç§‘ç›®ä¸“ä¸šç»„", ""
    s = str(req).strip()
    if "ä¸é™" in s:
        return "ä¸é™ç§‘ç›®ä¸“ä¸šç»„", ""
    if len(s) == 1:
        return "å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s
    if "ä¸”" in s:
        return "å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s.replace("ä¸”", "")
    if "æˆ–" in s:
        return "å¤šé—¨é€‰è€ƒ", s.replace("æˆ–", "")
    return "", ""


def _to_text(value):
    """è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼ï¼ˆå­¦ä¸šæ¡¥å·¥å…·ç”¨ï¼‰"""
    if value is None or (value != 0 and not value):
        return ''
    text = str(value).lstrip('^').strip().lstrip("'")
    return text


def _get_first_subject(category):
    """æ ¹æ®ç§‘ç±»å–é¦–é€‰ç§‘ç›®ï¼ˆå­¦ä¸šæ¡¥å·¥å…·ç”¨ï¼‰"""
    if not category:
        return ''
    c = str(category)
    if 'ç‰©ç†ç±»' in c or 'ç‰©ç†' in c:
        return 'ç‰©'
    if 'å†å²ç±»' in c or 'å†å²' in c:
        return 'å†'
    return ''


def _normalize_kele(kele):
    """è½¬æ¢æ‹›ç”Ÿç§‘ç±»ï¼šç‰©ç†â†’ç‰©ç†ç±»ï¼Œå†å²â†’å†å²ç±»ï¼Œå…¶ä»–ç§‘ç±»ç›´æ¥è¿”å›ã€‚"""
    if kele is None or (isinstance(kele, str) and not kele.strip()):
        return ''
    k = str(kele).strip()
    if k == 'ç‰©ç†':
        return 'ç‰©ç†ç±»'
    if k == 'å†å²':
        return 'å†å²ç±»'
    return k


# ä¸“ä¸šç»„ä»£ç æŒ‰çœä»½è½¬æ¢ï¼šæ— ä¸“ä¸šç»„ / æ‹›ç”Ÿä»£ç +ä¸“ä¸šç»„ç¼–å· / æ‹›ç”Ÿä»£ç =ä¸“ä¸šç»„ä»£ç  / æ‹›ç”Ÿä»£ç +ï¼ˆä¸“ä¸šç»„ç¼–å·ï¼‰
PROVINCE_NO_GROUP = {'æ²³åŒ—', 'è¾½å®', 'å±±ä¸œ', 'æµ™æ±Ÿ', 'é‡åº†', 'è´µå·', 'é’æµ·', 'æ–°ç–†', 'è¥¿è—'}
PROVINCE_CODE_PLUS_GROUP = {'å‰æ—'}   # æ‹›ç”Ÿä»£ç +ä¸“ä¸šç»„ç¼–å·ï¼Œå¦‚ 320401ã€0200001
PROVINCE_CODE_EQUALS_GROUP = {'æ¹–åŒ—', 'æ±Ÿè‹', 'ä¸Šæµ·', 'æµ·å—', 'å¤©æ´¥'}  # æ‹›ç”Ÿä»£ç =ä¸“ä¸šç»„ä»£ç ï¼Œå¦‚ 320401


def _convert_group_code_by_province(province, zhaosheng_code, group_no):
    """
    æŒ‰çœä»½è½¬æ¢ä¸“ä¸šç»„ä»£ç ã€‚
    1. æ²³åŒ—ã€è¾½å®ã€å±±ä¸œã€æµ™æ±Ÿã€é‡åº†ã€è´µå·ã€é’æµ·ã€æ–°ç–†ã€è¥¿è—ï¼šæ— ä¸“ä¸šç»„ä»£ç ï¼Œæ— éœ€è½¬æ¢ï¼Œè¿”å›ç©º
    2. æµ·å—ã€å‰æ—ï¼šæ‹›ç”Ÿä»£ç +ä¸“ä¸šç»„ç¼–å·ï¼ˆå¦‚ 320401ã€0200001ï¼‰
    3. æ¹–åŒ—ã€æ±Ÿè‹ã€ä¸Šæµ·ã€å¤©æ´¥ï¼šæ‹›ç”Ÿä»£ç =ä¸“ä¸šç»„ä»£ç ï¼ˆå¦‚ 320401ï¼‰
    4. å…¶ä½™çœä»½ï¼šæ‹›ç”Ÿä»£ç +ï¼ˆä¸“ä¸šç»„ç¼–å·ï¼‰ï¼ˆå¦‚ 3204ï¼ˆ01ï¼‰ã€0200ï¼ˆ001ï¼‰ï¼‰
    """
    p = (province or '').strip()
    code = _to_text(zhaosheng_code or '')
    group = _to_text(group_no or '')
    if p in PROVINCE_NO_GROUP:
        return ''
    if p in PROVINCE_CODE_PLUS_GROUP:
        return (code or '') + (group or '')
    if p in PROVINCE_CODE_EQUALS_GROUP:
        return code or ''
    # å…¶ä½™çœä»½ï¼šæ‹›ç”Ÿä»£ç +ï¼ˆä¸“ä¸šç»„ç¼–å·ï¼‰
    if not group:
        return code or ''
    return (code or '') + 'ï¼ˆ' + group + 'ï¼‰'


# å­¦ä¸šæ¡¥ä¸Šä¼ æ–‡ä»¶ä»ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜è¡Œï¼‰å¼€å§‹æ ¡éªŒï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µ
XUEYEQIAO_UPLOAD_COLUMNS = [
    'æ•°æ®ç±»å‹', 'å¹´ä»½', 'çœä»½', 'æ‰¹æ¬¡', 'ç§‘ç±»', 'é™¢æ ¡åç§°', 'é™¢æ ¡åŸå§‹åç§°', 'æ‹›ç”Ÿä»£ç ', 'ä¸“ä¸šç»„ç¼–å·',
    'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿç±»å‹', 'ä¸“ä¸šåç§°', 'æŠ¥è€ƒè¦æ±‚', 'ä¸“ä¸šå¤‡æ³¨', 'æ‹›ç”Ÿè®¡åˆ’äººæ•°', 'æœ€ä½åˆ†', 'æœ€ä½ä½æ¬¡',
    'æœ€é«˜åˆ†', 'å¹³å‡åˆ†', 'å½•å–äººæ•°'
]

# å­¦ä¸šæ¡¥å¯¼å‡ºæ–‡ä»¶ç¬¬3è¡Œæ ‡é¢˜åˆ—ï¼ˆä¸ä¸Šä¼ å­—æ®µæ˜ å°„åçš„å¯¼å‡ºæ ¼å¼ï¼‰
XUEYEQIAO_EXPORT_HEADERS = [
    'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡',
    'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æ•°æ®æ¥æº',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ',
    'æœ€ä½åˆ†æ•°åŒºé—´ä½', 'æœ€ä½åˆ†æ•°åŒºé—´é«˜', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰',
    'ä¿®æ”¹åå¤‡æ³¨', 'å¤‡æ³¨ä¿®æ”¹è¯´æ˜'
]

# å­¦ä¸šæ¡¥å¯¼å‡ºæ–‡ä»¶ç¬¬1è¡Œåˆå¹¶å•å…ƒæ ¼å¤‡æ³¨å†…å®¹ï¼ˆA1-U1ï¼Œè¡Œé«˜220ç£…ï¼‰
XUEYEQIAO_EXPORT_NOTE = (
    'å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›\n'
    '1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰\n'
    '2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"\n'
    '3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰\n'
    'æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›\n'
    'é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›\n'
    'å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›\n'
    'æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ\n'
    '4.æ‹›ç”Ÿäººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—\n'
    '5.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼Œä¿ç•™å°æ•°åä¸¤ä½ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°\n'
    '6.ä¸€çº§å±‚æ¬¡ï¼šé™å®š"æœ¬ç§‘ã€ä¸“ç§‘ï¼ˆé«˜èŒï¼‰"ï¼Œè¯¥éƒ¨åˆ†ä¸ºæ‹›ç”Ÿä¸“ä¸šå¯¹åº”çš„ä¸“ä¸šå±‚æ¬¡\n'
    '7.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—;\n'
    '8.æ•°æ®æ¥æºï¼šå¿…é¡»é™å®šâ€”â€”å®˜æ–¹è€ƒè¯•é™¢ã€å¤§çº¢æœ¬æ•°æ®ã€å­¦æ ¡å®˜ç½‘ã€é”€å”®ã€æŠ“å–ã€åœ£è¾¾ä¿¡ã€ä¼˜å¿—æ„¿ã€å­¦ä¸šæ¡¥\n'
    '9.é€‰ç§‘è¦æ±‚ï¼šä¸é™ç§‘ç›®ä¸“ä¸šç»„;å¤šé—¨é€‰è€ƒ;å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ\n'
    '10.é€‰ç§‘ç§‘ç›®å¿…é¡»æ˜¯ç§‘ç›®çš„ç®€å†™ï¼ˆç‰©ã€åŒ–ã€ç”Ÿã€å†ã€åœ°ã€æ”¿ã€æŠ€ï¼‰\n'
    '11.2020åŒ—äº¬ã€æµ·å—ï¼Œ17-19ä¸Šæµ·ä»…é™åˆ¶æœ¬ç§‘ä¸“ä¸šç»„ä»£ç å¿…å¡«\n'
    '12.æ–°å…«çœé¦–é€‰ç§‘ç›®å¿…é¡»é€‰æ‹©ï¼ˆç‰©ç†æˆ–å†å²ï¼‰\n'
    '13.åˆ†æ•°åŒºé—´ä»…é™åŒ—äº¬'
)


def map_upload_row_to_export(row):
    """
    å°†ä¸Šä¼ æ–‡ä»¶çš„ä¸€è¡Œæ˜ å°„ä¸ºå¯¼å‡ºæ–‡ä»¶æ ¼å¼ã€‚
    å­—æ®µæ˜ å°„ï¼šå­¦æ ¡åç§°â†é™¢æ ¡åç§°ï¼Œæ‹›ç”Ÿä¸“ä¸šâ†ä¸“ä¸šåç§°ï¼Œæ‹›ç”Ÿç§‘ç±»â†ç§‘ç±»ï¼Œä¸“ä¸šç»„ä»£ç â†ä¸“ä¸šç»„ç¼–å·ç­‰ï¼›
    é¦–é€‰ç§‘ç›®ç”±ç§‘ç±»ç» _get_first_subject å¾—åˆ°ï¼›é€‰ç§‘è¦æ±‚ã€æ¬¡é€‰ç§‘ç›®ç”±æŠ¥è€ƒè¦æ±‚ç» convert_selection_requirement_from_requirement è½¬æ¢ã€‚
    """
    new_row = {}
    new_row['å­¦æ ¡åç§°'] = row.get('é™¢æ ¡åç§°', '') or ''
    new_row['çœä»½'] = row.get('çœä»½', '') or ''
    new_row['æ‹›ç”Ÿä¸“ä¸š'] = row.get('ä¸“ä¸šåç§°', '') or ''
    new_row['ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰'] = row.get('ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', '') or ''
    new_row['ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰'] = row.get('ä¸“ä¸šå¤‡æ³¨', '') or ''
    new_row['ä¸€çº§å±‚æ¬¡'] = row.get('ä¸€çº§å±‚æ¬¡', '') or ''
    # æ‹›ç”Ÿç§‘ç±»ï¼šç‰©ç†â†’ç‰©ç†ç±»ï¼Œå†å²â†’å†å²ç±»ï¼Œå…¶ä»–ç›´æ¥è½¬æ¢
    kele_raw = row.get('ç§‘ç±»', '') or ''
    new_row['æ‹›ç”Ÿç§‘ç±»'] = _normalize_kele(kele_raw)
    new_row['æ‹›ç”Ÿæ‰¹æ¬¡'] = row.get('æ‰¹æ¬¡', '') or ''
    new_row['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = row.get('æ‹›ç”Ÿç±»å‹', '') or ''
    new_row['æœ€é«˜åˆ†'] = row.get('æœ€é«˜åˆ†', '') or ''
    new_row['æœ€ä½åˆ†'] = row.get('æœ€ä½åˆ†', '') or ''
    new_row['å¹³å‡åˆ†'] = row.get('å¹³å‡åˆ†', '') or ''
    new_row['æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰'] = row.get('æœ€ä½ä½æ¬¡', '') or ''
    new_row['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = row.get('æ‹›ç”Ÿè®¡åˆ’äººæ•°', '') or ''
    new_row['æ•°æ®æ¥æº'] = row.get('æ•°æ®æ¥æº', '') or ''
    # ä¸“ä¸šç»„ä»£ç æŒ‰çœä»½è½¬æ¢
    province = row.get('çœä»½', '') or ''
    zhaosheng_code = row.get('æ‹›ç”Ÿä»£ç ', '') or ''
    group_no = row.get('ä¸“ä¸šç»„ç¼–å·', '') or row.get('ä¸“ä¸šç»„ä»£ç ', '')
    new_row['ä¸“ä¸šç»„ä»£ç '] = _convert_group_code_by_province(province, zhaosheng_code, group_no)
    cat = row.get('ç§‘ç±»', '') or ''
    new_row['é¦–é€‰ç§‘ç›®'] = _get_first_subject(cat)
    req = row.get('æŠ¥è€ƒè¦æ±‚', '') or ''
    sel_desc, second = convert_selection_requirement_from_requirement(req)
    new_row['é€‰ç§‘è¦æ±‚'] = sel_desc
    new_row['æ¬¡é€‰ç§‘ç›®'] = second
    new_row['ä¸“ä¸šä»£ç '] = _to_text(row.get('ä¸“ä¸šä»£ç ', ''))
    new_row['æ‹›ç”Ÿä»£ç '] = _to_text(row.get('æ‹›ç”Ÿä»£ç ', ''))
    new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½'] = row.get('æœ€ä½åˆ†æ•°åŒºé—´ä½', '') or ''
    new_row['æœ€ä½åˆ†æ•°åŒºé—´é«˜'] = row.get('æœ€ä½åˆ†æ•°åŒºé—´é«˜', '') or ''
    new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½'] = row.get('æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', '') or ''
    new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜'] = row.get('æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', '') or ''
    new_row['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = row.get('å½•å–äººæ•°', '') or ''
    # ä¿®æ”¹åå¤‡æ³¨å’Œå¤‡æ³¨ä¿®æ”¹è¯´æ˜æ”¾åœ¨æœ€åä¸¤åˆ—
    new_row['ä¿®æ”¹åå¤‡æ³¨'] = row.get('ä¿®æ”¹åå¤‡æ³¨', '') or ''
    new_row['å¤‡æ³¨ä¿®æ”¹è¯´æ˜'] = row.get('å¤‡æ³¨æ£€æŸ¥ç»“æœ', '') or ''
    return new_row


CUSTOM_WHITELIST = {
    "å®ç¦æ ¡åŒº", "æ²™æ²³æ ¡åŒº", "ä¸­å¤–åˆä½œåŠå­¦", "ç æµ·æ ¡åŒº", "æ±ŸåŒ—æ ¡åŒº", "æ´¥å—æ ¡åŒº", "å¼€å°æ ¡åŒº",
    "è”åˆåŠå­¦", "æ ¡ä¼åˆä½œ", "åˆä½œåŠå­¦", "å¨æµ·æ ¡åŒº", "æ·±åœ³æ ¡åŒº", "è‹å·æ ¡åŒº", "å¹³æœæ ¡åŒº",
    "æ±Ÿå—æ ¡åŒº", "åˆå·æ ¡åŒº", "é•¿å®‰æ ¡åŒº", "å´‡å®‰æ ¡åŒº", "å—æ ¡åŒº", "ä¸œæ ¡åŒº", "éƒ½å¸‚å›­è‰º", "ç”˜è‚ƒå…°å·"
}

TYPO_DICT = {
    "æ•™åŠ©": "æ•‘åŠ©",
    "æŒ‡è¾‰": "æŒ‡æŒ¥",
    "æ–™å­¦": "ç§‘å­¦",
    "è¯è¨€": "è¯­è¨€",
    "5å3": "5+3",
    "5å3ä¸€ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "â€œ5å3â€ä¸€ä½“åŒ–": "â€œ5+3â€ä¸€ä½“åŒ–",
    "5+31ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "5+3ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "è‰²è¨€": "è‰²ç›²",
    "NIT": "NIIT",
    "è‰²è‚²": "è‰²ç›²",
    "äººå›´": "å…¥å›´",
    "é¡¹æœˆ": "é¡¹ç›®",
    "å¸èŒƒç±»": "å¸ˆèŒƒç±»",
    "æŠ•è¯¾": "æˆè¯¾",
    "å°±è–„": "å°±è¯»",
    "ç”µè¯·": "ç”³è¯·",
    "ä¸­å›½é¢": "ä¸­å›½ç”»",
    "ç«æ•°æ°‘æ—": "å°‘æ•°æ°‘æ—",
    "è‰²è‡ª": "è‰²ç›²",
    "è‰²ç›²è‰²å¼±ç”³æŠ¥": "è‰²ç›²è‰²å¼±æ…æŠ¥",
    "æ•°å­¦ä¸åº”ç”¨æ•°ç¬‘": "æ•°å­¦ä¸åº”ç”¨æ•°å­¦",
    "æ³•å­¦å": "æ³•å­¦+",
    "æµ£æµ·æ ¡åŒº": "æ»¨æµ·æ ¡åŒº",
    "ä¸­æº´": "ä¸­æ¾³"
}

REGEX_PATTERNS = {
    'excess_punct': re.compile(r'[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+'),
    'outer_punct': re.compile(r'^[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+|[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+$'),
    'consecutive_right': re.compile(r'ï¼‰{2,}')
}
NESTED_PAREN_PATTERN = re.compile(r'ï¼ˆï¼ˆ(.*?)ï¼‰ï¼‰')
CONSECUTIVE_REPEAT_PATTERN = re.compile(r'ï¼ˆ(.+?)ï¼‰\s*ï¼ˆ\1ï¼‰')


def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()


def normalize_brackets(text):
    """ç»Ÿä¸€å„ç§æ‹¬å·ä¸ºä¸­æ–‡æ‹¬å·å¹¶å¤„ç†ä¸å®Œæ•´æ‹¬å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()

    # æ›¿æ¢æ‰€æœ‰æ‹¬å·å˜ä½“ä¸ºä¸­æ–‡æ‹¬å·
    text = re.sub(r'[{\[ã€]', 'ï¼ˆ', text)  # å·¦æ‹¬å·
    text = re.sub(r'[}\]ã€‘]', 'ï¼‰', text)  # å³æ‹¬å·
    text = re.sub(r'[<ã€Š]', 'ï¼ˆ', text)  # å·¦ä¹¦åå·æ›¿æ¢ä¸ºå·¦æ‹¬å·
    text = re.sub(r'[>ã€‹]', 'ï¼‰', text)  # å³ä¹¦åå·æ›¿æ¢ä¸ºå³æ‹¬å·

    return text


def clean_outer_punctuation(text):
    """æ¸…ç†æœ€å¤–å±‚æ‹¬å·å¤–çš„æ ‡ç‚¹ç¬¦å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()
    text = REGEX_PATTERNS['outer_punct'].sub('', text)
    parts = re.split(r'(ï¼ˆ.*?ï¼‰)', text)
    cleaned_parts = []
    for part in parts:
        if part.startswith('ï¼ˆ') and part.endswith('ï¼‰'):
            cleaned_parts.append(part)
        else:
            cleaned_parts.append(REGEX_PATTERNS['outer_punct'].sub('', part))
    return ''.join(cleaned_parts)


def check_score_consistency(row):
    """æ£€æŸ¥åˆ†æ•°ä¸€è‡´æ€§ï¼šæœ€é«˜åˆ† >= å¹³å‡åˆ† >= æœ€ä½åˆ†"""
    issues = []
    try:
        max_score = float(row['æœ€é«˜åˆ†']) if pd.notna(row['æœ€é«˜åˆ†']) else None
        avg_score = float(row['å¹³å‡åˆ†']) if pd.notna(row['å¹³å‡åˆ†']) else None
        min_score = float(row['æœ€ä½åˆ†']) if pd.notna(row['æœ€ä½åˆ†']) else None

        if max_score is not None and avg_score is not None and max_score < avg_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < å¹³å‡åˆ†({avg_score})")

        if max_score is not None and min_score is not None and max_score < min_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < æœ€ä½åˆ†({min_score})")

        if avg_score is not None and min_score is not None and avg_score < min_score:
            issues.append(f"å¹³å‡åˆ†({avg_score}) < æœ€ä½åˆ†({min_score})")

    except (ValueError, TypeError) as e:
        issues.append(f"åˆ†æ•°æ ¼å¼é”™è¯¯: {str(e)}")

    return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜'


def analyze_and_fix(text):
    if pd.isna(text) or not str(text).strip():
        return text, []

    text = normalize_brackets(text)
    text = clean_outer_punctuation(text)
    issues = []

    if text in CUSTOM_WHITELIST:
        return text, []

    # ========== æ‹¬å·æˆå¯¹ä¿®æ­£ ==========
    text_list = list(text)
    stack = []
    unmatched_right = []

    for i, char in enumerate(text_list):
        if char == 'ï¼ˆ':
            stack.append(i)
        elif char == 'ï¼‰':
            if stack:
                stack.pop()
            else:
                unmatched_right.append(i)

    for i in reversed(unmatched_right):
        del text_list[i]
        issues.append("åˆ é™¤å¤šä½™å³æ‹¬å·1ä¸ª")

    if stack:
        text_list.extend(['ï¼‰'] * len(stack))
        issues.append(f"è¡¥å……ç¼ºå¤±å³æ‹¬å·{len(stack)}ä¸ª")

    text = ''.join(text_list)

    # åµŒå¥—ä¿®æ­£
    text, nested_count = NESTED_PAREN_PATTERN.subn(r'ï¼ˆ\1ï¼‰', text)
    if nested_count > 0:
        issues.append(f"ä¿®å¤åµŒå¥—æ‹¬å·{nested_count}å¤„")

    # ========== æ¸…ç†ç©ºæ‹¬å·æˆ–çº¯æ ‡ç‚¹æ‹¬å· ==========
    def clean_empty_paren(m):
        content = m.group(1).strip('ï¼Œã€,;ï¼›:ï¼šã€‚ï¼ï¼Ÿ.!? ')
        if not content:
            issues.append("åˆ é™¤ç©ºæ‹¬å·æˆ–ä»…å«æ ‡ç‚¹æ‹¬å·")
            return ''
        return f'ï¼ˆ{content}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', clean_empty_paren, text)

    # ========== å»é‡ ==========
    seen = set()

    def dedup(m):
        c = m.group(1)
        if c in seen:
            issues.append(f"é‡å¤æ‹¬å·å†…å®¹ï¼š'{c}'")
            return ''
        seen.add(c)
        return f'ï¼ˆ{c}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', dedup, text)

    # ========== å¤šä½™æ ‡ç‚¹ç®€åŒ– ==========
    text = REGEX_PATTERNS['excess_punct'].sub(lambda m: m.group(0)[0], text)

    # ========== é”™åˆ«å­—ä¿®æ­£ ==========
    for typo, corr in TYPO_DICT.items():
        if typo in text:
            text = text.replace(typo, corr)
            issues.append(f"é”™åˆ«å­—ï¼š'{typo}'â†’'{corr}'")

    return text, issues


def process_chunk(chunk):
    """
    å¤„ç†æ•°æ®å—ã€‚æ”¯æŒä¸Šä¼ æ–‡ä»¶åˆ—åä¸å¯¼å‡ºåˆ—åå¹¶å­˜ï¼š
    å­¦æ ¡åç§°/é™¢æ ¡åç§°ã€æ‹›ç”Ÿä¸“ä¸š/ä¸“ä¸šåç§°ã€æ‹›ç”Ÿç§‘ç±»/ç§‘ç±»ã€é€‰ç§‘è¦æ±‚/æŠ¥è€ƒè¦æ±‚ã€‚
    é€‰ç§‘è½¬æ¢é€»è¾‘ä¸ docx ä¸€è‡´ï¼šä¸é™/å•å­—/ä¸”/æˆ– â†’ é€‰ç§‘è¦æ±‚è¯´æ˜ã€æ¬¡é€‰ã€‚
    """
    # å­¦æ ¡åç§°æ£€æŸ¥ï¼ˆæ”¯æŒ å­¦æ ¡åç§° æˆ– é™¢æ ¡åç§°ï¼‰
    school_col = 'å­¦æ ¡åç§°' if 'å­¦æ ¡åç§°' in chunk.columns else ('é™¢æ ¡åç§°' if 'é™¢æ ¡åç§°' in chunk.columns else None)
    if school_col:
        chunk['å­¦æ ¡åŒ¹é…ç»“æœ'] = chunk[school_col].apply(check_school_name)

    # ä¸“ä¸šåŒ¹é…æ£€æŸ¥ï¼ˆæ”¯æŒ æ‹›ç”Ÿä¸“ä¸š æˆ– ä¸“ä¸šåç§°ï¼Œéœ€æœ‰ä¸€çº§å±‚æ¬¡ï¼‰
    major_col = 'æ‹›ç”Ÿä¸“ä¸š' if 'æ‹›ç”Ÿä¸“ä¸š' in chunk.columns else ('ä¸“ä¸šåç§°' if 'ä¸“ä¸šåç§°' in chunk.columns else None)
    if major_col and 'ä¸€çº§å±‚æ¬¡' in chunk.columns:
        chunk['æ‹›ç”Ÿä¸“ä¸šåŒ¹é…ç»“æœ'] = chunk.apply(
            lambda r: check_major_combo(r[major_col], r['ä¸€çº§å±‚æ¬¡']), axis=1)

    # å¤‡æ³¨å¤„ç†ï¼ˆæ”¯æŒ ä¸“ä¸šå¤‡æ³¨ï¼‰
    remark_col = None
    for c in chunk.columns:
        if 'ä¸“ä¸šå¤‡æ³¨' in str(c):
            remark_col = c
            break
    if remark_col is not None:
        def process_remark(remark):
            if pd.isna(remark) or not str(remark).strip():
                return 'æ— é—®é¢˜', ''
            fixed_text, issues = analyze_and_fix(remark)
            return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜', fixed_text

        chunk[['å¤‡æ³¨æ£€æŸ¥ç»“æœ', 'ä¿®æ”¹åå¤‡æ³¨']] = chunk[remark_col].apply(
            lambda x: pd.Series(process_remark(x)))

    # åˆ†æ•°æ£€æŸ¥
    score_columns = ['æœ€é«˜åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†']
    if all(col in chunk.columns for col in score_columns):
        chunk['åˆ†æ•°æ£€æŸ¥ç»“æœ'] = chunk.apply(check_score_consistency, axis=1)

    # é€‰ç§‘è¦æ±‚å¤„ç†ï¼šä¾æ® docxï¼Œæ”¯æŒ é€‰ç§‘è¦æ±‚ æˆ– æŠ¥è€ƒè¦æ±‚ï¼Œç»Ÿä¸€ç”¨ convert_selection_requirement_from_requirement
    req_col = 'é€‰ç§‘è¦æ±‚' if 'é€‰ç§‘è¦æ±‚' in chunk.columns else ('æŠ¥è€ƒè¦æ±‚' if 'æŠ¥è€ƒè¦æ±‚' in chunk.columns else None)
    if req_col:
        chunk[['é€‰ç§‘è¦æ±‚è¯´æ˜', 'æ¬¡é€‰']] = chunk[req_col].apply(
            lambda x: pd.Series(convert_selection_requirement_from_requirement(x)))

    # æ‹›ç”Ÿç§‘ç±»å¤„ç†ï¼ˆæ”¯æŒ æ‹›ç”Ÿç§‘ç±» æˆ– ç§‘ç±»ï¼‰ï¼Œç»Ÿä¸€ä¸ºç‰©ç†ç±»/å†å²ç±»å¹¶ç”Ÿæˆé¦–é€‰ç§‘ç›®
    cat_col = 'æ‹›ç”Ÿç§‘ç±»' if 'æ‹›ç”Ÿç§‘ç±»' in chunk.columns else ('ç§‘ç±»' if 'ç§‘ç±»' in chunk.columns else None)
    if cat_col:
        chunk['æ‹›ç”Ÿç§‘ç±»'] = chunk[cat_col].replace({'ç‰©ç†': 'ç‰©ç†ç±»', 'å†å²': 'å†å²ç±»'})
        chunk['é¦–é€‰ç§‘ç›®'] = chunk['æ‹›ç”Ÿç§‘ç±»'].apply(
            lambda x: _get_first_subject(x) if pd.notna(x) and str(x).strip() else '')
    elif 'é¦–é€‰ç§‘ç›®' not in chunk.columns and req_col:
        chunk['é¦–é€‰ç§‘ç›®'] = ''

    return chunk


# ============================
# é™¢æ ¡åˆ†æå–ç›¸å…³å‡½æ•°ï¼ˆæ™®é€šç±»ï¼‰
# ============================
expected_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡',
    'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æ•°æ®æ¥æº',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
]
columns_to_convert = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'
]


def process_score_file(file_path):
    # é¦–å…ˆè¯»å–å¹´ä»½ï¼ˆä»B2å•å…ƒæ ¼ï¼‰
    try:
        wb = openpyxl.load_workbook(file_path, data_only=True)
        ws = wb.active
        year_value = ws['B2'].value
        if year_value is None:
            # å¦‚æœB2ä¸ºç©ºï¼Œå°è¯•ä»æ•°æ®ä¸­æå–å¹´ä»½
            year_value = ''
        else:
            year_value = str(year_value).strip()
        wb.close()
    except Exception as e:
        year_value = ''

    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€é«˜åˆ†': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰': str,
            'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    missing_columns = [col for col in expected_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æœ€é«˜åˆ†'] = pd.to_numeric(df['æœ€é«˜åˆ†'], errors='coerce')
    df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df = df.dropna(subset=['æœ€ä½åˆ†'])

    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'].fillna('')

    # é¦–é€‰ç§‘ç›®è½¬æ¢é€»è¾‘
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()  # å»é™¤å‰åç©ºæ ¼
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',  # ç¡®ä¿å·²ç»æ˜¯"å†å²"çš„ä¸å˜
            'ç‰©ç†': 'ç‰©ç†'  # ç¡®ä¿å·²ç»æ˜¯"ç‰©ç†"çš„ä¸å˜
        })

    try:
        # åˆ¤æ–­æ˜¯å¦æœ‰ä¸“ä¸šç»„ä»£ç åˆ—ï¼Œä¸”ä¸å…¨ä¸ºç©º
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # æ¯ç»„æœ€é«˜åˆ†
        max_scores = df.groupby(group_fields)['æœ€é«˜åˆ†'].max()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

        # è¡¥å……æœ€é«˜åˆ†
        def get_max_score(row):
            key = tuple(row[col] for col in group_fields)
            return max_scores.get(key, None)

        result['æœ€é«˜åˆ†'] = result.apply(get_max_score, axis=1)

        # æ‹›ç”Ÿäººæ•°ã€å½•å–äººæ•°æŒ‰åˆ†ç»„æ€»å’Œ
        enroll_groups = df.groupby(group_fields)['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()
        code_groups = df.groupby(group_fields)['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()

        def get_group_total(row, column_name):
            key = tuple(row[col] for col in group_fields)
            if column_name == 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return enroll_groups.get(key, '')
            elif column_name == 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return code_groups.get(key, '')
            return ''

        result['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)
        result['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # æ„å»ºæ–°çš„æ•°æ®æ¡†ï¼ŒæŒ‰ç…§æ–°çš„åˆ—é¡ºåº
    new_columns = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§',
        'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡',
        'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨',
        'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç '
    ]

    # åˆ›å»ºæ–°çš„DataFrameï¼Œç¡®ä¿æ‰€æœ‰åˆ—éƒ½æœ‰æ­£ç¡®çš„é•¿åº¦
    num_rows = len(result)
    new_result = pd.DataFrame(index=range(num_rows))

    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†åˆ—å€¼ï¼Œå°†NaNè½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆç”¨äºæ–‡æœ¬åˆ—ï¼‰
    def get_col_values(col_name, default=''):
        if col_name in result.columns:
            values = result[col_name].fillna(default).astype(str).values
            # å°†'nan'å­—ç¬¦ä¸²è½¬æ¢å›ç©ºå­—ç¬¦ä¸²
            values = ['' if str(v).lower() == 'nan' else v for v in values]
            return values
        else:
            return [default] * num_rows

    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æ•°å­—åˆ—å€¼ï¼Œä¿æŒæ•°å­—ç±»å‹
    def get_numeric_values(col_name, default=0):
        if col_name in result.columns:
            values = result[col_name].fillna(default)
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œæ— æ³•è½¬æ¢çš„ä¿æŒåŸå€¼æˆ–è®¾ä¸ºé»˜è®¤å€¼
            try:
                return pd.to_numeric(values, errors='coerce').fillna(default).values
            except:
                return [default] * num_rows
        else:
            return [default] * num_rows

    new_result['å­¦æ ¡åç§°'] = get_col_values('å­¦æ ¡åç§°')
    new_result['çœä»½'] = get_col_values('çœä»½')
    new_result['æ‹›ç”Ÿç±»åˆ«'] = get_col_values('æ‹›ç”Ÿç§‘ç±»')
    new_result['æ‹›ç”Ÿæ‰¹æ¬¡'] = get_col_values('æ‹›ç”Ÿæ‰¹æ¬¡')
    new_result['æ‹›ç”Ÿç±»å‹'] = get_col_values('æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰')
    new_result['é€‰æµ‹ç­‰çº§'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜åˆ†'] = get_col_values('æœ€é«˜åˆ†')
    new_result['æœ€ä½åˆ†'] = get_col_values('æœ€ä½åˆ†')
    new_result['å¹³å‡åˆ†'] = [''] * num_rows  # åˆ é™¤å¹³å‡åˆ†æå–é€»è¾‘ï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€ä½ä½æ¬¡'] = get_col_values('æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰')
    new_result['å¹³å‡ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['å½•å–äººæ•°'] = get_numeric_values('å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ‹›ç”Ÿäººæ•°'] = get_numeric_values('æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ•°æ®æ¥æº'] = get_col_values('æ•°æ®æ¥æº')
    new_result['çœæ§çº¿ç§‘ç±»'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿æ‰¹æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿å¤‡æ³¨'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['ä¸“ä¸šç»„ä»£ç '] = get_col_values('ä¸“ä¸šç»„ä»£ç ')
    new_result['é¦–é€‰ç§‘ç›®'] = get_col_values('é¦–é€‰ç§‘ç›®')
    new_result['é™¢æ ¡æ‹›ç”Ÿä»£ç '] = get_col_values('æ‹›ç”Ÿä»£ç ')

    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
        remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    åŒ—äº¬ã€å¤©æ´¥ã€è¾½å®ã€ä¸Šæµ·ã€å±±ä¸œã€å¹¿ä¸œã€æµ·å—é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼ˆæœ€å¤šä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
5.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—
6.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
7.é¦–é€‰ç§‘ç›®ï¼šæ–°å…«çœå¿…å¡«ï¼Œåªèƒ½å¡«å†™ï¼ˆå†å²æˆ–ç‰©ç†ï¼‰"""

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # å…ˆå†™å…¥æ•°æ®ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼Œä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            new_result.to_excel(writer, index=False, header=False, startrow=3)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']

            # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
            worksheet.merge_cells('A1:U1')
            worksheet['A1'] = remark_text
            worksheet['A1'].alignment = Alignment(wrap_text=True, vertical='top')
            # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º215ç£…
            worksheet.row_dimensions[1].height = 215

            # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=å¹´ä»½ï¼ŒC2="1"ï¼ŒD2="æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰"
            worksheet['A2'] = 'æ‹›ç”Ÿå¹´'
            # B2å’ŒC2è®¾ç½®ä¸ºæ•°å­—æ ¼å¼
            try:
                # å°è¯•å°†å¹´ä»½è½¬æ¢ä¸ºæ•°å­—
                if year_value and str(year_value).strip():
                    year_num = int(float(str(year_value).strip()))
                    worksheet['B2'] = year_num
                else:
                    worksheet['B2'] = ''
            except:
                worksheet['B2'] = year_value
            worksheet['C2'] = 1  # ç›´æ¥è®¾ç½®ä¸ºæ•°å­—1
            worksheet['D2'] = 'æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰'

            # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
            headers = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§',
                       'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡',
                       'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨',
                       'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ']
            for col_idx, header in enumerate(headers, start=1):
                worksheet.cell(row=3, column=col_idx, value=header)

            # è®¾ç½®æ–‡æœ¬æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼Œå³æ•°æ®è¡Œï¼‰
            # éœ€è¦è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼çš„åˆ—ï¼ˆä½¿ç”¨æ–°åˆ—åï¼Œä¸åŒ…æ‹¬æ‹›ç”Ÿäººæ•°å’Œå½•å–äººæ•°ï¼‰
            text_format_cols = ['ä¸“ä¸šç»„ä»£ç ', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½ä½æ¬¡']
            for col in text_format_cols:
                if col in new_result.columns:
                    col_idx = new_result.columns.get_loc(col) + 1
                    for row in range(4, len(new_result) + 4):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT

            # ç¡®ä¿B2å’ŒC2å•å…ƒæ ¼ä¿æŒæ•°å­—æ ¼å¼
            if worksheet['B2'].value is not None and str(worksheet['B2'].value).strip():
                try:
                    worksheet['B2'].value = int(float(str(worksheet['B2'].value)))
                except:
                    pass
            worksheet['C2'].value = 1

            # ç¡®ä¿"å½•å–äººæ•°"å’Œ"æ‹›ç”Ÿäººæ•°"åˆ—ä¿æŒæ•°å­—æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            if 'å½•å–äººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('å½•å–äººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass

            if 'æ‹›ç”Ÿäººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('æ‹›ç”Ÿäººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")


# ============================
# ä¿æŒæ–‡æœ¬æ ¼å¼
# ============================
def _find_remark_column(df):
    """åœ¨ DataFrame ä¸­æŸ¥æ‰¾ä¸“ä¸šå¤‡æ³¨ç›¸å…³åˆ—ï¼ˆä¸Šä¼ å¤šä¸ºâ€œä¸“ä¸šå¤‡æ³¨â€ï¼Œæ–°æ–‡ä»¶å¤šä¸ºâ€œä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰â€ï¼‰"""
    for col in df.columns:
        c = str(col).strip() if col is not None else ""
        if not c:
            continue
        if c in ("ä¸“ä¸šå¤‡æ³¨", "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰") or "ä¸“ä¸šå¤‡æ³¨" in c:
            return col
    return None


def process_remarks_file(file_path, progress_callback=None):
    """å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ï¼šä¸Šä¼ æ–‡ä»¶ç¬¬1è¡Œä¸ºæ ‡é¢˜ï¼Œæ ¡éªŒæŒ‡å®šåˆ—ï¼›æ ¡å¯¹å­¦æ ¡/ä¸“ä¸š/å¤‡æ³¨åæŒ‰æ–°æ ¼å¼å¯¼å‡ºã€‚"""
    try:
        # ä¸Šä¼ æ–‡ä»¶ä»ç¬¬ä¸€è¡Œï¼ˆæ ‡é¢˜è¡Œï¼‰å¼€å§‹è¯»å–
        df = pd.read_excel(file_path, header=0, dtype={
            'æ‹›ç”Ÿä»£ç ': str,
            'ä¸“ä¸šç»„ç¼–å·': str,
            'ä¸“ä¸šä»£ç ': str,
        }, engine='openpyxl', keep_default_na=False)
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")
    # æ ¡éªŒå¿…é¡»åŒ…å«çš„åˆ—ï¼ˆå­¦ä¸šæ¡¥ä¸Šä¼ æ ¼å¼ï¼‰
    missing = [c for c in XUEYEQIAO_UPLOAD_COLUMNS if c not in df.columns]
    if missing:
        raise Exception("ä¸Šä¼ æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼ˆåº”ä»ç¬¬1è¡Œæ ‡é¢˜å¼€å§‹ï¼‰ï¼š%sã€‚å½“å‰åˆ—åï¼š%s" % (missing, list(df.columns)))
    for col in ['æ‹›ç”Ÿä»£ç ', 'ä¸“ä¸šç»„ç¼–å·', 'ä¸“ä¸šä»£ç ']:
        if col in df.columns:
            df[col] = df[col].astype(str)
    # ä¸“ä¸šå¤‡æ³¨åˆ—å·²åœ¨ä¸Šä¼ åˆ—ä¸­ï¼Œæ— éœ€å†æŸ¥æ‰¾æˆ–é‡å‘½å
    chunks = []
    for i in range(0, len(df), 1000):
        chunks.append(df.iloc[i:i + 1000].copy())
    results = {}
    total_chunks = len(chunks)
    with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
        future_to_index = {executor.submit(process_chunk, chunk): idx for idx, chunk in enumerate(chunks)}
        for count, future in enumerate(as_completed(future_to_index)):
            idx = future_to_index[future]
            results[idx] = future.result()
            if progress_callback:
                progress_callback(count + 1, total_chunks)
    ordered_results = [results[i] for i in sorted(results.keys())]
    final_result = pd.concat(ordered_results)
    # ä»ä¸Šä¼ æ•°æ®å–æ‹›ç”Ÿå¹´ä»½ï¼ˆå¹´ä»½åˆ—ç¬¬ä¸€ä¸ªéç©ºå€¼ï¼‰
    year_value = ''
    if 'å¹´ä»½' in final_result.columns:
        for v in final_result['å¹´ä»½']:
            if pd.notna(v) and str(v).strip():
                year_value = str(v).strip()
                break
    # å°†æ¯ä¸€è¡Œæ˜ å°„ä¸ºå¯¼å‡ºæ ¼å¼ï¼ˆå« process_chunk äº§ç”Ÿçš„ä¿®æ”¹åå¤‡æ³¨ç­‰ï¼‰
    export_rows = []
    for _, row in final_result.iterrows():
        export_rows.append(map_upload_row_to_export(row.to_dict()))
    export_df = pd.DataFrame(export_rows, columns=XUEYEQIAO_EXPORT_HEADERS)
    # æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…æ•°å­—ä¿ç•™å°æ•°åä¸¤ä½
    def _format_score(x):
        if x is None or (isinstance(x, str) and not x.strip()):
            return ''
        s = str(x).strip()
        if not s or not _is_numeric_str(s):
            return s
        return '%.2f' % float(s)
    for col in ['æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†']:
        if col in export_df.columns:
            export_df[col] = export_df[col].apply(_format_score)
    output_path = file_path.replace('.xlsx', '_æ£€æŸ¥ç»“æœ.xlsx')
    try:
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = 'Sheet1'
        # ç¬¬1è¡Œï¼šA1-U1 åˆå¹¶ï¼Œè¡Œé«˜ 220 ç£…ï¼Œå¤‡æ³¨å†…å®¹
        ws.merge_cells('A1:U1')
        ws['A1'] = XUEYEQIAO_EXPORT_NOTE
        ws['A1'].alignment = Alignment(wrap_text=True, vertical='top', horizontal='left')
        ws.row_dimensions[1].height = 220
        # ç¬¬2è¡Œï¼šA2=æ‹›ç”Ÿå¹´ä»½ï¼ŒB2=å¹´ä»½
        ws['A2'] = 'æ‹›ç”Ÿå¹´ä»½'
        ws['B2'] = year_value
        # ç¬¬3è¡Œï¼šæ ‡é¢˜è¡Œ
        for col_idx, col_name in enumerate(XUEYEQIAO_EXPORT_HEADERS, start=1):
            ws.cell(row=3, column=col_idx, value=col_name)
        # ç¬¬4è¡Œèµ·ï¼šæ•°æ®
        for row_idx, (_, row_data) in enumerate(export_df.iterrows(), start=4):
            for col_idx, col_name in enumerate(XUEYEQIAO_EXPORT_HEADERS, start=1):
                val = row_data.get(col_name)
                if pd.isna(val):
                    val = ''
                ws.cell(row=row_idx, column=col_idx, value=val)
        # ä¸“ä¸šç»„ä»£ç ã€ä¸“ä¸šä»£ç ã€æ‹›ç”Ÿä»£ç ç­‰åˆ—ä¸ºæ–‡æœ¬æ ¼å¼
        text_cols = ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æœ€ä½åˆ†æ•°åŒºé—´ä½', 'æœ€ä½åˆ†æ•°åŒºé—´é«˜', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰']
        for col_name in text_cols:
            if col_name in XUEYEQIAO_EXPORT_HEADERS:
                col_idx = XUEYEQIAO_EXPORT_HEADERS.index(col_name) + 1
                for r in range(4, len(export_df) + 4):
                    cell = ws.cell(row=r, column=col_idx)
                    if cell.value is not None and str(cell.value).strip() != '':
                        cell.number_format = numbers.FORMAT_TEXT
        wb.save(output_path)
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶é”™è¯¯ï¼š{e}")
    return output_path


def _is_numeric_str(s):
    """åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä¸ºæ•°å­—ï¼ˆå«å°æ•°ï¼‰"""
    try:
        float(s)
        return True
    except (ValueError, TypeError):
        return False


# ============================
# é™¢æ ¡åˆ†æ•°æ®å¤„ç†ï¼ˆè‰ºä½“ç±»ï¼‰
# ============================

expected_new_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡',
    'ä¸“ä¸šç±»åˆ«', 'æ˜¯å¦æ ¡è€ƒ', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'æ‹›ç”Ÿä»£ç ', 'æ ¡ç»Ÿè€ƒåˆ†',
    'æ ¡æ–‡åŒ–åˆ†', 'ä¸“ä¸šä»£ç ', 'æ•°æ®æ¥æº'
]
columns_to_convert_new = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ ¡ç»Ÿè€ƒåˆ†', 'æ ¡æ–‡åŒ–åˆ†'
]


def process_new_template_file(file_path):
    # é¦–å…ˆè¯»å–åŸå§‹æ–‡ä»¶çš„B2å•å…ƒæ ¼å†…å®¹
    try:
        wb_original = openpyxl.load_workbook(file_path, data_only=True)
        ws_original = wb_original.active
        b2_value = ws_original['B2'].value
        if b2_value is None:
            b2_value = ''
        else:
            b2_value = str(b2_value).strip()
        wb_original.close()
    except Exception as e:
        b2_value = ''

    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ ¡ç»Ÿè€ƒåˆ†': str,
            'æ ¡æ–‡åŒ–åˆ†': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    # æ£€æŸ¥å¿…éœ€åˆ—
    missing_columns = [col for col in expected_new_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    # æ•°å€¼åˆ—è½¬ä¸ºæ•°å€¼å‹
    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æ ¡ç»Ÿè€ƒåˆ†'] = pd.to_numeric(df['æ ¡ç»Ÿè€ƒåˆ†'], errors='coerce')
    df['æ ¡æ–‡åŒ–åˆ†'] = pd.to_numeric(df['æ ¡æ–‡åŒ–åˆ†'], errors='coerce')

    # åˆ é™¤æœ€ä½åˆ†ä¸ºç©ºçš„è¡Œ
    df = df.dropna(subset=['æœ€ä½åˆ†'])
    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    # é¦–é€‰ç§‘ç›®æ¸…æ´—
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',
            'ç‰©ç†': 'ç‰©ç†'
        })

    try:
        # åˆ¤æ–­åˆ†ç»„å­—æ®µ
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡',
                            'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # å‡†å¤‡æ–°çš„åˆ—åæ˜ å°„
    new_columns = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æŠ•æ¡£åˆ†', 'ä½æ¬¡', 'æ‹›ç”Ÿä»£ç ', 'ä¸“ä¸šç»„', 'å¤‡æ³¨', 'æ˜¯å¦æ ¡è€ƒ']
    
    # åˆ›å»ºæ–°çš„DataFrameï¼Œæ˜ å°„å­—æ®µ
    new_result = pd.DataFrame()
    new_result['å­¦æ ¡åç§°'] = result['å­¦æ ¡åç§°'] if 'å­¦æ ¡åç§°' in result.columns else pd.Series([None] * len(result))
    new_result['çœä»½'] = result['çœä»½'] if 'çœä»½' in result.columns else pd.Series([None] * len(result))
    new_result['æ‹›ç”Ÿç±»åˆ«'] = result['æ‹›ç”Ÿç±»åˆ«'] if 'æ‹›ç”Ÿç±»åˆ«' in result.columns else pd.Series([None] * len(result))
    new_result['æ‹›ç”Ÿæ‰¹æ¬¡'] = result['æ‹›ç”Ÿæ‰¹æ¬¡'] if 'æ‹›ç”Ÿæ‰¹æ¬¡' in result.columns else pd.Series([None] * len(result))
    new_result['ä¸“ä¸šç±»åˆ«'] = result['ä¸“ä¸šç±»åˆ«'] if 'ä¸“ä¸šç±»åˆ«' in result.columns else pd.Series([None] * len(result))
    new_result['æŠ•æ¡£åˆ†'] = result['æœ€ä½åˆ†'] if 'æœ€ä½åˆ†' in result.columns else pd.Series([None] * len(result))
    new_result['ä½æ¬¡'] = result['æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰'] if 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰' in result.columns else pd.Series([None] * len(result))
    new_result['æ‹›ç”Ÿä»£ç '] = result['æ‹›ç”Ÿä»£ç '] if 'æ‹›ç”Ÿä»£ç ' in result.columns else pd.Series([None] * len(result))
    new_result['ä¸“ä¸šç»„'] = result['ä¸“ä¸šç»„ä»£ç '] if 'ä¸“ä¸šç»„ä»£ç ' in result.columns else pd.Series([None] * len(result))
    new_result['å¤‡æ³¨'] = result['ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰'] if 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰' in result.columns else pd.Series([None] * len(result))
    # æ˜¯å¦æ ¡è€ƒï¼šå¦‚æœå­˜åœ¨åˆ™ä½¿ç”¨ï¼Œå¦åˆ™é»˜è®¤ä¸º'å¦'
    if 'æ˜¯å¦æ ¡è€ƒ' in result.columns:
        new_result['æ˜¯å¦æ ¡è€ƒ'] = result['æ˜¯å¦æ ¡è€ƒ'].fillna('å¦')
    else:
        new_result['æ˜¯å¦æ ¡è€ƒ'] = 'å¦'

    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        # åˆ›å»ºæ–°çš„å·¥ä½œç°¿
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = 'Sheet1'

        # ç¬¬ä¸€è¡Œï¼šA1-K1åˆå¹¶å•å…ƒæ ¼ï¼Œè¡Œé«˜90ç£…
        ws.merge_cells('A1:K1')
        cell_a1 = ws['A1']
        cell_a1.value = 'å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›\n1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰\n2.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—\n3.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—\n4.æ˜¯å¦æ ¡è€ƒï¼šæœ‰æ•ˆå€¼ã€æ˜¯ï¼Œå¦ã€‘ï¼Œä¸å¡«å†™æˆ–ä¸åœ¨æœ‰æ•ˆå€¼ä¸­é»˜è®¤\'å¦\''
        cell_a1.alignment = Alignment(wrap_text=True, vertical='top', horizontal='left')
        ws.row_dimensions[1].height = 90

        # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=åŸå§‹æ–‡ä»¶B2çš„å†…å®¹
        ws['A2'] = 'æ‹›ç”Ÿå¹´'
        ws['B2'] = b2_value

        # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
        for col_idx, col_name in enumerate(new_columns, start=1):
            ws.cell(row=3, column=col_idx, value=col_name)

        # ç¬¬å››è¡Œå¼€å§‹ï¼šæ•°æ®è¡Œ
        for row_idx, (_, row_data) in enumerate(new_result.iterrows(), start=4):
            ws.cell(row=row_idx, column=1, value=row_data['å­¦æ ¡åç§°'] if pd.notna(row_data['å­¦æ ¡åç§°']) else None)
            ws.cell(row=row_idx, column=2, value=row_data['çœä»½'] if pd.notna(row_data['çœä»½']) else None)
            ws.cell(row=row_idx, column=3, value=row_data['æ‹›ç”Ÿç±»åˆ«'] if pd.notna(row_data['æ‹›ç”Ÿç±»åˆ«']) else None)
            ws.cell(row=row_idx, column=4, value=row_data['æ‹›ç”Ÿæ‰¹æ¬¡'] if pd.notna(row_data['æ‹›ç”Ÿæ‰¹æ¬¡']) else None)
            ws.cell(row=row_idx, column=5, value=row_data['ä¸“ä¸šç±»åˆ«'] if pd.notna(row_data['ä¸“ä¸šç±»åˆ«']) else None)
            ws.cell(row=row_idx, column=6, value=row_data['æŠ•æ¡£åˆ†'] if pd.notna(row_data['æŠ•æ¡£åˆ†']) else None)
            ws.cell(row=row_idx, column=7, value=row_data['ä½æ¬¡'] if pd.notna(row_data['ä½æ¬¡']) else None)
            ws.cell(row=row_idx, column=8, value=row_data['æ‹›ç”Ÿä»£ç '] if pd.notna(row_data['æ‹›ç”Ÿä»£ç ']) else None)
            ws.cell(row=row_idx, column=9, value=row_data['ä¸“ä¸šç»„'] if pd.notna(row_data['ä¸“ä¸šç»„']) else None)
            ws.cell(row=row_idx, column=10, value=row_data['å¤‡æ³¨'] if pd.notna(row_data['å¤‡æ³¨']) else None)
            ws.cell(row=row_idx, column=11, value=row_data['æ˜¯å¦æ ¡è€ƒ'] if pd.notna(row_data['æ˜¯å¦æ ¡è€ƒ']) else 'å¦')

        # è®¾ç½®æ–‡æœ¬æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼Œå³æ•°æ®è¡Œï¼‰
        # éœ€è¦è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼çš„åˆ—
        text_format_cols = ['æ‹›ç”Ÿä»£ç ', 'ä¸“ä¸šç»„', 'ä½æ¬¡']
        for col_name in text_format_cols:
            col_idx = new_columns.index(col_name) + 1
            for row in range(4, len(new_result) + 4):
                cell = ws.cell(row=row, column=col_idx)
                if cell.value is not None:
                    # å°†å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç„¶åè®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼
                    cell.value = str(cell.value)
                    cell.number_format = numbers.FORMAT_TEXT

        # ä¿å­˜æ–‡ä»¶
        wb.save(output_path)
        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")


# ============================
# ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†
# ============================

def process_segmentation_file(file_path):
    output_path = os.path.splitext(file_path)[0] + "_æ ¡éªŒç»“æœ.xlsx"
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active

    ws['E7'] = 'ç´¯è®¡äººæ•°æ ¡éªŒç»“æœ'
    ws['F7'] = 'åˆ†æ•°æ ¡éªŒç»“æœ'
    ws['F2'] = 'å¹´ä»½æ ¡éªŒ'

    # æ ¡éªŒ B2 æ˜¯å¦ä¸º 2025
    if ws['B2'].value != 2025:
        ws['G2'] = f"Ã— åº”ä¸º2025ï¼Œå½“å‰ä¸ºï¼š{ws['B2'].value}"
    else:
        ws['G2'] = "âˆš"

    region = ws['B3'].value
    suffix = "-750"
    if region == "ä¸Šæµ·":
        suffix = "-660"
    elif region == "æµ·å—":
        suffix = "-900"

    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    # ---------- ç¬¬8è¡Œç‰¹æ®Šå¤„ç† ----------
    row = 8
    curr_score = ws[f"A{row}"].value
    curr_num = ws[f"B{row}"].value
    curr_total = ws[f"C{row}"].value

    try:
        score_int = int(float(str(curr_score).split('-')[0]))
    except:
        score_int = None

    inserted = False
    if curr_total is not None:
        if curr_num is None or curr_num == "":
            # æ²¡æœ‰äººæ•° â†’ è‡ªåŠ¨è®¡ç®—
            if row == 8:
                ws[f"B{row}"] = curr_total
            else:
                prev_total = ws[f"C{row - 1}"].value
                if prev_total is not None:
                    ws[f"B{row}"] = curr_total - prev_total
        else:
            # æœ‰äººæ•°å’Œç´¯è®¡äººæ•°ä¸ä¸€è‡´æ—¶æ’å…¥è¡¥æ–­ç‚¹è¡Œ
            if curr_num != curr_total:
                try:
                    insert_score = score_int + 1
                    insert_num = curr_total - curr_num
                    ws.insert_rows(row)
                    ws[f"A{row}"] = f"{insert_score}{suffix}"  # âœ… ä»…åŠ åç¼€åœ¨æ–°å¢è¡Œ
                    ws[f"B{row}"] = insert_num
                    ws[f"C{row}"] = insert_num
                    for col in ['A', 'B', 'C', 'E', 'F']:
                        ws[f"{col}{row}"].fill = yellow_fill
                    ws[f"E{row}"] = "è¡¥æ–­ç‚¹"
                    ws[f"F{row}"] = "è¡¥æ–­ç‚¹"
                    inserted = True
                except:
                    pass

    # ä»…å½“æ²¡æœ‰æ’å…¥è¡Œæ—¶ï¼Œç¬¬8è¡ŒåŠ åç¼€
    if not inserted and score_int is not None:
        ws[f"A{row}"] = f"{score_int}{suffix}"

    # ---------- è¡¥æ–­ç‚¹é€»è¾‘ ----------
    while row < ws.max_row:
        curr = ws[f"A{row}"].value
        next = ws[f"A{row + 1}"].value
        try:
            curr_score_int = int(str(curr).split('-')[0])
            next_score_int = int(str(next).split('-')[0])
        except:
            row += 1
            continue

        if curr_score_int - next_score_int > 1:
            missing_score = curr_score_int - 1
            ws.insert_rows(row + 1)
            ws[f"A{row + 1}"] = missing_score
            ws[f"B{row + 1}"] = 0
            ws[f"C{row + 1}"] = ws[f"C{row}"].value
            for col in ['A', 'B', 'C', 'E', 'F']:
                ws[f"{col}{row + 1}"].fill = yellow_fill
            ws[f"E{row + 1}"] = "è¡¥æ–­ç‚¹"
            ws[f"F{row + 1}"] = "è¡¥æ–­ç‚¹"
        else:
            row += 1

    # ---------- æ ¡éªŒä¸è‡ªåŠ¨è¡¥äººæ•° ----------
    for row in range(8, ws.max_row + 1):
        curr_score = ws[f"A{row}"].value
        curr_num = ws[f"B{row}"].value
        curr_total = ws[f"C{row}"].value
        prev_total = ws[f"C{row - 1}"].value if row > 8 else None
        prev_score = ws[f"A{row - 1}"].value if row > 8 else None

        # è‡ªåŠ¨è¡¥äººæ•°
        if (curr_num is None or curr_num == "") and curr_total is not None:
            if row == 8:
                ws[f"B{row}"] = curr_total
                curr_num = curr_total
            elif prev_total is not None:
                try:
                    calc = curr_total - prev_total
                    ws[f"B{row}"] = calc
                    curr_num = calc
                except:
                    pass

        # æ ¡éªŒç´¯è®¡äººæ•°
        if row == 8:
            # ç¬¬8è¡Œç›´æ¥æ ‡è®°æ­£ç¡®ï¼ˆå‡è®¾ç¬¬8è¡Œç´¯è®¡äººæ•°æ­£ç¡®ï¼‰
            if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"E{row}"] = "âˆš"
            correct_total = curr_total
        else:
            if curr_num is not None and curr_total is not None and correct_total is not None:
                expected_total = correct_total + curr_num
                if expected_total == curr_total:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = "âˆš"
                    correct_total = curr_total  # æœ¬è¡Œç´¯è®¡æ­£ç¡®ï¼Œç”¨å®ƒæ›´æ–°åŸºå‡†
                else:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = f"Ã— åº”ä¸º{expected_total}"
                    correct_total = expected_total

        # æ ¡éªŒåˆ†æ•°å·®
        try:
            curr_score_num = float(str(curr_score).split('-')[0])
            prev_score_num = float(str(prev_score).split('-')[0])
        except:
            curr_score_num = prev_score_num = None

        if curr_score_num is not None and prev_score_num is not None:
            diff = prev_score_num - curr_score_num
            if diff == 1:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = "âˆš"
            else:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = f"Ã— å·®å€¼{diff}"
        else:
            if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"F{row}"] = "Ã— åˆ†æ•°éæ•°å­—ï¼Œæ— æ³•æ ¡éªŒ"

    wb.save(output_path)
    return output_path


# ============================
# ä¸“ä¸šç»„ä»£ç åŒ¹é…å¯¼å‡ºå‡½æ•°
# ============================
def export_match_result_to_excel(export_df, headers, year_value, output_path):
    """å¯¼å‡ºä¸“ä¸šç»„ä»£ç åŒ¹é…ç»“æœä¸ºExcelæ ¼å¼"""
    # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
    remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€
ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€
æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æ‹›ç”Ÿäººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
5.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼Œä¿ç•™å°æ•°åä¸¤ä½ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
6.ä¸€çº§å±‚æ¬¡ï¼šé™å®š"æœ¬ç§‘ã€ä¸“ç§‘ï¼ˆé«˜èŒï¼‰"ï¼Œè¯¥éƒ¨åˆ†ä¸ºæ‹›ç”Ÿä¸“ä¸šå¯¹åº”çš„ä¸“ä¸šå±‚æ¬¡
7.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—;
8.æ•°æ®æ¥æºï¼šå¿…é¡»é™å®šâ€”â€”å®˜æ–¹è€ƒè¯•é™¢ã€å¤§çº¢æœ¬æ•°æ®ã€å­¦æ ¡å®˜ç½‘ã€é”€å”®ã€æŠ“å–ã€åœ£è¾¾ä¿¡ã€ä¼˜å¿—æ„¿ã€å­¦ä¸šæ¡¥
9.é€‰ç§‘è¦æ±‚ï¼šä¸é™ç§‘ç›®ä¸“ä¸šç»„;å¤šé—¨é€‰è€ƒ;å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ
10.é€‰ç§‘ç§‘ç›®å¿…é¡»æ˜¯ç§‘ç›®çš„ç®€å†™ï¼ˆç‰©ã€åŒ–ã€ç”Ÿã€å†ã€åœ°ã€æ”¿ã€æŠ€ï¼‰
                    
11.2020åŒ—äº¬ã€æµ·å—ï¼Œ17-19ä¸Šæµ·ä»…é™åˆ¶æœ¬ç§‘ä¸“ä¸šç»„ä»£ç å¿…å¡«
12.æ–°å…«çœé¦–é€‰ç§‘ç›®å¿…é¡»é€‰æ‹©ï¼ˆç‰©ç†æˆ–å†å²ï¼‰
13.åˆ†æ•°åŒºé—´ä»…é™åŒ—äº¬"""

    # åˆ›å»ºå·¥ä½œç°¿
    wb = openpyxl.Workbook()
    ws = wb.active

    # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
    ws.merge_cells('A1:U1')
    ws['A1'] = remark_text
    ws['A1'].alignment = Alignment(wrap_text=True, vertical='top')
    # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º220ç£…
    ws.row_dimensions[1].height = 220

    # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´ä»½"ï¼ŒB2=å¹´ä»½å€¼
    ws['A2'] = 'æ‹›ç”Ÿå¹´ä»½'
    ws['B2'] = year_value if year_value else ''
    # B2è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼
    ws['B2'].number_format = numbers.FORMAT_TEXT

    # å¤„ç†æ ‡é¢˜è¡Œï¼šå¦‚æœheadersä¸ºç©ºæˆ–Noneï¼Œä½¿ç”¨export_dfçš„åˆ—å
    if not headers or len(headers) == 0:
        headers = list(export_df.columns)
    
    # æ¸…ç†headersä¸­çš„Noneå€¼ï¼Œå¹¶å»é™¤ç©ºå­—ç¬¦ä¸²
    headers = [h if h is not None else '' for h in headers]
    
    # æŒ‰ç…§headersçš„é¡ºåºå¯¼å‡ºï¼Œç¡®ä¿ä¸åŸå§‹æ–‡ä»¶Açš„ç¬¬3è¡Œæ ‡é¢˜é¡ºåºä¸€è‡´
    # å¦‚æœheadersä¸­çš„åˆ—åœ¨export_dfä¸­å­˜åœ¨ï¼Œä½¿ç”¨export_dfçš„å€¼ï¼›å¦åˆ™ä¸ºç©º
    final_headers = []
    for h in headers:
        if h and h.strip():  # éç©ºæ ‡é¢˜
            final_headers.append(h.strip())
    
    # æ·»åŠ export_dfä¸­å­˜åœ¨ä½†headersä¸­æ²¡æœ‰çš„åˆ—ï¼ˆè¿½åŠ åˆ°æœ«å°¾ï¼‰
    for col in export_df.columns:
        if col not in final_headers:
            final_headers.append(col)

    # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œï¼ˆä½¿ç”¨å¤„ç†åçš„æ ‡é¢˜ï¼‰
    for col_idx, header in enumerate(final_headers, start=1):
        ws.cell(row=3, column=col_idx, value=header if header else '')

    # æ•°æ®è¡Œï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
    for row_idx, (_, row_data) in enumerate(export_df.iterrows(), start=4):
        for col_idx, header in enumerate(final_headers, start=1):
            if header in export_df.columns:
                value = row_data[header]
                # å¤„ç†ç©ºå€¼
                if value is None or pd.isna(value):
                    value = ''
                elif isinstance(value, str) and value.lower() in ['nan', 'none']:
                    value = ''
                cell = ws.cell(row=row_idx, column=col_idx, value=value)
                # è®¾ç½®ä»£ç åˆ—ä¸ºæ–‡æœ¬æ ¼å¼
                if header in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                    cell.number_format = numbers.FORMAT_TEXT
            else:
                ws.cell(row=row_idx, column=col_idx, value='')

    wb.save(output_path)


# ============================
# ä¸“ä¸šç»„ä»£ç åŒ¹é…
# ============================

tableA_fields = [
    "å­¦æ ¡åç§°", "çœä»½", "æ‹›ç”Ÿä¸“ä¸š", "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰",
    "ä¸€çº§å±‚æ¬¡", "æ‹›ç”Ÿç§‘ç±»", "æ‹›ç”Ÿæ‰¹æ¬¡", "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰"
]

rename_mapping_B = {
    "å­¦æ ¡": "å­¦æ ¡åç§°",
    "çœä»½": "çœä»½",
    "å±‚æ¬¡": "ä¸€çº§å±‚æ¬¡",
    "ç§‘ç±»": "æ‹›ç”Ÿç§‘ç±»",
    "æ‰¹æ¬¡": "æ‹›ç”Ÿæ‰¹æ¬¡",
    "æ‹›ç”Ÿç±»å‹": "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰",
    "ä¸“ä¸š": "æ‹›ç”Ÿä¸“ä¸š",
    "å¤‡æ³¨": "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"
}


def process_data(dfA, dfB):
    dfB.rename(columns=rename_mapping_B, inplace=True)

    # æ„å»ºç»„åˆé”®ï¼ˆä¸å«å¤‡æ³¨å’Œæ‹›ç”Ÿç±»å‹ï¼‰ï¼šå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ä¸“ä¸š
    key_fields = [f for f in tableA_fields if f not in ["ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰"]]
    dfA["ç»„åˆé”®"] = dfA[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)
    dfB["ç»„åˆé”®"] = dfB[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)

    # æ£€æŸ¥Aè¡¨å’ŒBè¡¨ä¸­ç»„åˆé”®çš„é‡å¤æ€§
    # ç»Ÿè®¡Aè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    a_key_counts = dfA["ç»„åˆé”®"].value_counts()
    # ç»Ÿè®¡Bè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    b_key_counts = dfB["ç»„åˆé”®"].value_counts()

    # æ‰¾å‡ºAè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    a_duplicate_keys = set(a_key_counts[a_key_counts > 1].index)
    # æ‰¾å‡ºBè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    b_duplicate_keys = set(b_key_counts[b_key_counts > 1].index)

    # æ„å»ºBè¡¨å­—å…¸ï¼šç»„åˆé”® â†’ è®°å½•åˆ—è¡¨
    b_dict = dfB.groupby("ç»„åˆé”®").apply(lambda x: x.to_dict("records")).to_dict()

    # å­˜å‚¨éœ€è¦æ‰‹åŠ¨è¡¥å……çš„è®°å½•ä¿¡æ¯
    manual_fill_records = []

    def get_code(row):
        key = row["ç»„åˆé”®"]
        candidates = b_dict.get(key, [])

        # æ£€æŸ¥è¯¥ç»„åˆé”®åœ¨Aè¡¨æˆ–Bè¡¨ä¸­æ˜¯å¦æœ‰é‡å¤
        has_duplicate_in_a = key in a_duplicate_keys
        has_duplicate_in_b = key in b_duplicate_keys

        # å¦‚æœAè¡¨æˆ–Bè¡¨ä¸­ä»»ä½•ä¸€ä¸ªæœ‰é‡å¤ï¼Œéœ€è¦æ‰‹åŠ¨è¡¥å……
        if has_duplicate_in_a or has_duplicate_in_b:
            # è¿”å›å®Œæ•´çš„å€™é€‰è®°å½•åˆ—è¡¨ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µä¿¡æ¯ï¼‰
            return None, candidates if candidates else []

        # Aè¡¨å’ŒBè¡¨ä¸­éƒ½æ²¡æœ‰é‡å¤ï¼Œä¸”Bè¡¨ä¸­åªæœ‰å”¯ä¸€å€™é€‰è®°å½•ï¼Œå¯ä»¥ç›´æ¥åŒ¹é…
        if len(candidates) == 1:
            return candidates[0]["ä¸“ä¸šç»„ä»£ç "], None

        # å…¶ä»–æƒ…å†µï¼ˆæ— å€™é€‰è®°å½•æˆ–å¤šä¸ªå€™é€‰è®°å½•ï¼‰éƒ½éœ€è¦æ‰‹åŠ¨è¡¥å……
        # è¿”å›Noneå’Œå€™é€‰è®°å½•åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
        return None, candidates if candidates else []

    # åº”ç”¨åŒ¹é…é€»è¾‘
    results = dfA.apply(get_code, axis=1)
    dfA["ä¸“ä¸šç»„ä»£ç "] = results.apply(lambda x: x[0] if x[0] is not None else "")
    
    # æ”¶é›†éœ€è¦æ‰‹åŠ¨è¡¥å……çš„è®°å½•ï¼ˆåŒ…å«å®Œæ•´çš„å€™é€‰è®°å½•ä¿¡æ¯ï¼‰
    # åªè¦ä¸“ä¸šç»„ä»£ç æ²¡åŒ¹é…åˆ°çš„ï¼Œéƒ½éœ€è¦æ‰‹åŠ¨é€‰æ‹©
    for idx, row in dfA.iterrows():
        result = results.iloc[idx]
        matched_code = result[0]  # åŒ¹é…åˆ°çš„ä¸“ä¸šç»„ä»£ç 
        candidates = result[1] if result[1] is not None else []
        
        # å¦‚æœä¸“ä¸šç»„ä»£ç ä¸ºç©ºï¼ˆæ²¡æœ‰åŒ¹é…åˆ°ï¼‰ï¼Œéœ€è¦æ‰‹åŠ¨è¡¥å……
        if not matched_code or matched_code == "":
            # æå–å€™é€‰è®°å½•çš„è¯¦ç»†ä¿¡æ¯
            candidate_records = []
            for candidate in candidates:
                candidate_records.append({
                    "ä¸“ä¸šç»„ä»£ç ": candidate.get("ä¸“ä¸šç»„ä»£ç ", ""),
                    "å­¦æ ¡åç§°": candidate.get("å­¦æ ¡åç§°", ""),
                    "çœä»½": candidate.get("çœä»½", ""),
                    "æ‹›ç”Ÿä¸“ä¸š": candidate.get("æ‹›ç”Ÿä¸“ä¸š", ""),
                    "ä¸€çº§å±‚æ¬¡": candidate.get("ä¸€çº§å±‚æ¬¡", ""),
                    "æ‹›ç”Ÿç§‘ç±»": candidate.get("æ‹›ç”Ÿç§‘ç±»", ""),
                    "æ‹›ç”Ÿæ‰¹æ¬¡": candidate.get("æ‹›ç”Ÿæ‰¹æ¬¡", ""),
                    "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰": candidate.get("æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰", ""),
                    "å¤‡æ³¨ï¼ˆæ‹›ç”Ÿè®¡åˆ’ï¼‰": candidate.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", ""),  # Bè¡¨é‡å‘½ååçš„å¤‡æ³¨å­—æ®µ
                })
            
            manual_fill_records.append({
                "ç´¢å¼•": idx,
                "å­¦æ ¡åç§°": row.get("å­¦æ ¡åç§°", ""),
                "çœä»½": row.get("çœä»½", ""),
                "æ‹›ç”Ÿä¸“ä¸š": row.get("æ‹›ç”Ÿä¸“ä¸š", ""),
                "ä¸€çº§å±‚æ¬¡": row.get("ä¸€çº§å±‚æ¬¡", ""),
                "æ‹›ç”Ÿç§‘ç±»": row.get("æ‹›ç”Ÿç§‘ç±»", ""),
                "æ‹›ç”Ÿæ‰¹æ¬¡": row.get("æ‹›ç”Ÿæ‰¹æ¬¡", ""),
                "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰": row.get("æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰", ""),
                "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰": row.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", ""),  # Aè¡¨çš„ä¸“ä¸šå¤‡æ³¨å­—æ®µ
                "å€™é€‰è®°å½•": candidate_records  # å®Œæ•´çš„å€™é€‰è®°å½•åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
            })

    return dfA, manual_fill_records


# ========== å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå– ==========

def fetch_images_static(url, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    image_paths = []
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        imgs = soup.find_all("img")
        for idx, img in enumerate(imgs, 1):
            src = img.get("src")
            if not src:
                continue
            full_url = urljoin(url, src)
            # è·³è¿‡ base64 æˆ– blob ç±»å‹
            if full_url.startswith("data:") or full_url.startswith("blob:"):
                continue
            ext = os.path.splitext(urlparse(full_url).path)[1] or ".jpg"
            filename = f"img_{idx:03d}{ext}"
            path = os.path.join(output_folder, filename)
            try:
                img_resp = requests.get(full_url, timeout=10)
                if img_resp.status_code != 200:
                    continue
                content_type = img_resp.headers.get("content-type", "")
                # ä»…ä¿å­˜çœŸæ­£çš„å›¾ç‰‡ç±»å‹
                if not content_type.startswith("image/"):
                    continue
                img_data = img_resp.content
                # éªŒè¯å›¾ç‰‡æ˜¯å¦å¯è¯†åˆ«
                try:
                    Image.open(io.BytesIO(img_data))
                except Exception:
                    continue
                with open(path, "wb") as f:
                    f.write(img_data)
                image_paths.append(path)
            except Exception:
                continue
    except Exception as e:
        raise Exception(f"é™æ€æ¨¡å¼åŠ è½½å¤±è´¥: {e}")
    return image_paths


def images_to_pdf(image_paths, pdf_path):
    images = []
    for path in sorted(image_paths):
        try:
            img = Image.open(path).convert("RGB")
            images.append(img)
        except Exception:
            continue
    if images:
        images[0].save(pdf_path, save_all=True, append_images=images[1:])
        return True
    return False


# ============================
# æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ä¸è½¬æ¢å·¥å…·ç›¸å…³å‡½æ•°
# ============================

def generate_plan_score_key(item):
    """ç”Ÿæˆæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†çš„ç»„åˆé”®"""
    year = str(item.get('å¹´ä»½', '') or '').strip()
    province = str(item.get('çœä»½', '') or '').strip()
    school = str(item.get('å­¦æ ¡', '') or '').strip()
    subject = str(item.get('ç§‘ç±»', '') or '').strip()
    batch = str(item.get('æ‰¹æ¬¡', '') or '').strip()
    major = str(item.get('ä¸“ä¸š', '') or '').strip()
    level = str(item.get('å±‚æ¬¡', '') or '').strip()
    group_code = str(item.get('ä¸“ä¸šç»„ä»£ç ', '') or '').strip()
    return f"{year}|{province}|{school}|{subject}|{batch}|{major}|{level}|{group_code}"


def generate_plan_college_key(item):
    """ç”Ÿæˆæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†çš„ç»„åˆé”®ï¼Œä½¿ç”¨æ–°çš„ç»„åˆé”®å­—æ®µ"""
    province = str(item.get('çœä»½', '') or '').strip()
    school = str(item.get('å­¦æ ¡', '') or '').strip()
    subject = str(item.get('ç§‘ç±»', '') or '').strip()
    batch = str(item.get('æ‰¹æ¬¡', '') or '').strip()
    group_code = str(item.get('ä¸“ä¸šç»„ä»£ç ', '') or '').strip()
    recruit_code = str(item.get('æ‹›ç”Ÿä»£ç ', '') or '').strip()
    return f"{province}|{school}|{subject}|{batch}|{group_code}|{recruit_code}"


def compare_plan_vs_score(plan_df, score_df):
    """æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†"""
    plan_score_results = []
    score_key_set = set()

    # ä¸ºä¸“ä¸šåˆ†æ•°æ®å»ºç«‹ç´¢å¼•
    for _, item in score_df.iterrows():
        key = generate_plan_score_key(item.to_dict())
        score_key_set.add(key)

    # æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’æ•°æ®
    for idx, row in plan_df.iterrows():
        item = row.to_dict()
        key = generate_plan_score_key(item)
        exists = key in score_key_set

        plan_score_results.append({
            'index': idx + 1,
            'originalIndex': idx,
            'keyFields': {
                'å¹´ä»½': item.get('å¹´ä»½', '') or '',
                'çœä»½': item.get('çœä»½', '') or '',
                'å­¦æ ¡': item.get('å­¦æ ¡', '') or '',
                'ç§‘ç±»': item.get('ç§‘ç±»', '') or '',
                'æ‰¹æ¬¡': item.get('æ‰¹æ¬¡', '') or '',
                'ä¸“ä¸š': item.get('ä¸“ä¸š', '') or '',
                'å±‚æ¬¡': item.get('å±‚æ¬¡', '') or '',
                'ä¸“ä¸šç»„ä»£ç ': item.get('ä¸“ä¸šç»„ä»£ç ', '') or ''
            },
            'exists': exists,
            'otherInfo': {
                'æ‹›ç”Ÿäººæ•°': item.get('æ‹›ç”Ÿäººæ•°', '') or '',
                'å­¦è´¹': item.get('å­¦è´¹', '') or '',
                'å­¦åˆ¶': item.get('å­¦åˆ¶', '') or '',
                'ä¸“ä¸šä»£ç ': item.get('ä¸“ä¸šä»£ç ', '') or '',
                'æ‹›ç”Ÿä»£ç ': item.get('æ‹›ç”Ÿä»£ç ', '') or '',
                'æ•°æ®æ¥æº': item.get('æ•°æ®æ¥æº', '') or '',
                'å¤‡æ³¨': item.get('å¤‡æ³¨', '') or '',
                'æ‹›ç”Ÿç±»å‹': item.get('æ‹›ç”Ÿç±»å‹', '') or '',
                'ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', '') or '',
                'ä¸“ä¸šé€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '') or ''
            }
        })

    return plan_score_results


def compare_plan_vs_college(plan_df, college_df):
    """æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†"""
    plan_college_results = []
    college_key_set = set()

    # ä¸ºé™¢æ ¡åˆ†æ•°æ®å»ºç«‹ç´¢å¼•
    for _, item in college_df.iterrows():
        key = generate_plan_college_key(item.to_dict())
        college_key_set.add(key)

    # æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’æ•°æ®
    for idx, row in plan_df.iterrows():
        item = row.to_dict()
        key = generate_plan_college_key(item)
        exists = key in college_key_set

        plan_college_results.append({
            'index': idx + 1,
            'originalIndex': idx,
            'keyFields': {
                'çœä»½': item.get('çœä»½', '') or '',
                'å­¦æ ¡': item.get('å­¦æ ¡', '') or '',
                'ç§‘ç±»': item.get('ç§‘ç±»', '') or '',
                'æ‰¹æ¬¡': item.get('æ‰¹æ¬¡', '') or '',
                'ä¸“ä¸šç»„ä»£ç ': item.get('ä¸“ä¸šç»„ä»£ç ', '') or '',
                'æ‹›ç”Ÿä»£ç ': item.get('æ‹›ç”Ÿä»£ç ', '') or ''
            },
            'exists': exists,
            'otherInfo': {
                'å¹´ä»½': item.get('å¹´ä»½', '') or '',
                'ä¸“ä¸š': item.get('ä¸“ä¸š', '') or '',
                'å±‚æ¬¡': item.get('å±‚æ¬¡', '') or '',
                'æ‹›ç”Ÿäººæ•°': item.get('æ‹›ç”Ÿäººæ•°', '') or '',
                'å­¦è´¹': item.get('å­¦è´¹', '') or '',
                'å­¦åˆ¶': item.get('å­¦åˆ¶', '') or '',
                'ä¸“ä¸šä»£ç ': item.get('ä¸“ä¸šä»£ç ', '') or '',
                'æ•°æ®æ¥æº': item.get('æ•°æ®æ¥æº', '') or '',
                'å¤‡æ³¨': item.get('å¤‡æ³¨', '') or '',
                'æ‹›ç”Ÿç±»å‹': item.get('æ‹›ç”Ÿç±»å‹', '') or '',
                'ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', '') or '',
                'ä¸“ä¸šé€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '') or ''
            }
        })

    return plan_college_results


def filter_unmatched_plan_data_for_college_export(plan_df, college_df):
    """
    è¿‡æ»¤å‡ºæ‹›ç”Ÿè®¡åˆ’ä¸­ä¸å­˜åœ¨äºé™¢æ ¡åˆ†ä¸­çš„æ•°æ®ã€‚
    
    æ¯”å¯¹é€»è¾‘ï¼š
    - æŒ‰çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šç»„ä»£ç ã€æ‹›ç”Ÿä»£ç è¿™å‡ ä¸ªå­—æ®µè¿›è¡Œæ¯”å¯¹
    - åªå¯¼å‡ºæ‹›ç”Ÿè®¡åˆ’ä¸­ï¼Œè¿™å‡ ä¸ªå­—æ®µçš„ç»„åˆé”®ä¸å­˜åœ¨çš„å†…å®¹
    - æ³¨æ„ï¼šæ‹›ç”Ÿè®¡åˆ’ä¸­å¯èƒ½å­˜åœ¨å¤šä¸ªç›¸åŒçš„ç»„åˆé”®ï¼Œåªè¦é™¢æ ¡åˆ†å­˜åœ¨ä¸€ä¸ªï¼Œå°±ä¸å¯¼å‡º
    
    è¿”å›ï¼šæœªåŒ¹é…çš„æ‹›ç”Ÿè®¡åˆ’è®°å½•åˆ—è¡¨
    """
    unmatched_records = []
    
    # ä¸ºé™¢æ ¡åˆ†æ•°æ®å»ºç«‹ç»„åˆé”®é›†åˆ
    college_key_set = set()
    for _, item in college_df.iterrows():
        key = generate_plan_college_key(item.to_dict())
        college_key_set.add(key)
    
    # éå†æ‹›ç”Ÿè®¡åˆ’ï¼Œæ‰¾å‡ºæœªåŒ¹é…çš„è®°å½•
    seen_keys = set()  # è®°å½•å·²å¤„ç†è¿‡çš„ç»„åˆé”®ï¼Œé¿å…é‡å¤
    for idx, row in plan_df.iterrows():
        item = row.to_dict()
        key = generate_plan_college_key(item)
        
        # åªæœ‰å½“ç»„åˆé”®ä¸åœ¨é™¢æ ¡åˆ†ä¸­ï¼Œä¸”è¿™ä¸ªç»„åˆé”®è¿˜æ²¡æœ‰è¢«å¤„ç†è¿‡æ—¶ï¼Œæ‰æ·»åŠ 
        if key not in college_key_set and key not in seen_keys:
            seen_keys.add(key)
            unmatched_records.append({
                'index': idx + 1,
                'originalIndex': idx,
                'data': item
            })
    
    return unmatched_records


def get_first_subject(category):
    """è·å–é¦–é€‰ç§‘ç›®ï¼šæ ¹æ®æ‹›ç”Ÿç§‘ç±»çš„ç¬¬ä¸€ä¸ªå­—"""
    if not category:
        return ''
    category_str = str(category)
    if 'ç‰©ç†ç±»' in category_str or 'ç‰©ç†' in category_str:
        return 'ç‰©'
    elif 'å†å²ç±»' in category_str or 'å†å²' in category_str:
        return 'å†'
    return ''


def convert_level(level):
    """è½¬æ¢å±‚æ¬¡å­—æ®µ"""
    if not level:
        return ''
    level_str = str(level).lower()
    if 'ä¸“ç§‘' in level_str or 'é«˜èŒ' in level_str:
        return 'ä¸“ç§‘(é«˜èŒ)'
    elif 'æœ¬ç§‘' in level_str:
        return 'æœ¬ç§‘(æ™®é€š)'
    return level


def extract_required_subjects(text):
    """æå–å¿…é€‰ç§‘ç›®ï¼ˆå¤„ç†"ç‰©åŒ–ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼ï¼‰"""
    if not text:
        return []

    subjects = []
    subject_map = {
        'ç‰©ç†': 'ç‰©', 'åŒ–å­¦': 'åŒ–', 'ç”Ÿç‰©': 'ç”Ÿ', 'å†å²': 'å†',
        'åœ°ç†': 'åœ°', 'æ”¿æ²»': 'æ”¿', 'æŠ€æœ¯': 'æŠ€'
    }

    # æ¸…ç†æ–‡æœ¬ï¼Œä¿ç•™ä¸­æ–‡å’Œé¡¿å·ã€é€—å·
    import re
    clean_text = re.sub(r'[^\u4e00-\u9fa5ã€ï¼Œ,]', '', str(text)).strip()

    # å¤„ç†"ç‰©åŒ–ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼ï¼šç›´æ¥æå–æ‹¬å·å‰çš„å†…å®¹
    if 'å¿…é€‰' in text and 'ï¼ˆ' in text and text.index('å¿…é€‰') > text.index('ï¼ˆ'):
        before_bracket = text.split('ï¼ˆ')[0]
        clean_text = before_bracket

    # å¤„ç†"ç‰©ã€åŒ–ã€ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼ï¼šé¡¿å·åˆ†éš”çš„ç§‘ç›®
    if 'ã€' in clean_text or 'ï¼Œ' in clean_text or ',' in clean_text:
        normalized_text = re.sub(r'[ã€ï¼Œ]', ',', clean_text)
        parts = [p.strip() for p in normalized_text.split(',') if p.strip()]
        for part in parts:
            for full_name, short_name in subject_map.items():
                if full_name in part or part in full_name:
                    if short_name not in subjects:
                        subjects.append(short_name)
                    break
    else:
        # å¤„ç†"ç‰©åŒ–ç”Ÿ"è¿™æ ·çš„è¿ç»­å­—ç¬¦ä¸²
        for full_name, short_name in subject_map.items():
            if full_name in clean_text:
                if short_name not in subjects:
                    subjects.append(short_name)

        # å¦‚æœæ²¡åŒ¹é…åˆ°å…¨åï¼Œå°è¯•æŒ‰å­—ç¬¦åŒ¹é…
        if len(subjects) == 0 and len(clean_text) > 0:
            char_to_short_map = {
                'ç‰©': 'ç‰©', 'åŒ–': 'åŒ–', 'ç”Ÿ': 'ç”Ÿ', 'å†': 'å†',
                'åœ°': 'åœ°', 'æ”¿': 'æ”¿', 'æŠ€': 'æŠ€'
            }
            for char in clean_text:
                if char in char_to_short_map and char_to_short_map[char] not in subjects:
                    subjects.append(char_to_short_map[char])

    return subjects


def extract_required_subjects_with_format(text):
    """æå–å¿…é€‰ç§‘ç›®ï¼ˆå»æ‰æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ï¼‰
    å¤„ç†æ ¼å¼å¦‚ï¼šç‰©åŒ–ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰ã€ç‰©ã€åŒ–ã€ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰ã€ç”Ÿã€åŒ–ã€ç‰©ï¼ˆ3ç§‘å¿…é€‰ï¼‰ã€ç‰©åŒ–ç”Ÿ(3ç§‘å¿…é€‰)ç­‰
    è¿”å›æ—¶å»æ‰æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œåªä¿ç•™ç§‘ç›®å­—ç¬¦
    """
    if not text:
        return ''
    
    import re
    
    # å¤„ç†"ç‰©åŒ–ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æˆ–"ç‰©ã€åŒ–ã€ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æˆ–"ç”Ÿã€åŒ–ã€ç‰©ï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼
    # æ”¯æŒä¸­æ–‡æ‹¬å·ï¼ˆã€ï¼‰å’Œè‹±æ–‡æ‹¬å·()
    extracted_text = ''
    
    if 'å¿…é€‰' in text:
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ‹¬å·ä½ç½®
        bracket_patterns = [
            (r'ï¼ˆ', r'ï¼‰'),  # ä¸­æ–‡æ‹¬å·
            (r'\(', r'\)'),  # è‹±æ–‡æ‹¬å·
        ]
        
        for left_bracket, right_bracket in bracket_patterns:
            # æŸ¥æ‰¾å·¦æ‹¬å·ä½ç½®
            left_match = re.search(left_bracket, text)
            if left_match:
                left_pos = left_match.start()
                # æå–æ‹¬å·å‰çš„å†…å®¹
                before_bracket = text[:left_pos].strip()
                if before_bracket:
                    extracted_text = before_bracket
                    break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ‹¬å·ï¼Œä½†åŒ…å«"3ç§‘å¿…é€‰"ç­‰å­—æ ·ï¼Œå°è¯•æå–å‰é¢çš„å†…å®¹
        # ä¾‹å¦‚ï¼š"ç‰©åŒ–ç”Ÿ3ç§‘å¿…é€‰"æˆ–"ç‰©ã€åŒ–ã€ç”Ÿ3ç§‘å¿…é€‰"
        if not extracted_text and ('3ç§‘å¿…é€‰' in text or 'ä¸‰ç§‘å¿…é€‰' in text):
            # æ‰¾åˆ°"å¿…é€‰"çš„ä½ç½®
            bi_xuan_pos = text.find('å¿…é€‰')
            if bi_xuan_pos > 0:
                before_bi_xuan = text[:bi_xuan_pos].strip()
                # ç§»é™¤å¯èƒ½çš„æ•°å­—å’Œ"ç§‘"å­—
                before_bi_xuan = re.sub(r'\d+ç§‘', '', before_bi_xuan).strip()
                if before_bi_xuan:
                    extracted_text = before_bi_xuan
        
        # å»æ‰æ‰€æœ‰æ ‡ç‚¹ç¬¦å·ï¼ˆé¡¿å·ã€é€—å·ã€ç©ºæ ¼ç­‰ï¼‰ï¼Œåªä¿ç•™ç§‘ç›®å­—ç¬¦
        if extracted_text:
            # åªä¿ç•™ç§‘ç›®å­—ç¬¦ï¼šç‰©ã€åŒ–ã€ç”Ÿã€å†ã€åœ°ã€æ”¿ã€æŠ€ç­‰
            subject_chars = ['ç‰©', 'åŒ–', 'ç”Ÿ', 'å†', 'åœ°', 'æ”¿', 'æŠ€']
            cleaned_text = ''.join([char for char in extracted_text if char in subject_chars])
            return cleaned_text
    
    return ''


def convert_selection_requirement(group_requirement, major_requirement):
    """è½¬æ¢é€‰ç§‘è¦æ±‚"""
    selection_requirement = ''
    second_subject = ''

    # åˆå¹¶ä¸¤ä¸ªè¦æ±‚å­—æ®µï¼ˆä¸“ä¸šç»„é€‰ç§‘è¦æ±‚å’Œä¸“ä¸šé€‰ç§‘è¦æ±‚ï¼‰
    group_req_str = str(group_requirement).strip() if group_requirement else ''
    major_req_str = str(major_requirement).strip() if major_requirement else ''
    
    # å¦‚æœä¸¤ä¸ªå­—æ®µéƒ½æœ‰å†…å®¹ï¼Œç”¨é¡¿å·è¿æ¥
    if group_req_str and major_req_str:
        requirement = group_req_str + 'ã€' + major_req_str
    else:
        requirement = group_req_str + major_req_str

    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    import re
    requirement = re.sub(r'^\^+', '', requirement).replace('^', 'ã€').strip()

    if not requirement or requirement == '' or requirement == 'ã€':
        return selection_requirement, second_subject

    # æ ¹æ®é™„ä»¶2ç¤ºä¾‹å¤„ç†å„ç§æƒ…å†µ
    if 'ä¸é™' in requirement or 'å†é€‰ä¸é™' in requirement:
        selection_requirement = 'ä¸é™ç§‘ç›®ä¸“ä¸šç»„'
    elif 'å¿…é€‰' in requirement:
        # å¯¹äº"3ç§‘å¿…é€‰"çš„æƒ…å†µï¼Œæå–ç§‘ç›®å¹¶å»æ‰æ ‡ç‚¹ç¬¦å·
        original_format = extract_required_subjects_with_format(requirement)
        required_subjects = []
        
        if original_format:
            selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
            second_subject = original_format
        else:
            # å…¶ä»–å¿…é€‰æƒ…å†µï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            required_subjects = extract_required_subjects(requirement)
            if len(required_subjects) > 0:
                selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
                second_subject = ''.join(required_subjects)

        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŒ…å«"é¦–é€‰"ï¼Œå¯èƒ½éœ€è¦æ’é™¤é¦–é€‰ç§‘ç›®
        if 'é¦–é€‰' in requirement:
            preferred_subjects = []
            if 'é¦–é€‰ç‰©ç†' in requirement:
                preferred_subjects.append('ç‰©')
            if 'é¦–é€‰å†å²' in requirement:
                preferred_subjects.append('å†')
            
            # å¦‚æœå·²ç»æå–äº†æ ¼å¼ï¼ˆå·²å»æ‰æ ‡ç‚¹ç¬¦å·ï¼‰ï¼Œéœ€è¦ä»ä¸­æ’é™¤é¦–é€‰ç§‘ç›®
            if original_format:
                # ä»å·²å»æ‰æ ‡ç‚¹çš„å­—ç¬¦ä¸²ä¸­ç§»é™¤é¦–é€‰ç§‘ç›®å­—ç¬¦
                filtered_format = original_format
                for pref_subj in preferred_subjects:
                    filtered_format = filtered_format.replace(pref_subj, '')
                if filtered_format:
                    second_subject = filtered_format
            elif required_subjects:
                filtered_subjects = [s for s in required_subjects if s not in preferred_subjects]
                if len(filtered_subjects) > 0:
                    second_subject = ''.join(filtered_subjects)
    elif 'é¦–é€‰' in requirement and 'å†é€‰' in requirement:
        re_select_part = requirement.split('å†é€‰')[1] if 'å†é€‰' in requirement else ''
        re_select_subjects = extract_required_subjects(re_select_part)
        if len(re_select_subjects) > 0:
            selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
            second_subject = ''.join(re_select_subjects)
    elif 'æˆ–' in requirement or 'é€‰1' in requirement:
        subjects = extract_required_subjects(requirement)
        filtered_subjects = [s for s in subjects if s not in ['ç‰©', 'å†']]
        if len(filtered_subjects) > 0:
            selection_requirement = 'å¤šé—¨é€‰è€ƒ'
            second_subject = ''.join(filtered_subjects)
    else:
        subjects = extract_required_subjects(requirement)
        filtered_subjects = [s for s in subjects if s not in ['ç‰©', 'å†']]
        second_subject = ''.join(filtered_subjects)
        if len(filtered_subjects) > 0:
            selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'

    return selection_requirement, second_subject


def convert_to_text(value):
    """è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
    if not value and value != 0:
        return ''
    text = str(value).lstrip('^').strip()
    if text == '':
        return ''
    text = text.lstrip("'")
    return text


def convert_data(source_data):
    """è½¬æ¢æ•°æ®ä¸»å‡½æ•°"""
    converted = []

    for row in source_data:
        new_row = {}

        # åŸºç¡€å­—æ®µæ˜ å°„
        new_row['å­¦æ ¡åç§°'] = row.get('å­¦æ ¡', '') or ''
        new_row['çœä»½'] = row.get('çœä»½', '') or ''
        new_row['æ‹›ç”Ÿä¸“ä¸š'] = row.get('ä¸“ä¸š', '') or ''
        new_row['æ‹›ç”Ÿç§‘ç±»'] = row.get('ç§‘ç±»', '') or ''
        new_row['æ‹›ç”Ÿæ‰¹æ¬¡'] = row.get('æ‰¹æ¬¡', '') or ''
        new_row['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = row.get('æ‹›ç”Ÿç±»å‹', '') or ''
        new_row['ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰'] = row.get('å¤‡æ³¨', '') or ''
        new_row['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = row.get('æ‹›ç”Ÿäººæ•°', '') or ''
        new_row['æ•°æ®æ¥æº'] = row.get('æ•°æ®æ¥æº', '') or ''

        # å¤„ç†å±‚æ¬¡å­—æ®µ
        new_row['ä¸€çº§å±‚æ¬¡'] = convert_level(row.get('å±‚æ¬¡', ''))

        # å¤„ç†ä»£ç å­—æ®µï¼ˆä¿æŒæ–‡æœ¬æ ¼å¼ï¼‰
        new_row['æ‹›ç”Ÿä»£ç '] = convert_to_text(row.get('æ‹›ç”Ÿä»£ç ', ''))
        new_row['ä¸“ä¸šä»£ç '] = convert_to_text(row.get('ä¸“ä¸šä»£ç ', ''))
        new_row['ä¸“ä¸šç»„ä»£ç '] = convert_to_text(row.get('ä¸“ä¸šç»„ä»£ç ', ''))

        # å¤„ç†é¦–é€‰ç§‘ç›®
        new_row['é¦–é€‰ç§‘ç›®'] = get_first_subject(row.get('ç§‘ç±»', ''))

        # å¤„ç†é€‰ç§‘è¦æ±‚
        selection_requirement, second_subject = convert_selection_requirement(
            row.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', ''),
            row.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '')
        )
        new_row['é€‰ç§‘è¦æ±‚'] = selection_requirement
        new_row['æ¬¡é€‰ç§‘ç›®'] = second_subject

        # å…¶ä»–å­—æ®µï¼ˆç•™ç©ºï¼‰
        new_row['ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰'] = ''
        new_row['æœ€é«˜åˆ†'] = ''
        new_row['æœ€ä½åˆ†'] = ''
        new_row['å¹³å‡åˆ†'] = ''
        new_row['æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´é«˜'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜'] = ''
        new_row['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = ''

        converted.append(new_row)

    return converted


def convert_to_college_score_format(conversion_data):
    """å°†æ‹›ç”Ÿè®¡åˆ’æ•°æ®è½¬æ¢ä¸ºé™¢æ ¡åˆ†æ ¼å¼"""
    if not conversion_data:
        return []

    # è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨åœ°å¤„ç†ç©ºå€¼ï¼Œå°†Noneã€NaNç­‰è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²
    def safe_str(value, default=''):
        """å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç†Noneã€NaNç­‰æƒ…å†µ"""
        if value is None:
            return default
        if pd.isna(value):
            return default
        value_str = str(value).strip()
        # æ£€æŸ¥æ˜¯å¦ä¸º'nan'ã€'None'ç­‰å­—ç¬¦ä¸²
        if value_str.lower() in ['nan', 'none', '']:
            return default
        return value_str

    # æ„å»ºåˆ†ç»„é”®ï¼šçœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€æ‹›ç”Ÿç±»å‹ã€å±‚æ¬¡ã€ä¸“ä¸šç»„ä»£ç 
    # å¦‚æœä¸“ä¸šç»„ä»£ç ä¸ºç©ºï¼Œåˆ™ä¸åŒ…å«åœ¨åˆ†ç»„é”®ä¸­
    def get_group_key(item):
        province = safe_str(item.get('çœä»½', ''))
        school = safe_str(item.get('å­¦æ ¡', ''))
        subject = safe_str(item.get('ç§‘ç±»', ''))
        batch = safe_str(item.get('æ‰¹æ¬¡', ''))
        recruit_type = safe_str(item.get('æ‹›ç”Ÿç±»å‹', ''))
        level = safe_str(item.get('å±‚æ¬¡', ''))
        group_code = safe_str(item.get('ä¸“ä¸šç»„ä»£ç ', ''))

        # å¦‚æœä¸“ä¸šç»„ä»£ç ä¸ºç©ºæˆ–åªæœ‰^ï¼Œåˆ™ä¸åŒ…å«åœ¨åˆ†ç»„é”®ä¸­
        if not group_code or group_code == '^' or group_code == '':
            return (province, school, subject, batch, recruit_type, level)
        else:
            return (province, school, subject, batch, recruit_type, level, group_code)

    # æŒ‰åˆ†ç»„é”®åˆ†ç»„
    grouped_data = {}
    for item in conversion_data:
        key = get_group_key(item)
        if key not in grouped_data:
            grouped_data[key] = []
        grouped_data[key].append(item)

    # è½¬æ¢ä¸ºé™¢æ ¡åˆ†æ ¼å¼
    college_score_data = []
    for key, items in grouped_data.items():
        # å–ç¬¬ä¸€æ¡è®°å½•ä½œä¸ºåŸºç¡€æ•°æ®
        base_item = items[0]

        # è®¡ç®—æ‹›ç”Ÿäººæ•°æ€»å’Œ
        total_recruit_num = 0
        for item in items:
            recruit_num = item.get('æ‹›ç”Ÿäººæ•°', '') or ''
            if recruit_num and not pd.isna(recruit_num):
                try:
                    total_recruit_num += float(str(recruit_num))
                except:
                    pass

        # å¤„ç†ä¸“ä¸šç»„ä»£ç ï¼šå¦‚æœä¸ºç©ºæˆ–åªæœ‰^ï¼Œåˆ™è®¾ä¸ºç©ºå­—ç¬¦ä¸²
        group_code = safe_str(base_item.get('ä¸“ä¸šç»„ä»£ç ', '')).lstrip('^')
        if not group_code or group_code == '^':
            group_code = ''

        # å¤„ç†é™¢æ ¡æ‹›ç”Ÿä»£ç ï¼šå»é™¤å¼€å¤´çš„^ç¬¦å·
        recruit_code = safe_str(base_item.get('æ‹›ç”Ÿä»£ç ', '')).lstrip('^')

        # å¤„ç†æ‹›ç”Ÿäººæ•°ï¼šä¿æŒä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
        recruit_num_str = str(int(total_recruit_num)) if total_recruit_num > 0 else ''

        # æ„å»ºé™¢æ ¡åˆ†è®°å½•
        college_record = {
            'å­¦æ ¡åç§°': safe_str(base_item.get('å­¦æ ¡', '')),
            'çœä»½': safe_str(base_item.get('çœä»½', '')),
            'æ‹›ç”Ÿç±»åˆ«': safe_str(base_item.get('ç§‘ç±»', '')),
            'æ‹›ç”Ÿæ‰¹æ¬¡': safe_str(base_item.get('æ‰¹æ¬¡', '')),
            'æ‹›ç”Ÿç±»å‹': safe_str(base_item.get('æ‹›ç”Ÿç±»å‹', '')),
            'é€‰æµ‹ç­‰çº§': '',
            'æœ€é«˜åˆ†': '',
            'æœ€ä½åˆ†': '',
            'å¹³å‡åˆ†': '',
            'æœ€é«˜ä½æ¬¡': '',
            'æœ€ä½ä½æ¬¡': '',
            'å¹³å‡ä½æ¬¡': '',
            'å½•å–äººæ•°': '',
            'æ‹›ç”Ÿäººæ•°': recruit_num_str,
            'æ•°æ®æ¥æº': safe_str(base_item.get('æ•°æ®æ¥æº', '')),
            'çœæ§çº¿ç§‘ç±»': '',
            'çœæ§çº¿æ‰¹æ¬¡': '',
            'çœæ§çº¿å¤‡æ³¨': '',
            'ä¸“ä¸šç»„ä»£ç ': group_code,
            'é¦–é€‰ç§‘ç›®': '',
            'é™¢æ ¡æ‹›ç”Ÿä»£ç ': recruit_code
        }

        # å¤„ç†é¦–é€‰ç§‘ç›®ï¼šåªæœ‰æ‹›ç”Ÿç±»åˆ«ä¸ºç‰©ç†ç±»/å†å²ç±»æ—¶æ‰å¡«å…¥
        category = college_record['æ‹›ç”Ÿç±»åˆ«']
        if 'ç‰©ç†ç±»' in category or category == 'ç‰©ç†':
            college_record['é¦–é€‰ç§‘ç›®'] = 'ç‰©ç†'
        elif 'å†å²ç±»' in category or category == 'å†å²':
            college_record['é¦–é€‰ç§‘ç›®'] = 'å†å²'

        college_score_data.append(college_record)

    return college_score_data


def export_college_score_data_to_excel(college_score_data, conversion_data, output_path):
    """å¯¼å‡ºé™¢æ ¡åˆ†æ ¼å¼çš„Excelæ–‡ä»¶"""
    # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
    remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    åŒ—äº¬ã€å¤©æ´¥ã€è¾½å®ã€ä¸Šæµ·ã€å±±ä¸œã€å¹¿ä¸œã€æµ·å—é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼ˆæœ€å¤šä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
5.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—
6.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
7.é¦–é€‰ç§‘ç›®ï¼šæ–°å…«çœå¿…å¡«ï¼Œåªèƒ½å¡«å†™ï¼ˆå†å²æˆ–ç‰©ç†ï¼‰"""

    # åˆ›å»ºå·¥ä½œç°¿
    wb = openpyxl.Workbook()
    ws = wb.active

    # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
    ws.merge_cells('A1:U1')
    ws['A1'] = remark_text
    ws['A1'].alignment = Alignment(wrap_text=True, vertical='top')
    # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º220ç£…
    ws.row_dimensions[1].height = 220

    # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=å¹´ä»½ï¼ŒC2="1"ï¼ŒD2="æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰"
    ws['A2'] = 'æ‹›ç”Ÿå¹´'
    # ä»conversion_dataä¸­æå–å¹´ä»½
    year_value = ''
    if conversion_data and len(conversion_data) > 0:
        year_value = conversion_data[0].get('å¹´ä»½', '') or ''
        if year_value:
            year_value = str(year_value).strip()

    # B2è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼
    ws['B2'] = year_value
    ws['B2'].number_format = numbers.FORMAT_TEXT
    ws['C2'] = 1
    ws['D2'] = 'æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰'

    # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
    headers = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§',
               'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡',
               'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨',
               'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ']
    for col_idx, header in enumerate(headers, start=1):
        ws.cell(row=3, column=col_idx, value=header)

    # æ•°æ®è¡Œï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
    for row_idx, row_data in enumerate(college_score_data, start=4):
        for col_idx, header in enumerate(headers, start=1):
            value = row_data.get(header, '')

            # å¤„ç†ç©ºå€¼ï¼šå°†Noneã€NaNã€'nan'å­—ç¬¦ä¸²ç­‰è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²
            if value is None or pd.isna(value):
                value = ''
            elif isinstance(value, str):
                # æ£€æŸ¥æ˜¯å¦ä¸º'nan'ã€'None'ç­‰å­—ç¬¦ä¸²
                if value.lower() in ['nan', 'none']:
                    value = ''

            cell = ws.cell(row=row_idx, column=col_idx, value=value)

            # è®¾ç½®æ–‡æœ¬æ ¼å¼çš„åˆ—ï¼šæ‹›ç”Ÿäººæ•°ã€ä¸“ä¸šç»„ä»£ç ã€é™¢æ ¡æ‹›ç”Ÿä»£ç 
            # è¿™äº›åˆ—éœ€è¦ä¿æŒæ–‡æœ¬æ ¼å¼ï¼Œå³ä½¿å†…å®¹å¼€å¤´ä¸º0ä¹Ÿä¸èƒ½æŠ¹æ‰
            if header == 'ä¸“ä¸šç»„ä»£ç ' or header == 'é™¢æ ¡æ‹›ç”Ÿä»£ç ' or header == 'æ‹›ç”Ÿäººæ•°':
                # ç¡®ä¿å€¼ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼
                if value is not None and value != '':
                    cell.value = str(value)
                else:
                    cell.value = ''  # ç¡®ä¿ç©ºå€¼å†™å…¥ä¸ºç©ºå­—ç¬¦ä¸²
                cell.number_format = numbers.FORMAT_TEXT

    wb.save(output_path)


def export_converted_data_to_excel(data, conversion_data, output_path):
    """å¯¼å‡ºè½¬æ¢åçš„æ•°æ®ä¸ºExcelï¼ˆä¿æŒä¸HTMLä¸­ç›¸åŒçš„æ ¼å¼ï¼‰"""
    from datetime import datetime

    # åˆ›å»ºå·¥ä½œç°¿
    wb = openpyxl.Workbook()
    ws = wb.active

    # ç¬¬1è¡Œï¼šå¤‡æ³¨ï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
    remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æ‹›ç”Ÿäººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
5.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼Œä¿ç•™å°æ•°åä¸¤ä½ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
6.ä¸€çº§å±‚æ¬¡ï¼šé™å®š"æœ¬ç§‘ã€ä¸“ç§‘ï¼ˆé«˜èŒï¼‰"ï¼Œè¯¥éƒ¨åˆ†ä¸ºæ‹›ç”Ÿä¸“ä¸šå¯¹åº”çš„ä¸“ä¸šå±‚æ¬¡
7.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—;
8.æ•°æ®æ¥æºï¼šå¿…é¡»é™å®šâ€”â€”å®˜æ–¹è€ƒè¯•é™¢ã€å¤§çº¢æœ¬æ•°æ®ã€å­¦æ ¡å®˜ç½‘ã€é”€å”®ã€æŠ“å–ã€åœ£è¾¾ä¿¡ã€ä¼˜å¿—æ„¿ã€å­¦ä¸šæ¡¥
9.é€‰ç§‘è¦æ±‚ï¼šä¸é™ç§‘ç›®ä¸“ä¸šç»„;å¤šé—¨é€‰è€ƒ;å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ
10.é€‰ç§‘ç§‘ç›®å¿…é¡»æ˜¯ç§‘ç›®çš„ç®€å†™ï¼ˆç‰©ã€åŒ–ã€ç”Ÿã€å†ã€åœ°ã€æ”¿ã€æŠ€ï¼‰

11.2020åŒ—äº¬ã€æµ·å—ï¼Œ17-19ä¸Šæµ·ä»…é™åˆ¶æœ¬ç§‘ä¸“ä¸šç»„ä»£ç å¿…å¡«
12.æ–°å…«çœé¦–é€‰ç§‘ç›®å¿…é¡»é€‰æ‹©ï¼ˆç‰©ç†æˆ–å†å²ï¼‰
13.åˆ†æ•°åŒºé—´ä»…é™åŒ—äº¬"""

    ws.merge_cells('A1:Y1')
    ws['A1'] = remark_text
    ws['A1'].alignment = Alignment(wrap_text=True, vertical='top')
    ws.row_dimensions[1].height = 220

    # ç¬¬2è¡Œï¼šæ‹›ç”Ÿå¹´ä»½
    admission_year = ''
    if conversion_data and len(conversion_data) > 0 and conversion_data[0].get('å¹´ä»½'):
        admission_year = conversion_data[0]['å¹´ä»½']
    ws['A2'] = 'æ‹›ç”Ÿå¹´ä»½'
    ws['B2'] = admission_year

    # ç¬¬3è¡Œï¼šè¡¨å¤´
    headers = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰',
        'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†',
        'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰',
        'æ•°æ®æ¥æº', 'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®',
        'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†æ•°åŒºé—´ä½', 'æœ€ä½åˆ†æ•°åŒºé—´é«˜',
        'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
    ]
    for col_idx, header in enumerate(headers, start=1):
        ws.cell(row=3, column=col_idx, value=header)

    # æ•°æ®è¡Œ
    for row_idx, row_data in enumerate(data, start=4):
        for col_idx, header in enumerate(headers, start=1):
            value = row_data.get(header, '')
            cell = ws.cell(row=row_idx, column=col_idx, value=value)
            # è®¾ç½®ä»£ç åˆ—ä¸ºæ–‡æœ¬æ ¼å¼
            if header in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                cell.number_format = numbers.FORMAT_TEXT

    # è®¾ç½®åˆ—å®½
    for col_idx in range(1, len(headers) + 1):
        ws.column_dimensions[openpyxl.utils.get_column_letter(col_idx)].width = 9.36

    wb.save(output_path)


# ============================
# Streamlité¡µé¢å¸ƒå±€
# ============================
# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š æ•°æ®å¤„ç†å·¥å…·")
st.markdown("---")

# åŠŸèƒ½è¯´æ˜
with st.expander("ğŸ“Œ åŠŸèƒ½è¯´æ˜", expanded=True):
    st.markdown("""
    1. ä¸Šä¼ çš„æ–‡ä»¶ä½¿ç”¨åº“ä¸­ä¸“ä¸šåˆ†ã€é™¢æ ¡åˆ†ã€æ‹›ç”Ÿè®¡åˆ’ã€ä¸€åˆ†ä¸€æ®µçš„æ¨¡æ¿ï¼Œç›´æ¥ä¸Šä¼ å³å¯ï¼Œæ— éœ€åˆ å‡
    2. å¤‡æ³¨æ£€æŸ¥ä¸­ï¼Œæ£€æŸ¥å‡ºæ¥æ‹¬å·æœ‰é—®é¢˜çš„å†…å®¹è¿˜éœ€è¦è‡ªå·±å†è¿‡ä¸€éï¼›æ•´ä¸ªæ–‡ä»¶çš„å¤‡æ³¨éœ€è¦å¤§æ¦‚çœ‹çœ‹æœ‰æ²¡æœ‰é”™åˆ«å­—
    3. æ ¡éªŒä¸€åˆ†ä¸€æ®µæ—¶ï¼Œå†…å®¹ä¸èƒ½ä¸ºæ–‡æœ¬æ ¼å¼
    4. ä½¿ç”¨ä¸“ä¸šç»„ä»£ç åŒ¹é…æ—¶ï¼Œä¸¤ä»½æ–‡ä»¶ä¸­çš„â€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹â€è¿™äº›å­—æ®µéœ€è¦ä¿æŒä¸€è‡´
    """)

# æ›´æ–°æ—¥å¿—å¯¹è¯æ¡†
with st.expander("ğŸ“¢ ç‰ˆæœ¬æ›´æ–°ï¼ˆ2026.1.27æ›´æ–°ï¼‰ï¼ˆå¿…çœ‹ï¼ï¼‰", expanded=False):
    st.markdown("""
    ### 2026.1.27æ›´æ–°
    â€¢ ä¿®æ”¹äº†ä¸“ä¸šåˆ†åŒ¹é…é€»è¾‘ï¼ˆâ€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡â€ï¼‰ï¼Œé‡å¤å­—æ®µåŠæœªåŒ¹é…åˆ°çš„å†…å®¹éœ€è¦æ‰‹åŠ¨è¡¥å……
    â€¢ ä¿®æ”¹äº†æ‹›ç”Ÿè®¡åˆ’æ•°æ®å¯¹æ¯”é€»è¾‘ï¼ˆéœ€æ£€æŸ¥æ— ä¸“ä¸šç»„ä»£ç çš„çœä»½çš„é€‰ç§‘è¦æ±‚ï¼‰

    ### å†å²æ›´æ–°

    #### 2025.4.14æ›´æ–°
    â€¢ æ‹›ç”Ÿä»£ç å’Œä¸“ä¸šä»£ç ä¿æŒæ–‡æœ¬æ ¼å¼  
    â€¢ å¢åŠ åŠŸèƒ½è¯´æ˜  
    â€¢ ä¼˜åŒ–å·¥å…·ç•Œé¢  

    #### 2025.4.16æ›´æ–°
    â€¢ ä¼˜åŒ–äº†é™¢æ ¡åˆ†æå–å¤„ç†é€»è¾‘  

    #### 2025.5.22æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†æå–ä¸­å½•å–äººæ•°çš„å¤„ç†é€»è¾‘ï¼ˆå»ºè®®è¿›è¡ŒæŠ½æŸ¥ï¼‰  
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†æœ€é«˜åˆ†ã€å¹³å‡åˆ†ã€æœ€ä½åˆ†çš„æ ¡éªŒï¼Œä¼šåœ¨æœ€ååŠ ä¸€åˆ—æ ¡éªŒç»“æœ  

    #### 2025.5.23æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†å­¦æ ¡åç§°å’Œæ‹›ç”Ÿä¸“ä¸šçš„åŒ¹é…  

    #### 2025.5.27æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­ï¼Œå¢åŠ äº†"æ‹›ç”Ÿç§‘ç±»"ã€"é¦–é€‰ç§‘ç›®"ã€"é€‰ç§‘è¦æ±‚"ï¼Œ"æ¬¡é€‰ç§‘ç›®"çš„å¤„ç†  
      - å­¦ä¸šæ¡¥æä¾›çš„"3+1+2"çœä»½çš„æ‹›ç”Ÿç§‘ç±»ä¸º"ç‰©ç†"ã€"å†å²"ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†çš„"ç‰©ç†ç±»"ã€"å†å²ç±»"  
      - "3+1+2"çœä»½çš„é¦–é€‰ç§‘ç›®å¯ä»¥ç›´æ¥æ ¹æ®æ‹›ç”Ÿç§‘ç±»æå–  
      - æ–°å¢äº†é€‰ç§‘è¦æ±‚ã€æ¬¡é€‰ç§‘ç›®çš„å¤„ç†ï¼Œå¯ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ï¼ˆå¤„ç†åçš„æ•°æ®åœ¨æ–‡æ¡£æœ€åå‡ åˆ—ï¼‰  

    #### 2025.5.30æ›´æ–°
    æ–°å¢"ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"  
      - å¯ç›´æ¥æ ¡éªŒåˆ†æ•°ã€ç´¯è®¡äººæ•°  
      - è‡ªåŠ¨è¡¥æ–­ç‚¹  
      - è‡ªåŠ¨å¢åŠ "æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  

    ### 2025.6.6æ›´æ–°
    "ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"ä¼˜åŒ–  
      - è‡ªåŠ¨è¡¥å……"æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  
      - åªæœ‰ç´¯è®¡äººæ•°æ²¡æœ‰äººæ•°æ—¶ï¼Œå¯è®¡ç®—äººæ•°ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ  
      - è¡¥æ–­ç‚¹çš„åˆ†æ•°æ ‡æ³¨é¢œè‰²ï¼Œå¹¶åœ¨åˆ†æ•°å’Œäººæ•°æ ¡éªŒä¸­æ ‡æ³¨"è¡¥æ–­ç‚¹"

    ### 2025.6.12æ›´æ–°
    é™¢æ ¡åˆ†æå–é€»è¾‘æ›´æ–°  
      - æå–æœ€é«˜åˆ†æ”¹ä¸ºå–åŒä¸€ä¸ªâ€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹ï¼ˆ-ä¸“ä¸šç»„ä»£ç ï¼‰â€ä¸‹çš„æœ€é«˜åˆ†

    ### 2025.6.14æ›´æ–°
    ä¸“ä¸šç»„ä»£ç åŒ¹é…åŠŸèƒ½  
      - éœ€è¦ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿å’Œåº“ä¸­æ‹›ç”Ÿè®¡åˆ’å¯¼å‡ºæ¨¡æ¿
      - æŠŠåº“ä¸­å¯¼å‡ºæ‹›ç”Ÿè®¡åˆ’ç±»å‹å°½é‡è¡¥å……å®Œæ•´ï¼Œå¦åˆ™å®¹æ˜“å‡ºé”™
      - åŒ¹é…ç»“æœéœ€è¦æ£€æŸ¥

    ### 2025.7.7æ›´æ–°
    å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æŠ“å–åŠŸèƒ½  
      - æŠ“å–å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡
      - å¦‚æœæŠ“å–åˆ°çš„å›¾ç‰‡æ¯”è¾ƒå¤šï¼Œâ€œä¸‹è½½PDFâ€çš„å¼¹æ¡†ä¼šå‡ºç°æ¯”è¾ƒæ…¢
      - æ³¨æ„ï¼šåªèƒ½æŠ“å–é™æ€é¡µé¢çš„å›¾ç‰‡ï¼ŒåŠ¨æ€é¡µé¢å’Œæœ‰é™åˆ¶çš„ç½‘é¡µæ— æ³•æŠ“å–


    ### 2025.9.26æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†ä¸­æœ€é«˜åˆ†çš„æå–é€»è¾‘  
    â€¢ æ–°å¢äº†è‰ºä½“ç±»é™¢æ ¡åˆ†æå–åŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ è‰ºä½“ç±»ä¸“ä¸šåˆ†æ¨¡æ¿ï¼ˆå¯æŠŠç‰¹æ®Šç±»å‹<å¦‚ï¼šä¸­å¤–åˆä½œåŠå­¦>çš„å¤‡æ³¨åœ¨ä¸“ä¸šåˆ†ä¸­æ”¾åˆ°ä¸“ä¸šæ–¹å‘å†æå–ï¼‰


    """)

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
    [
        "é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰",
        "é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰",
        "å­¦ä¸šæ¡¥æ•°æ®å¤„ç†",
        "ä¸€åˆ†ä¸€æ®µæ ¡éªŒ",
        "ä¸“ä¸šç»„ä»£ç åŒ¹é…",
        "å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–",
        "æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹"
    ]
)

# ====================== é™¢æ ¡åˆ†æå– ======================
with tab1:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="score_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_score_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_score_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰ ======================
with tab2:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file_new = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="new_score_file")

    if uploaded_file_new is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file_new.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_new_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_new_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file_new.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # è°ƒç”¨æ–°æ¨¡æ¿å¤„ç†å‡½æ•°
                    if percent_complete == 100:
                        output_path = process_new_template_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†ï¼ˆè‰ºä½“ç±»ï¼‰æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== å­¦ä¸šæ¡¥æ•°æ®å¤„ç† ======================
with tab3:
    st.header("å­¦ä¸šæ¡¥æ•°æ®å¤„ç†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="remarks_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_remarks"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_remarks.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())


                # è¿›åº¦å›è°ƒå‡½æ•°
                def update_progress(current, total):
                    percent = int((current / total) * 100)
                    progress_bar.progress(percent)
                    status_text.text(f"å¤„ç†ä¸­... {percent}%")


                # å¤„ç†æ–‡ä»¶
                output_path = process_remarks_file(temp_file, progress_callback=update_progress)

                # å¤„ç†å®Œæˆ
                progress_bar.progress(100)
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸€åˆ†ä¸€æ®µæ ¡éªŒ ======================
with tab4:
    st.header("ä¸€åˆ†ä¸€æ®µæ ¡éªŒ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="segmentation_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_segmentation"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "ä¸€åˆ†ä¸€æ®µ.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_segmentation_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_segmentation_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()

                b64 = base64.b64encode(bytes_data).decode()

                # ä» output_path æå–åŸæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                base_name = os.path.splitext(os.path.basename(output_path))[0]

                # æ‹¼æ¥æ–°æ–‡ä»¶å
                new_filename = f"{base_name}.xlsx"

                # æ„é€ ä¸‹è½½é“¾æ¥
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="{new_filename}">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'

                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸“ä¸šç»„ä»£ç åŒ¹é… ======================
with tab5:
    st.header("ä¸“ä¸šç»„ä»£ç åŒ¹é…")

    # åˆå§‹åŒ–session state
    if 'match_result_df' not in st.session_state:
        st.session_state.match_result_df = None
    if 'manual_fill_records' not in st.session_state:
        st.session_state.manual_fill_records = []
    if 'manual_selections' not in st.session_state:
        st.session_state.manual_selections = {}
    if 'temp_fileA_path' not in st.session_state:
        st.session_state.temp_fileA_path = None
    if 'temp_fileB_path' not in st.session_state:
        st.session_state.temp_fileB_path = None
    if 'fileA_headers' not in st.session_state:
        st.session_state.fileA_headers = None
    if 'fileB_year' not in st.session_state:
        st.session_state.fileB_year = None

    uploaded_fileA = st.file_uploader("ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿", type=["xls", "xlsx"], key="fileA")
    uploaded_fileB = st.file_uploader("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ•°æ®å¯¼å‡ºæ–‡ä»¶", type=["xls", "xlsx"], key="fileB")

    if uploaded_fileA and uploaded_fileB:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶ï¼š{uploaded_fileA.name} å’Œ {uploaded_fileB.name}")

        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("ç­‰å¾…å¼€å§‹å¤„ç†...")

        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="start_match"):
            try:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_fileA = "tempA.xlsx"
                temp_fileB = "tempB.xlsx"
                with open(temp_fileA, "wb") as f:
                    f.write(uploaded_fileA.getbuffer())
                with open(temp_fileB, "wb") as f:
                    f.write(uploaded_fileB.getbuffer())

                st.session_state.temp_fileA_path = temp_fileA
                st.session_state.temp_fileB_path = temp_fileB

                status_text.text("è¯»å–æ–‡ä»¶...")
                progress_bar.progress(10)

                # è¯»å–æ–‡ä»¶Açš„æ ‡é¢˜è¡Œï¼ˆç¬¬3è¡Œï¼‰
                wbA = openpyxl.load_workbook(temp_fileA, data_only=True)
                wsA = wbA.active
                headers_row = []
                # è¯»å–ç¬¬3è¡Œçš„æ‰€æœ‰éç©ºå•å…ƒæ ¼
                max_col = wsA.max_column
                for col_idx in range(1, max_col + 1):
                    cell_value = wsA.cell(row=3, column=col_idx).value
                    headers_row.append(cell_value if cell_value is not None else '')
                wbA.close()
                st.session_state.fileA_headers = headers_row

                # è¯»å–æ–‡ä»¶Bçš„å¹´ä»½ï¼ˆä»Aåˆ—å¹´ä»½å­—æ®µè¯»å–ï¼‰
                year_value = ''
                try:
                    # å…ˆå°è¯•ä»æ•°æ®ä¸­è¯»å–å¹´ä»½å­—æ®µï¼ˆAåˆ—ï¼‰
                    dfB_temp = pd.read_excel(temp_fileB)
                    if 'å¹´ä»½' in dfB_temp.columns:
                        year_values = dfB_temp['å¹´ä»½'].dropna()
                        if len(year_values) > 0:
                            year_value = year_values.iloc[0]
                    # å¦‚æœå¹´ä»½å­—æ®µä¸å­˜åœ¨ï¼Œå°è¯•ä»Aåˆ—ç¬¬ä¸€è¡Œæ•°æ®è¯»å–
                    elif len(dfB_temp) > 0:
                        # å°è¯•è¯»å–Aåˆ—çš„ç¬¬ä¸€è¡Œæ•°æ®
                        first_col = dfB_temp.iloc[:, 0]
                        if len(first_col) > 0:
                            first_value = first_col.iloc[0]
                            # å¦‚æœç¬¬ä¸€è¡Œæ•°æ®çœ‹èµ·æ¥åƒå¹´ä»½ï¼ˆ4ä½æ•°å­—ï¼‰
                            if first_value and str(first_value).strip().isdigit() and len(str(first_value).strip()) == 4:
                                year_value = str(first_value).strip()
                    # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»Excelæ–‡ä»¶çš„Aåˆ—è¯»å–
                    if not year_value or year_value == '':
                        wbB = openpyxl.load_workbook(temp_fileB, data_only=True)
                        wsB = wbB.active
                        # ä»Aåˆ—æŸ¥æ‰¾å¹´ä»½ï¼ˆè·³è¿‡å¯èƒ½çš„æ ‡é¢˜è¡Œï¼Œä»ç¬¬2è¡Œå¼€å§‹æŸ¥æ‰¾ï¼‰
                        for row_idx in range(2, min(wsB.max_row + 1, 100)):  # æœ€å¤šæŸ¥æ‰¾100è¡Œ
                            cell_value = wsB[f'A{row_idx}'].value
                            if cell_value:
                                cell_str = str(cell_value).strip()
                                # å¦‚æœçœ‹èµ·æ¥åƒå¹´ä»½ï¼ˆ4ä½æ•°å­—ï¼‰
                                if cell_str.isdigit() and len(cell_str) == 4:
                                    year_value = cell_str
                                    break
                        wbB.close()
                    if year_value is not None:
                        year_value = str(year_value).strip()
                    else:
                        year_value = ''
                except Exception as e:
                    logging.warning(f"è¯»å–æ–‡ä»¶Bå¹´ä»½å¤±è´¥ï¼š{e}")
                    year_value = ''
                st.session_state.fileB_year = year_value

                dfA = pd.read_excel(temp_fileA, header=2)
                dfB = pd.read_excel(temp_fileB)

                status_text.text("å¼€å§‹å¤„ç†æ•°æ®...")
                progress_bar.progress(30)

                result_df, manual_fill_records = process_data(dfA, dfB)

                st.session_state.match_result_df = result_df.copy()
                st.session_state.manual_fill_records = manual_fill_records
                st.session_state.manual_selections = {}

                status_text.text("å¤„ç†å®Œæˆï¼")
                progress_bar.progress(100)

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                total_count = len(result_df)
                matched_count = len(result_df[result_df["ä¸“ä¸šç»„ä»£ç "].notna() & (result_df["ä¸“ä¸šç»„ä»£ç "] != "")])
                manual_count = len(manual_fill_records)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", total_count)
                with col2:
                    st.metric("è‡ªåŠ¨åŒ¹é…æˆåŠŸ", matched_count)
                with col3:
                    st.metric("éœ€è¦æ‰‹åŠ¨è¡¥å……", manual_count, delta=f"{manual_count}æ¡")

                if manual_count > 0:
                    st.warning(f"âš ï¸ å‘ç° {manual_count} æ¡è®°å½•éœ€è¦æ‰‹åŠ¨è¡¥å……ä¸“ä¸šç»„ä»£ç ")

            except Exception as e:
                st.error(f"å¤„ç†é”™è¯¯ï¼š{e}")
                import traceback
                st.error(traceback.format_exc())

        # æ˜¾ç¤ºæ‰‹åŠ¨è¡¥å……ç•Œé¢ï¼ˆå¼¹æ¡†å½¢å¼ï¼‰
        if st.session_state.match_result_df is not None and len(st.session_state.manual_fill_records) > 0:
            st.markdown("---")
            st.subheader("ğŸ“ æ‰‹åŠ¨è¡¥å……ä¸“ä¸šç»„ä»£ç ")
            
            # çœä»½ç­›é€‰åŠŸèƒ½
            all_provinces = sorted(set([r.get("çœä»½", "") for r in st.session_state.manual_fill_records if r.get("çœä»½", "")]))
            all_provinces = [p for p in all_provinces if p]  # è¿‡æ»¤ç©ºå€¼
            
            # åˆå§‹åŒ–çœä»½ç­›é€‰
            if 'selected_province' not in st.session_state:
                st.session_state.selected_province = "å…¨éƒ¨"
            
            # çœä»½ç­›é€‰æ¡†
            col1, col2 = st.columns([1, 3])
            with col1:
                selected_province = st.selectbox(
                    "ç­›é€‰çœä»½",
                    ["å…¨éƒ¨"] + all_provinces,
                    index=0 if st.session_state.selected_province == "å…¨éƒ¨" else (all_provinces.index(st.session_state.selected_province) + 1 if st.session_state.selected_province in all_provinces else 0),
                    key="province_filter"
                )
                # å¦‚æœçœä»½ç­›é€‰æ”¹å˜ï¼Œé‡ç½®å½“å‰ç´¢å¼•
                if selected_province != st.session_state.selected_province:
                    st.session_state.current_record_idx = 0
                st.session_state.selected_province = selected_province
            
            # æ ¹æ®çœä»½ç­›é€‰è®°å½•ï¼ˆç¡®ä¿ä¿ç•™æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬å€™é€‰è®°å½•ï¼‰
            if selected_province == "å…¨éƒ¨":
                filtered_records = st.session_state.manual_fill_records
            else:
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ç­›é€‰ï¼Œç¡®ä¿ä¿ç•™æ‰€æœ‰å­—æ®µ
                filtered_records = []
                for r in st.session_state.manual_fill_records:
                    if r.get("çœä»½", "") == selected_province:
                        # ç¡®ä¿ä¿ç•™å®Œæ•´çš„è®°å½•ï¼ŒåŒ…æ‹¬å€™é€‰è®°å½•å­—æ®µ
                        filtered_records.append(r)
            
            # æ˜¾ç¤ºç­›é€‰åçš„ç»Ÿè®¡ä¿¡æ¯
            with col2:
                st.info(f"**ç­›é€‰ç»“æœï¼š** å…± {len(filtered_records)} æ¡è®°å½•éœ€è¦æ‰‹åŠ¨è¡¥å……ï¼ˆæ€»è®°å½•æ•°ï¼š{len(st.session_state.manual_fill_records)}ï¼‰")
            
            if len(filtered_records) == 0:
                st.warning(f"âš ï¸ çœä»½ã€Œ{selected_province}ã€æ²¡æœ‰éœ€è¦æ‰‹åŠ¨è¡¥å……çš„è®°å½•")
                st.stop()
            
            # åˆå§‹åŒ–å½“å‰å¤„ç†çš„è®°å½•ç´¢å¼•ï¼ˆåŸºäºç­›é€‰åçš„è®°å½•ï¼‰
            if 'current_record_idx' not in st.session_state:
                st.session_state.current_record_idx = 0
            
            # å¦‚æœå½“å‰ç´¢å¼•è¶…å‡ºç­›é€‰åçš„è®°å½•èŒƒå›´ï¼Œé‡ç½®ä¸º0
            if st.session_state.current_record_idx >= len(filtered_records):
                st.session_state.current_record_idx = 0
            
            total_records = len(filtered_records)
            current_record = filtered_records[st.session_state.current_record_idx]
            idx = current_record["ç´¢å¼•"]
            key = f"manual_select_{idx}"
            
            # ç¡®ä¿ä»åŸå§‹è®°å½•ä¸­è·å–å®Œæ•´çš„å€™é€‰è®°å½•ä¿¡æ¯
            # å¦‚æœç­›é€‰åçš„è®°å½•ä¸­å€™é€‰è®°å½•ä¸¢å¤±æˆ–ä¸ºç©ºï¼Œä»åŸå§‹è®°å½•ä¸­è·å–
            candidate_records_from_filtered = current_record.get("å€™é€‰è®°å½•")
            if candidate_records_from_filtered is None or (isinstance(candidate_records_from_filtered, list) and len(candidate_records_from_filtered) == 0):
                # ä»åŸå§‹è®°å½•ä¸­æŸ¥æ‰¾å¯¹åº”çš„è®°å½•
                original_record = next((r for r in st.session_state.manual_fill_records if r.get("ç´¢å¼•") == idx), None)
                if original_record:
                    original_candidates = original_record.get("å€™é€‰è®°å½•")
                    if original_candidates is not None:
                        current_record["å€™é€‰è®°å½•"] = original_candidates
                    else:
                        current_record["å€™é€‰è®°å½•"] = []
                else:
                    current_record["å€™é€‰è®°å½•"] = []
            
            # æ˜¾ç¤ºè¿›åº¦
            if selected_province == "å…¨éƒ¨":
                progress_text = f"å¤„ç†è¿›åº¦ï¼š{st.session_state.current_record_idx + 1} / {total_records}"
            else:
                progress_text = f"å¤„ç†è¿›åº¦ï¼š{st.session_state.current_record_idx + 1} / {total_records}ï¼ˆçœä»½ï¼š{selected_province}ï¼‰"
            st.progress((st.session_state.current_record_idx + 1) / total_records, text=progress_text)
            
            # å¼¹æ¡†å½¢å¼æ˜¾ç¤ºå½“å‰è®°å½•
            with st.expander(f"ğŸ“‹ è®°å½• {st.session_state.current_record_idx + 1}ï¼š{current_record['å­¦æ ¡åç§°']} - {current_record['æ‹›ç”Ÿä¸“ä¸š']}", expanded=True):
                st.markdown("### å½“å‰è®°å½•ä¿¡æ¯ï¼ˆä¸“ä¸šåˆ†æ–‡ä»¶ï¼‰")
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**å­¦æ ¡åç§°ï¼š** {current_record['å­¦æ ¡åç§°']}")
                    st.write(f"**çœä»½ï¼š** {current_record['çœä»½']}")
                    st.write(f"**æ‹›ç”Ÿä¸“ä¸šï¼š** {current_record['æ‹›ç”Ÿä¸“ä¸š']}")
                    st.write(f"**ä¸€çº§å±‚æ¬¡ï¼š** {current_record['ä¸€çº§å±‚æ¬¡']}")
                with col2:
                    st.write(f"**æ‹›ç”Ÿç§‘ç±»ï¼š** {current_record['æ‹›ç”Ÿç§‘ç±»']}")
                    st.write(f"**æ‹›ç”Ÿæ‰¹æ¬¡ï¼š** {current_record['æ‹›ç”Ÿæ‰¹æ¬¡']}")
                    st.write(f"**æ‹›ç”Ÿç±»å‹ï¼š** {current_record['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰']}")
                    # æ˜¾ç¤ºå½“å‰å·²é€‰æ‹©çš„å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
                    current_value = st.session_state.manual_selections.get(key, "")
                    if current_value:
                        st.success(f"**å·²é€‰æ‹©ï¼š** {current_value}")
                
                # æ˜¾ç¤ºä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰å­—æ®µ
                if current_record.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"):
                    st.markdown("**ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰ï¼š**")
                    st.info(current_record.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", ""))
                
                st.markdown("---")
                st.markdown("### æ‹›ç”Ÿè®¡åˆ’ä¸­çš„å€™é€‰è®°å½•")
                
                # æ˜¾ç¤ºå€™é€‰è®°å½•
                candidate_records = current_record.get("å€™é€‰è®°å½•")
                # å¤„ç†Noneã€ç©ºåˆ—è¡¨ç­‰æƒ…å†µ
                if candidate_records is None:
                    candidate_records = []
                
                if candidate_records and len(candidate_records) > 0:
                    # æ˜¾ç¤ºå€™é€‰è®°å½•çš„è¯¦ç»†ä¿¡æ¯è¡¨æ ¼
                    st.markdown("**å€™é€‰è®°å½•è¯¦æƒ…ï¼š**")
                    candidate_df = pd.DataFrame(candidate_records)
                    # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œä¸“ä¸šç»„ä»£ç æ”¾åœ¨æœ€å‰é¢
                    if 'ä¸“ä¸šç»„ä»£ç ' in candidate_df.columns:
                        cols = ['ä¸“ä¸šç»„ä»£ç '] + [c for c in candidate_df.columns if c != 'ä¸“ä¸šç»„ä»£ç ']
                        candidate_df = candidate_df[cols]
                    st.dataframe(candidate_df, use_container_width=True, hide_index=True)
                    
                    # æ„å»ºé€‰é¡¹åˆ—è¡¨ï¼ˆæ˜¾ç¤ºä¸“ä¸šç»„ä»£ç ï¼‰
                    candidate_options = []
                    for i, cand in enumerate(candidate_records):
                        code = cand.get("ä¸“ä¸šç»„ä»£ç ", "")
                        if code and str(code).strip():
                            candidate_options.append(str(code).strip())
                    
                    # å»é‡
                    candidate_options = list(set(candidate_options))
                    
                    if candidate_options:
                        # æ·»åŠ "è¯·é€‰æ‹©"é€‰é¡¹
                        options = ["è¯·é€‰æ‹©"] + candidate_options
                        # è·å–å½“å‰é€‰æ‹©ï¼ˆå¦‚æœæœ‰ï¼‰
                        current_selection = st.session_state.manual_selections.get(key, "è¯·é€‰æ‹©")
                        default_index = 0
                        if current_selection in options:
                            default_index = options.index(current_selection)
                        
                        selected_code = st.selectbox(
                            "é€‰æ‹©ä¸“ä¸šç»„ä»£ç ",
                            options,
                            index=default_index,
                            key=key
                        )
                        
                        if selected_code != "è¯·é€‰æ‹©":
                            st.session_state.manual_selections[key] = selected_code
                        else:
                            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†"è¯·é€‰æ‹©"ï¼Œæ¸…é™¤ä¹‹å‰çš„é€‰æ‹©
                            if key in st.session_state.manual_selections:
                                del st.session_state.manual_selections[key]
                    else:
                        st.warning("âš ï¸ å€™é€‰è®°å½•ä¸­æ²¡æœ‰ä¸“ä¸šç»„ä»£ç ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥")
                        input_key = f"{key}_input"
                        prev_value = st.session_state.get(input_key, "")
                        manual_input = st.text_input(
                            "æ‰‹åŠ¨è¾“å…¥ä¸“ä¸šç»„ä»£ç ",
                            value=prev_value,
                            key=input_key
                        )
                        if manual_input and manual_input.strip():
                            st.session_state.manual_selections[key] = manual_input.strip()
                        elif key in st.session_state.manual_selections:
                            del st.session_state.manual_selections[key]
                else:
                    st.warning("âš ï¸ è¯¥è®°å½•æ²¡æœ‰å€™é€‰è®°å½•ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥")
                    input_key = f"{key}_input"
                    prev_value = st.session_state.get(input_key, "")
                    manual_input = st.text_input(
                        "æ‰‹åŠ¨è¾“å…¥ä¸“ä¸šç»„ä»£ç ",
                        value=prev_value,
                        key=input_key
                    )
                    if manual_input and manual_input.strip():
                        st.session_state.manual_selections[key] = manual_input.strip()
                    elif key in st.session_state.manual_selections:
                        del st.session_state.manual_selections[key]
            
            # å¯¼èˆªæŒ‰é’®
            col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
            with col1:
                if st.button("â®ï¸ ç¬¬ä¸€æ¡", disabled=st.session_state.current_record_idx == 0):
                    st.session_state.current_record_idx = 0
                    st.rerun()
            with col2:
                if st.button("â—€ï¸ ä¸Šä¸€æ¡", disabled=st.session_state.current_record_idx == 0):
                    st.session_state.current_record_idx -= 1
                    st.rerun()
            with col3:
                if st.button("â–¶ï¸ ä¸‹ä¸€æ¡", disabled=st.session_state.current_record_idx >= total_records - 1):
                    st.session_state.current_record_idx += 1
                    st.rerun()
            with col4:
                if st.button("â­ï¸ æœ€åä¸€æ¡", disabled=st.session_state.current_record_idx >= total_records - 1):
                    st.session_state.current_record_idx = total_records - 1
                    st.rerun()
            
            st.markdown("---")
            
            # åº”ç”¨æ‰€æœ‰æ‰‹åŠ¨é€‰æ‹©å¹¶å®Œæˆ
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("âœ… åº”ç”¨å½“å‰é€‰æ‹©å¹¶ç»§ç»­", type="primary", use_container_width=True):
                    # åº”ç”¨å½“å‰è®°å½•çš„é€‰æ‹©
                    selected_code = None
                    if key in st.session_state.manual_selections:
                        selected_code = st.session_state.manual_selections[key]
                    elif f"{key}_input" in st.session_state:
                        input_value = st.session_state[f"{key}_input"]
                        if input_value and input_value.strip():
                            selected_code = input_value.strip()
                    
                    if selected_code and selected_code.strip():
                        updated_df = st.session_state.match_result_df.copy()
                        updated_df.at[idx, "ä¸“ä¸šç»„ä»£ç "] = selected_code.strip()
                        st.session_state.match_result_df = updated_df
                        st.success(f"âœ… å·²åº”ç”¨è®°å½• {st.session_state.current_record_idx + 1} çš„é€‰æ‹©ï¼š{selected_code.strip()}")
                    
                    # ç§»åŠ¨åˆ°ä¸‹ä¸€æ¡
                    if st.session_state.current_record_idx < total_records - 1:
                        st.session_state.current_record_idx += 1
                    st.rerun()
            
            with col2:
                if st.button("âœ… åº”ç”¨æ‰€æœ‰é€‰æ‹©å¹¶å®Œæˆ", type="primary", use_container_width=True):
                    # æ›´æ–°ç»“æœæ•°æ®æ¡†
                    updated_df = st.session_state.match_result_df.copy()
                    applied_count = 0
                    
                    for record in st.session_state.manual_fill_records:
                        idx = record["ç´¢å¼•"]
                        key = f"manual_select_{idx}"
                        input_key = f"{key}_input"
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰é€‰æ‹©
                        selected_code = None
                        
                        # å…ˆæ£€æŸ¥selectboxçš„é€‰æ‹©
                        if key in st.session_state.manual_selections:
                            selected_code = st.session_state.manual_selections[key]
                            if selected_code == "è¯·é€‰æ‹©":
                                selected_code = None
                        elif key in st.session_state:
                            selected_code = st.session_state[key]
                            if selected_code == "è¯·é€‰æ‹©":
                                selected_code = None
                        
                        # å¦‚æœæ²¡æœ‰selectboxé€‰æ‹©ï¼Œæ£€æŸ¥text_input
                        if not selected_code and input_key in st.session_state:
                            input_value = st.session_state[input_key]
                            if input_value and input_value.strip():
                                selected_code = input_value.strip()
                        
                        # åº”ç”¨é€‰æ‹©
                        if selected_code and selected_code.strip():
                            updated_df.at[idx, "ä¸“ä¸šç»„ä»£ç "] = selected_code.strip()
                            applied_count += 1

                    st.session_state.match_result_df = updated_df
                    if applied_count > 0:
                        st.success(f"âœ… å·²åº”ç”¨ {applied_count} æ¡è®°å½•çš„æ‰‹åŠ¨é€‰æ‹©ï¼")
                    else:
                        st.warning("âš ï¸ æ²¡æœ‰åº”ç”¨ä»»ä½•é€‰æ‹©")
                    st.rerun()

        # å¯¼å‡ºç»“æœ
        if st.session_state.match_result_df is not None:
            st.markdown("---")
            st.subheader("ğŸ“¥ å¯¼å‡ºç»“æœ")
            
            # ç§»é™¤ä¸´æ—¶åˆ—
            export_df = st.session_state.match_result_df.drop(columns=["ç»„åˆé”®"], errors='ignore')
            
            # è·å–æ ‡é¢˜å’Œå¹´ä»½
            headers = st.session_state.fileA_headers if st.session_state.fileA_headers else list(export_df.columns)
            year_value = st.session_state.fileB_year if st.session_state.fileB_year else ''
            
            # å¯¼å‡ºç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶
            temp_output_path = "temp_match_result.xlsx"
            try:
                export_match_result_to_excel(export_df, headers, year_value, temp_output_path)
                
                # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
                with open(temp_output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="ä¸“ä¸šç»„ä»£ç åŒ¹é…ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½åŒ¹é…ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_output_path):
                    os.remove(temp_output_path)
            except Exception as e:
                st.error(f"å¯¼å‡ºå¤±è´¥ï¼š{str(e)}")
                import traceback
                st.error(traceback.format_exc())

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶æŒ‰é’®
            if st.button("æ¸…ç†ä¸´æ—¶æ–‡ä»¶", key="cleanup_temp"):
                if st.session_state.temp_fileA_path and os.path.exists(st.session_state.temp_fileA_path):
                    os.remove(st.session_state.temp_fileA_path)
                if st.session_state.temp_fileB_path and os.path.exists(st.session_state.temp_fileB_path):
                    os.remove(st.session_state.temp_fileB_path)
                st.session_state.temp_fileA_path = None
                st.session_state.temp_fileB_path = None
                st.success("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")

    else:
        st.info("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶")

# ====================== tab5ï¼šç½‘é¡µå›¾ç‰‡æå–PDF ======================
with tab6:
    st.header("å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–")

    url = st.text_input("è¯·è¾“å…¥å°±ä¸šè´¨é‡æŠ¥å‘Šç½‘é¡µé“¾æ¥", placeholder="ä¾‹å¦‚ï¼šhttps://www.example.com/report.html")

    if st.button("å¼€å§‹æå–å›¾ç‰‡"):
        if not url:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘é¡µé“¾æ¥")
        else:
            output_folder = tempfile.mkdtemp()
            with st.spinner("æ­£åœ¨æŠ“å–å›¾ç‰‡..."):
                try:
                    image_paths = fetch_images_static(url, output_folder)
                except Exception as e:
                    st.error(f"æŠ“å–å¤±è´¥: {e}")
                    image_paths = []

            if image_paths:
                st.success(f"æˆåŠŸæå–åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

                with st.expander(f"ç‚¹å‡»æŸ¥çœ‹ {len(image_paths)} å¼ å›¾ç‰‡é¢„è§ˆ", expanded=False):
                    cols = st.columns(5)
                    for i, path in enumerate(image_paths):
                        cols[i % 5].image(path, width=120)

                pdf_path = os.path.join(output_folder, "å›¾ç‰‡åˆé›†.pdf")
                if images_to_pdf(image_paths, pdf_path):
                    with open(pdf_path, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è½½åˆæˆPDF", f, file_name="å°±ä¸šè´¨é‡æŠ¥å‘Š.pdf", mime="application/pdf")
                else:
                    st.warning("PDFåˆæˆå¤±è´¥")
            else:
                st.warning("æœªæŠ“å–åˆ°ä»»ä½•å›¾ç‰‡")





# ====================== tab7ï¼šæ‹›ç”Ÿè®¡åˆ’å·¥å…·======================
with tab7:
    st.header("æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ä¸è½¬æ¢å·¥å…·")
    st.markdown("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’ã€ä¸“ä¸šåˆ†å’Œé™¢æ ¡åˆ†æ–‡ä»¶è¿›è¡Œæ¯”å¯¹ï¼Œå¯¼å‡ºæœªåŒ¹é…æ•°æ®ä¸ºä¸“ä¸šåˆ†/é™¢æ ¡åˆ†æ ¼å¼")

    # åˆå§‹åŒ–session state
    if 'plan_data' not in st.session_state:
        st.session_state.plan_data = None
    if 'score_data' not in st.session_state:
        st.session_state.score_data = None
    if 'college_data' not in st.session_state:
        st.session_state.college_data = None
    if 'plan_score_results' not in st.session_state:
        st.session_state.plan_score_results = []
    if 'plan_college_results' not in st.session_state:
        st.session_state.plan_college_results = []

    # å·¥ä½œæµæ­¥éª¤æ˜¾ç¤º
    col1, col2, col3, col4, col5 = st.columns([1, 0.3, 1, 0.3, 1])
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 10px; background: #e3f2fd; border-radius: 10px;">
            <div style="font-size: 24px; font-weight: bold;">1</div>
            <div>ä¸Šä¼ æ–‡ä»¶</div>
        </div>
        """, unsafe_allow_html=True)
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 10px; background: #f5f5f5; border-radius: 10px;">
            <div style="font-size: 24px; font-weight: bold;">2</div>
            <div>æ•°æ®æ¯”å¯¹</div>
        </div>
        """, unsafe_allow_html=True)
    with col5:
        st.markdown("""
        <div style="text-align: center; padding: 10px; background: #f5f5f5; border-radius: 10px;">
            <div style="font-size: 24px; font-weight: bold;">3</div>
            <div>å¯¼å‡ºæœªåŒ¹é…æ•°æ®</div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # å­—æ®µè¯´æ˜
    with st.expander("ğŸ“‹ æ¯”å¯¹å­—æ®µè¯´æ˜", expanded=False):
        st.markdown("""
        **æ¯”å¯¹1ï¼ˆæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†ï¼‰ï¼š** æ£€æŸ¥æ‹›ç”Ÿè®¡åˆ’çš„è®°å½•æ˜¯å¦åœ¨ä¸“ä¸šåˆ†ä¸­å­˜åœ¨
        - åŒ¹é…å­—æ®µï¼šå¹´ä»½ã€çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šã€å±‚æ¬¡ã€ä¸“ä¸šç»„ä»£ç 

        **æ¯”å¯¹2ï¼ˆæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†ï¼‰ï¼š** æ£€æŸ¥æ‹›ç”Ÿè®¡åˆ’çš„è®°å½•æ˜¯å¦åœ¨é™¢æ ¡åˆ†ä¸­å­˜åœ¨
        - åŒ¹é…å­—æ®µï¼šå¹´ä»½ã€çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šç»„ä»£ç 
        """)

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.subheader("æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
        plan_file = st.file_uploader("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶", type=["xlsx", "xls"], key="tab7_plan_file")
        if plan_file is not None:
            try:
                plan_df = pd.read_excel(plan_file, engine='openpyxl')
                st.session_state.plan_data = plan_df
                st.success(f"âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ\næ–‡ä»¶å: {plan_file.name}\nè®°å½•æ•°: {len(plan_df)} æ¡")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    with col2:
        st.subheader("ä¸“ä¸šåˆ†æ–‡ä»¶")
        score_file = st.file_uploader("ä¸Šä¼ ä¸“ä¸šåˆ†æ–‡ä»¶", type=["xlsx", "xls"], key="tab7_score_file")
        if score_file is not None:
            try:
                score_df = pd.read_excel(score_file, engine='openpyxl')
                st.session_state.score_data = score_df
                st.success(f"âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ\næ–‡ä»¶å: {score_file.name}\nè®°å½•æ•°: {len(score_df)} æ¡")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    with col3:
        st.subheader("é™¢æ ¡åˆ†æ–‡ä»¶")
        college_file = st.file_uploader("ä¸Šä¼ é™¢æ ¡åˆ†æ–‡ä»¶", type=["xlsx", "xls"], key="tab7_college_file")
        if college_file is not None:
            try:
                college_df = pd.read_excel(college_file, engine='openpyxl')
                st.session_state.college_data = college_df
                st.success(f"âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ\næ–‡ä»¶å: {college_file.name}\nè®°å½•æ•°: {len(college_df)} æ¡")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    st.markdown("---")

    # æ¯”å¯¹æŒ‰é’®
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
    with col1:
        compare_plan_score_btn = st.button("æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†", type="primary", use_container_width=True)
    with col2:
        compare_plan_college_btn = st.button("æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†", type="primary", use_container_width=True)
    with col3:
        compare_all_btn = st.button("å…¨éƒ¨æ¯”å¯¹", type="primary", use_container_width=True)
    with col4:
        reset_btn = st.button("é‡ç½®", use_container_width=True)

    # æ‰§è¡Œæ¯”å¯¹
    if compare_plan_score_btn:
        if st.session_state.plan_data is None:
            st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
        elif st.session_state.score_data is None:
            st.error("è¯·å…ˆä¸Šä¼ ä¸“ä¸šåˆ†æ–‡ä»¶")
        else:
            with st.spinner("æ­£åœ¨æ¯”å¯¹æ•°æ®..."):
                st.session_state.plan_score_results = compare_plan_vs_score(
                    st.session_state.plan_data, st.session_state.score_data
                )
            st.success("æ¯”å¯¹1å®Œæˆï¼")
            st.balloons()

    if compare_plan_college_btn:
        if st.session_state.plan_data is None:
            st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
        elif st.session_state.college_data is None:
            st.error("è¯·å…ˆä¸Šä¼ é™¢æ ¡åˆ†æ–‡ä»¶")
        else:
            with st.spinner("æ­£åœ¨æ¯”å¯¹æ•°æ®..."):
                st.session_state.plan_college_results = compare_plan_vs_college(
                    st.session_state.plan_data, st.session_state.college_data
                )
            st.success("æ¯”å¯¹2å®Œæˆï¼")
            st.balloons()

    if compare_all_btn:
        comparisons = []
        if st.session_state.plan_data is not None and st.session_state.score_data is not None:
            comparisons.append("æ¯”å¯¹1")
        if st.session_state.plan_data is not None and st.session_state.college_data is not None:
            comparisons.append("æ¯”å¯¹2")

        if len(comparisons) == 0:
            st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªæ–‡ä»¶ä»¥è¿›è¡Œæ¯”å¯¹")
        else:
            with st.spinner("æ­£åœ¨æ‰§è¡Œå…¨éƒ¨æ¯”å¯¹..."):
                if "æ¯”å¯¹1" in comparisons:
                    st.session_state.plan_score_results = compare_plan_vs_score(
                        st.session_state.plan_data, st.session_state.score_data
                    )
                if "æ¯”å¯¹2" in comparisons:
                    st.session_state.plan_college_results = compare_plan_vs_college(
                        st.session_state.plan_data, st.session_state.college_data
                    )
            st.success("å…¨éƒ¨æ¯”å¯¹å®Œæˆï¼")
            st.balloons()

    if reset_btn:
        st.session_state.plan_data = None
        st.session_state.score_data = None
        st.session_state.college_data = None
        st.session_state.plan_score_results = []
        st.session_state.plan_college_results = []
        st.success("é‡ç½®å®Œæˆï¼")
        st.rerun()

    # æ˜¾ç¤ºæ¯”å¯¹ç»“æœ
    if len(st.session_state.plan_score_results) > 0 or len(st.session_state.plan_college_results) > 0:
        st.markdown("---")

        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab_plan_score, tab_plan_college = st.tabs([
            "æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†",
            "æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†"
        ])

        # æ¯”å¯¹1ç»“æœ
        with tab_plan_score:
            if len(st.session_state.plan_score_results) > 0:
                results = st.session_state.plan_score_results
                total = len(results)
                matched = sum(1 for r in results if r['exists'])
                unmatched = total - matched
                rate = (matched / total * 100) if total > 0 else 0

                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", total)
                with col2:
                    st.metric("åŒ¹é…è®°å½•æ•°", matched, delta=f"{rate:.1f}%")
                with col3:
                    st.metric("æœªåŒ¹é…è®°å½•æ•°", unmatched)
                with col4:
                    st.metric("åŒ¹é…ç‡", f"{rate:.1f}%")

                # ç­›é€‰æ§ä»¶
                st.markdown("### ç­›é€‰æ¡ä»¶")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    provinces = sorted(set(r['keyFields']['çœä»½'] for r in results if r['keyFields']['çœä»½']))
                    province_filter = st.selectbox("çœä»½", ["å…¨éƒ¨"] + provinces, key="ps_province")
                with col2:
                    batches = sorted(set(r['keyFields']['æ‰¹æ¬¡'] for r in results if r['keyFields']['æ‰¹æ¬¡']))
                    batch_filter = st.selectbox("æ‰¹æ¬¡", ["å…¨éƒ¨"] + batches, key="ps_batch")
                with col3:
                    match_status_filter = st.selectbox("åŒ¹é…çŠ¶æ€", ["å…¨éƒ¨", "åŒ¹é…", "æœªåŒ¹é…"], key="ps_status")
                with col4:
                    display_option = st.selectbox("æ˜¾ç¤ºé€‰é¡¹", ["å…¨éƒ¨", "å‰100æ¡", "å‰500æ¡"], key="ps_display")

                # åº”ç”¨ç­›é€‰
                filtered_results = results
                if province_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['çœä»½'] == province_filter]
                if batch_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['æ‰¹æ¬¡'] == batch_filter]
                if match_status_filter == "åŒ¹é…":
                    filtered_results = [r for r in filtered_results if r['exists']]
                elif match_status_filter == "æœªåŒ¹é…":
                    filtered_results = [r for r in filtered_results if not r['exists']]

                display_count = len(filtered_results)
                if display_option == "å‰100æ¡":
                    display_count = min(100, len(filtered_results))
                elif display_option == "å‰500æ¡":
                    display_count = min(500, len(filtered_results))

                # æ˜¾ç¤ºè¡¨æ ¼
                st.markdown(
                    f"### æ¯”å¯¹ç»“æœï¼ˆæ˜¾ç¤º {min(display_count, len(filtered_results))} / {len(filtered_results)} æ¡ï¼‰")
                display_results = filtered_results[:display_count]

                if len(display_results) > 0:
                    # å‡†å¤‡è¡¨æ ¼æ•°æ®
                    table_data = []
                    for r in display_results:
                        table_data.append({
                            'åºå·': r['index'],
                            'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                            'çœä»½': r['keyFields']['çœä»½'],
                            'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                            'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                            'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                            'ä¸“ä¸š': r['keyFields']['ä¸“ä¸š'],
                            'å±‚æ¬¡': r['keyFields']['å±‚æ¬¡'],
                            'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '] or '-',
                            'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'] or '-',
                            'åŒ¹é…çŠ¶æ€': 'âœ“ å­˜åœ¨' if r['exists'] else 'âœ— ä¸å­˜åœ¨'
                        })

                    df_display = pd.DataFrame(table_data)
                    st.dataframe(df_display, use_container_width=True, hide_index=True)

                # å¯¼å‡ºæŒ‰é’®
                if st.button("å¯¼å‡ºæ¯”å¯¹1ç»“æœ", key="export_ps", use_container_width=True):
                    try:
                        export_data = []
                        for r in results:
                            export_data.append({
                                'åºå·': r['index'],
                                'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                                'çœä»½': r['keyFields']['çœä»½'],
                                'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                'ä¸“ä¸š': r['keyFields']['ä¸“ä¸š'],
                                'å±‚æ¬¡': r['keyFields']['å±‚æ¬¡'],
                                'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                'å­¦è´¹': r['otherInfo']['å­¦è´¹'],
                                'å­¦åˆ¶': r['otherInfo']['å­¦åˆ¶'],
                                'ä¸“ä¸šä»£ç ': r['otherInfo']['ä¸“ä¸šä»£ç '],
                                'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                            })

                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            pd.DataFrame(export_data).to_excel(writer, index=False, sheet_name='æ¯”å¯¹1_æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†')

                        output.seek(0)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½æ¯”å¯¹1ç»“æœ",
                            output,
                            file_name=f"æ¯”å¯¹1_æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            else:
                st.info("æš‚æ— æ¯”å¯¹ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œæ¯”å¯¹")

        # æ¯”å¯¹2ç»“æœ
        with tab_plan_college:
            if len(st.session_state.plan_college_results) > 0:
                results = st.session_state.plan_college_results
                total = len(results)
                matched = sum(1 for r in results if r['exists'])
                unmatched = total - matched
                rate = (matched / total * 100) if total > 0 else 0

                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", total)
                with col2:
                    st.metric("åŒ¹é…è®°å½•æ•°", matched, delta=f"{rate:.1f}%")
                with col3:
                    st.metric("æœªåŒ¹é…è®°å½•æ•°", unmatched)
                with col4:
                    st.metric("åŒ¹é…ç‡", f"{rate:.1f}%")

                # ç­›é€‰æ§ä»¶
                st.markdown("### ç­›é€‰æ¡ä»¶")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    provinces = sorted(set(r['keyFields']['çœä»½'] for r in results if r['keyFields']['çœä»½']))
                    province_filter = st.selectbox("çœä»½", ["å…¨éƒ¨"] + provinces, key="pc_province")
                with col2:
                    batches = sorted(set(r['keyFields']['æ‰¹æ¬¡'] for r in results if r['keyFields']['æ‰¹æ¬¡']))
                    batch_filter = st.selectbox("æ‰¹æ¬¡", ["å…¨éƒ¨"] + batches, key="pc_batch")
                with col3:
                    match_status_filter = st.selectbox("åŒ¹é…çŠ¶æ€", ["å…¨éƒ¨", "åŒ¹é…", "æœªåŒ¹é…"], key="pc_status")
                with col4:
                    display_option = st.selectbox("æ˜¾ç¤ºé€‰é¡¹", ["å…¨éƒ¨", "å‰100æ¡", "å‰500æ¡"], key="pc_display")

                # åº”ç”¨ç­›é€‰
                filtered_results = results
                if province_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['çœä»½'] == province_filter]
                if batch_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['æ‰¹æ¬¡'] == batch_filter]
                if match_status_filter == "åŒ¹é…":
                    filtered_results = [r for r in filtered_results if r['exists']]
                elif match_status_filter == "æœªåŒ¹é…":
                    filtered_results = [r for r in filtered_results if not r['exists']]

                display_count = len(filtered_results)
                if display_option == "å‰100æ¡":
                    display_count = min(100, len(filtered_results))
                elif display_option == "å‰500æ¡":
                    display_count = min(500, len(filtered_results))

                # æ˜¾ç¤ºè¡¨æ ¼
                st.markdown(
                    f"### æ¯”å¯¹ç»“æœï¼ˆæ˜¾ç¤º {min(display_count, len(filtered_results))} / {len(filtered_results)} æ¡ï¼‰")
                display_results = filtered_results[:display_count]

                if len(display_results) > 0:
                    # å‡†å¤‡è¡¨æ ¼æ•°æ®
                    table_data = []
                    for r in display_results:
                        table_data.append({
                            'åºå·': r['index'],
                            'çœä»½': r['keyFields']['çœä»½'],
                            'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                            'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                            'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                            'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '] or '-',
                            'æ‹›ç”Ÿä»£ç ': r['keyFields']['æ‹›ç”Ÿä»£ç '] or '-',
                            'ä¸“ä¸š': r['otherInfo']['ä¸“ä¸š'] or '-',
                            'åŒ¹é…çŠ¶æ€': 'âœ“ å­˜åœ¨' if r['exists'] else 'âœ— ä¸å­˜åœ¨'
                        })

                    df_display = pd.DataFrame(table_data)
                    st.dataframe(df_display, use_container_width=True, hide_index=True)

                # å¯¼å‡ºæŒ‰é’®
                if st.button("å¯¼å‡ºæ¯”å¯¹2ç»“æœ", key="export_pc", use_container_width=True):
                    try:
                        export_data = []
                        for r in results:
                            export_data.append({
                                'åºå·': r['index'],
                                'å¹´ä»½': r['otherInfo']['å¹´ä»½'],
                                'çœä»½': r['keyFields']['çœä»½'],
                                'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                'æ‹›ç”Ÿä»£ç ': r['keyFields']['æ‹›ç”Ÿä»£ç '],
                                'ä¸“ä¸š': r['otherInfo']['ä¸“ä¸š'],
                                'å±‚æ¬¡': r['otherInfo']['å±‚æ¬¡'],
                                'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                            })

                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            pd.DataFrame(export_data).to_excel(writer, index=False, sheet_name='æ¯”å¯¹2_æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†')

                        output.seek(0)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½æ¯”å¯¹2ç»“æœ",
                            output,
                            file_name=f"æ¯”å¯¹2_æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            else:
                st.info("æš‚æ— æ¯”å¯¹ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œæ¯”å¯¹")

        # å…¨å±€å¯¼å‡ºåŒºåŸŸ
        if len(st.session_state.plan_score_results) > 0 or len(st.session_state.plan_college_results) > 0:
            st.markdown("---")
            st.markdown("### ğŸ“¤ å…¨å±€å¯¼å‡ºåŠŸèƒ½")

            # æ”¶é›†æ‰€æœ‰æœªåŒ¹é…çš„æ•°æ®
            all_unmatched_results = []
            if len(st.session_state.plan_score_results) > 0:
                all_unmatched_results.extend([r for r in st.session_state.plan_score_results if not r['exists']])
            if len(st.session_state.plan_college_results) > 0:
                all_unmatched_results.extend([r for r in st.session_state.plan_college_results if not r['exists']])

            # ä½¿ç”¨ä¸‰åˆ—å¸ƒå±€ï¼Œæ·»åŠ é™¢æ ¡åˆ†æ ¼å¼å¯¼å‡º
            col1, col2, col3 = st.columns([1, 1, 1])

            with col1:
                if st.button("ğŸ“Š å¯¼å‡ºå…¨éƒ¨ç»“æœ", use_container_width=True):
                    try:
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            # æ¯”å¯¹1ç»“æœ
                            if len(st.session_state.plan_score_results) > 0:
                                export_data = []
                                for r in st.session_state.plan_score_results:
                                    export_data.append({
                                        'åºå·': r['index'],
                                        'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                                        'çœä»½': r['keyFields']['çœä»½'],
                                        'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                        'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                        'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                        'ä¸“ä¸š': r['keyFields']['ä¸“ä¸š'],
                                        'å±‚æ¬¡': r['keyFields']['å±‚æ¬¡'],
                                        'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                        'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                        'å­¦è´¹': r['otherInfo']['å­¦è´¹'],
                                        'å­¦åˆ¶': r['otherInfo']['å­¦åˆ¶'],
                                        'ä¸“ä¸šä»£ç ': r['otherInfo']['ä¸“ä¸šä»£ç '],
                                        'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                        'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                                    })
                                pd.DataFrame(export_data).to_excel(writer, index=False,
                                                                   sheet_name='æ¯”å¯¹1_æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†')

                            # æ¯”å¯¹2ç»“æœ
                            if len(st.session_state.plan_college_results) > 0:
                                export_data = []
                                for r in st.session_state.plan_college_results:
                                    export_data.append({
                                        'åºå·': r['index'],
                                        'å¹´ä»½': r['otherInfo']['å¹´ä»½'],
                                        'çœä»½': r['keyFields']['çœä»½'],
                                        'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                        'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                        'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                        'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                        'æ‹›ç”Ÿä»£ç ': r['keyFields']['æ‹›ç”Ÿä»£ç '],
                                        'ä¸“ä¸š': r['otherInfo']['ä¸“ä¸š'],
                                        'å±‚æ¬¡': r['otherInfo']['å±‚æ¬¡'],
                                        'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                        'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                        'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                                    })
                                pd.DataFrame(export_data).to_excel(writer, index=False,
                                                                   sheet_name='æ¯”å¯¹2_æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†')

                            # ç»Ÿè®¡æŠ¥å‘Š
                            summary_data = {
                                'æ¯”å¯¹ç±»å‹': ['æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†', 'æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†'],
                                'æ€»è®°å½•æ•°': [
                                    len(st.session_state.plan_score_results),
                                    len(st.session_state.plan_college_results)
                                ],
                                'åŒ¹é…è®°å½•æ•°': [
                                    sum(1 for r in st.session_state.plan_score_results if r['exists']),
                                    sum(1 for r in st.session_state.plan_college_results if r['exists'])
                                ],
                                'åŒ¹é…ç‡': [
                                    f"{(sum(1 for r in st.session_state.plan_score_results if r['exists']) / len(st.session_state.plan_score_results) * 100):.1f}%" if len(
                                        st.session_state.plan_score_results) > 0 else "0%",
                                    f"{(sum(1 for r in st.session_state.plan_college_results if r['exists']) / len(st.session_state.plan_college_results) * 100):.1f}%" if len(
                                        st.session_state.plan_college_results) > 0 else "0%"
                                ]
                            }
                            pd.DataFrame(summary_data).to_excel(writer, index=False, sheet_name='ç»Ÿè®¡æŠ¥å‘Š')

                        output.seek(0)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½å…¨éƒ¨ç»“æœ",
                            output,
                            file_name=f"æ•°æ®æ¯”å¯¹ç»“æœæ±‡æ€»_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

            with col2:
                if len(all_unmatched_results) > 0:
                    if st.button("â­ å¯¼å‡ºæœªåŒ¹é…æ•°æ®ä¸ºä¸“ä¸šåˆ†æ ¼å¼", type="primary", use_container_width=True):
                        try:
                            # æå–åŸå§‹æ•°æ®ï¼ˆå»é‡ï¼Œå› ä¸ºåŒä¸€ä¸ªè®°å½•å¯èƒ½åœ¨æ¯”å¯¹1å’Œæ¯”å¯¹2ä¸­éƒ½æœªåŒ¹é…ï¼‰
                            seen_indices = set()
                            conversion_data = []
                            for r in all_unmatched_results:
                                original_idx = r['originalIndex']
                                if original_idx not in seen_indices:
                                    seen_indices.add(original_idx)
                                    conversion_data.append(st.session_state.plan_data.iloc[original_idx].to_dict())

                            # è½¬æ¢æ•°æ®
                            converted_data = convert_data(conversion_data)

                            # å¯¼å‡º
                            output = BytesIO()
                            temp_path = "temp_converted.xlsx"
                            export_converted_data_to_excel(converted_data, conversion_data, temp_path)

                            with open(temp_path, 'rb') as f:
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½è½¬æ¢åçš„ä¸“ä¸šåˆ†æ•°æ®",
                                    f.read(),
                                    file_name=f"ä¸“ä¸šåˆ†æ•°æ®_æœªåŒ¹é…æ•°æ®_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )

                            os.remove(temp_path)
                            st.success(f"è½¬æ¢å®Œæˆï¼å…±è½¬æ¢ {len(converted_data)} æ¡æ•°æ®ï¼ˆå·²å»é‡ï¼‰")
                        except Exception as e:
                            st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
                else:
                    st.info("æš‚æ— æœªåŒ¹é…æ•°æ®")

            with col3:
                if len(all_unmatched_results) > 0:
                    if st.button("â­ å¯¼å‡ºæœªåŒ¹é…æ•°æ®ä¸ºé™¢æ ¡åˆ†æ ¼å¼", type="primary", use_container_width=True):
                        try:
                            # æ£€æŸ¥æ˜¯å¦æœ‰é™¢æ ¡åˆ†æ•°æ®
                            if 'college_data' not in st.session_state or st.session_state.college_data is None:
                                st.error("è¯·å…ˆä¸Šä¼ é™¢æ ¡åˆ†æ–‡ä»¶ï¼Œä»¥ä¾¿è¿›è¡Œæ¯”å¯¹è¿‡æ»¤")
                            else:
                                # æå–åŸå§‹æ‹›ç”Ÿè®¡åˆ’æ•°æ®
                                plan_df = st.session_state.plan_data.copy()
                                college_df = st.session_state.college_data.copy()
                                
                                # ä½¿ç”¨æ–°çš„è¿‡æ»¤å‡½æ•°ï¼Œåªå¯¼å‡ºæ‹›ç”Ÿè®¡åˆ’ä¸­ä¸å­˜åœ¨äºé™¢æ ¡åˆ†çš„æ•°æ®
                                unmatched_records = filter_unmatched_plan_data_for_college_export(plan_df, college_df)
                                
                                if len(unmatched_records) == 0:
                                    st.warning("âš ï¸ æ‰€æœ‰æ‹›ç”Ÿè®¡åˆ’æ•°æ®éƒ½å·²å­˜åœ¨äºé™¢æ ¡åˆ†ä¸­ï¼Œæ— éœ€è½¬æ¢")
                                else:
                                    # æå–æœªåŒ¹é…æ•°æ®
                                    conversion_data = [r['data'] for r in unmatched_records]
                                    
                                    # è½¬æ¢æ•°æ®ä¸ºé™¢æ ¡åˆ†æ ¼å¼
                                    college_score_data = convert_to_college_score_format(conversion_data)
                                    
                                    # å¯¼å‡º
                                    temp_path = "temp_college_score.xlsx"
                                    export_college_score_data_to_excel(college_score_data, conversion_data, temp_path)
                                    
                                    with open(temp_path, 'rb') as f:
                                        st.download_button(
                                            "ğŸ“¥ ä¸‹è½½è½¬æ¢åçš„é™¢æ ¡åˆ†æ•°æ®",
                                            f.read(),
                                            file_name=f"é™¢æ ¡åˆ†æ•°æ®_æœªåŒ¹é…æ•°æ®å¯¼å‡º{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                        )
                                    
                                    os.remove(temp_path)
                                    st.success(f"è½¬æ¢å®Œæˆï¼å…±è½¬æ¢ {len(college_score_data)} æ¡æ•°æ®")
                        except Exception as e:
                            st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
                            import traceback
                            st.error(traceback.format_exc())
                else:
                    st.info("æš‚æ— æœªåŒ¹é…æ•°æ®")

# é¡µè„š
st.markdown("---")
st.markdown("Â© æ•°æ®å¤„ç†", unsafe_allow_html=True)
