import streamlit as st
import pandas as pd
import os
import logging
import re
import streamlit.components.v1 as components
from difflib import SequenceMatcher
from concurrent.futures import ThreadPoolExecutor, as_completed
import openpyxl
from openpyxl.styles import PatternFill, Alignment
from openpyxl.styles import numbers
import base64
import sys
from io import BytesIO
import requests
import tempfile
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from PIL import Image
import io

# ============================
# åˆå§‹åŒ–è®¾ç½®
# ============================
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†å·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("å¯åŠ¨æ•°æ®å¤„ç†å·¥å…·ã€‚")


# ============================
# å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°
# ============================

# ======== è·¯å¾„å…¼å®¹å‡½æ•° =========
def resource_path(relative_path):
    """å…¼å®¹ PyCharm å¼€å‘ç¯å¢ƒ å’Œ PyInstaller æ‰“åŒ…åçš„è·¯å¾„"""
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)


# ======== åŠ è½½å­¦æ ¡æ•°æ® =========
try:
    school_data_path = resource_path("school_data.xlsx")
    school_df = pd.read_excel(school_data_path)
    VALID_SCHOOL_NAMES = set(school_df['å­¦æ ¡åç§°'].dropna().str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_SCHOOL_NAMES)} ä¸ªæœ‰æ•ˆå­¦æ ¡åç§°")
except Exception as e:
    logging.error(f"è¯»å– school_data.xlsx å‡ºé”™ï¼š{e}")
    VALID_SCHOOL_NAMES = set()
    st.warning("å­¦æ ¡æ•°æ®åŠ è½½å¤±è´¥ï¼Œå­¦æ ¡åç§°æ£€æŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨")

# ======== åŠ è½½æ‹›ç”Ÿä¸“ä¸šæ•°æ® =========
try:
    major_data_path = resource_path("æ‹›ç”Ÿä¸“ä¸š.xlsx")
    major_df = pd.read_excel(major_data_path)
    VALID_MAJOR_COMBOS = set(major_df['æ‹›ç”Ÿä¸“ä¸š'].dropna().astype(str).str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_MAJOR_COMBOS)} ä¸ªæœ‰æ•ˆä¸“ä¸šç»„åˆ")
except Exception as e:
    logging.error(f"è¯»å– æ‹›ç”Ÿä¸“ä¸š.xlsx å‡ºé”™ï¼š{e}")
    VALID_MAJOR_COMBOS = set()
    st.warning("ä¸“ä¸šæ•°æ®åŠ è½½å¤±è´¥ï¼Œä¸“ä¸šåŒ¹é…åŠŸèƒ½å°†ä¸å¯ç”¨")


def check_school_name(name):
    if pd.isna(name) or not str(name).strip():
        return 'å­¦æ ¡åç§°ä¸ºç©º'
    return 'åŒ¹é…' if name.strip() in VALID_SCHOOL_NAMES else 'ä¸åŒ¹é…'


def check_major_combo(major, level):
    if pd.isna(major) or pd.isna(level):
        return "æ•°æ®ç¼ºå¤±"
    combo = f"{str(major).strip()}{str(level).strip()}"
    return "åŒ¹é…" if combo in VALID_MAJOR_COMBOS else "ä¸åŒ¹é…"


CUSTOM_WHITELIST = {
    "å®ç¦æ ¡åŒº", "æ²™æ²³æ ¡åŒº", "ä¸­å¤–åˆä½œåŠå­¦", "ç æµ·æ ¡åŒº", "æ±ŸåŒ—æ ¡åŒº", "æ´¥å—æ ¡åŒº", "å¼€å°æ ¡åŒº",
    "è”åˆåŠå­¦", "æ ¡ä¼åˆä½œ", "åˆä½œåŠå­¦", "å¨æµ·æ ¡åŒº", "æ·±åœ³æ ¡åŒº", "è‹å·æ ¡åŒº", "å¹³æœæ ¡åŒº",
    "æ±Ÿå—æ ¡åŒº", "åˆå·æ ¡åŒº", "é•¿å®‰æ ¡åŒº", "å´‡å®‰æ ¡åŒº", "å—æ ¡åŒº", "ä¸œæ ¡åŒº", "éƒ½å¸‚å›­è‰º", "ç”˜è‚ƒå…°å·"
}

TYPO_DICT = {
    "æ•™åŠ©": "æ•‘åŠ©",
    "æŒ‡è¾‰": "æŒ‡æŒ¥",
    "æ–™å­¦": "ç§‘å­¦",
    "è¯è¨€": "è¯­è¨€",
    "5å3": "5+3",
    "5å3ä¸€ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "â€œ5å3â€ä¸€ä½“åŒ–": "â€œ5+3â€ä¸€ä½“åŒ–",
    "5+31ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "5+3ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "è‰²è¨€": "è‰²ç›²",
    "NIT": "NIIT",
    "è‰²è‚²": "è‰²ç›²",
    "äººå›´": "å…¥å›´",
    "é¡¹æœˆ": "é¡¹ç›®",
    "å¸èŒƒç±»": "å¸ˆèŒƒç±»",
    "æŠ•è¯¾": "æˆè¯¾",
    "å°±è–„": "å°±è¯»",
    "ç”µè¯·": "ç”³è¯·",
    "ä¸­å›½é¢": "ä¸­å›½ç”»",
    "ç«æ•°æ°‘æ—": "å°‘æ•°æ°‘æ—",
    "è‰²è‡ª": "è‰²ç›²",
    "è‰²ç›²è‰²å¼±ç”³æŠ¥": "è‰²ç›²è‰²å¼±æ…æŠ¥",
    "æ•°å­¦ä¸åº”ç”¨æ•°ç¬‘": "æ•°å­¦ä¸åº”ç”¨æ•°å­¦",
    "æ³•å­¦å": "æ³•å­¦+",
    "æµ£æµ·æ ¡åŒº": "æ»¨æµ·æ ¡åŒº",
    "ä¸­æº´": "ä¸­æ¾³"
}

REGEX_PATTERNS = {
    'excess_punct': re.compile(r'[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+'),
    'outer_punct': re.compile(r'^[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+|[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+$'),
    'consecutive_right': re.compile(r'ï¼‰{2,}')
}
NESTED_PAREN_PATTERN = re.compile(r'ï¼ˆï¼ˆ(.*?)ï¼‰ï¼‰')
CONSECUTIVE_REPEAT_PATTERN = re.compile(r'ï¼ˆ(.+?)ï¼‰\s*ï¼ˆ\1ï¼‰')


def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()


def normalize_brackets(text):
    """ç»Ÿä¸€å„ç§æ‹¬å·ä¸ºä¸­æ–‡æ‹¬å·å¹¶å¤„ç†ä¸å®Œæ•´æ‹¬å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()

    # æ›¿æ¢æ‰€æœ‰æ‹¬å·å˜ä½“ä¸ºä¸­æ–‡æ‹¬å·
    text = re.sub(r'[{\[ã€]', 'ï¼ˆ', text)  # å·¦æ‹¬å·
    text = re.sub(r'[}\]ã€‘]', 'ï¼‰', text)  # å³æ‹¬å·
    text = re.sub(r'[<ã€Š]', 'ï¼ˆ', text)  # å·¦ä¹¦åå·æ›¿æ¢ä¸ºå·¦æ‹¬å·
    text = re.sub(r'[>ã€‹]', 'ï¼‰', text)  # å³ä¹¦åå·æ›¿æ¢ä¸ºå³æ‹¬å·

    return text


def clean_outer_punctuation(text):
    """æ¸…ç†æœ€å¤–å±‚æ‹¬å·å¤–çš„æ ‡ç‚¹ç¬¦å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()
    text = REGEX_PATTERNS['outer_punct'].sub('', text)
    parts = re.split(r'(ï¼ˆ.*?ï¼‰)', text)
    cleaned_parts = []
    for part in parts:
        if part.startswith('ï¼ˆ') and part.endswith('ï¼‰'):
            cleaned_parts.append(part)
        else:
            cleaned_parts.append(REGEX_PATTERNS['outer_punct'].sub('', part))
    return ''.join(cleaned_parts)


def check_score_consistency(row):
    """æ£€æŸ¥åˆ†æ•°ä¸€è‡´æ€§ï¼šæœ€é«˜åˆ† >= å¹³å‡åˆ† >= æœ€ä½åˆ†"""
    issues = []
    try:
        max_score = float(row['æœ€é«˜åˆ†']) if pd.notna(row['æœ€é«˜åˆ†']) else None
        avg_score = float(row['å¹³å‡åˆ†']) if pd.notna(row['å¹³å‡åˆ†']) else None
        min_score = float(row['æœ€ä½åˆ†']) if pd.notna(row['æœ€ä½åˆ†']) else None

        if max_score is not None and avg_score is not None and max_score < avg_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < å¹³å‡åˆ†({avg_score})")

        if max_score is not None and min_score is not None and max_score < min_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < æœ€ä½åˆ†({min_score})")

        if avg_score is not None and min_score is not None and avg_score < min_score:
            issues.append(f"å¹³å‡åˆ†({avg_score}) < æœ€ä½åˆ†({min_score})")

    except (ValueError, TypeError) as e:
        issues.append(f"åˆ†æ•°æ ¼å¼é”™è¯¯: {str(e)}")

    return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜'


def analyze_and_fix(text):
    if pd.isna(text) or not str(text).strip():
        return text, []

    text = normalize_brackets(text)
    text = clean_outer_punctuation(text)
    issues = []

    if text in CUSTOM_WHITELIST:
        return text, []

    # ========== æ‹¬å·æˆå¯¹ä¿®æ­£ ==========
    text_list = list(text)
    stack = []
    unmatched_right = []

    for i, char in enumerate(text_list):
        if char == 'ï¼ˆ':
            stack.append(i)
        elif char == 'ï¼‰':
            if stack:
                stack.pop()
            else:
                unmatched_right.append(i)

    for i in reversed(unmatched_right):
        del text_list[i]
        issues.append("åˆ é™¤å¤šä½™å³æ‹¬å·1ä¸ª")

    if stack:
        text_list.extend(['ï¼‰'] * len(stack))
        issues.append(f"è¡¥å……ç¼ºå¤±å³æ‹¬å·{len(stack)}ä¸ª")

    text = ''.join(text_list)

    # åµŒå¥—ä¿®æ­£
    text, nested_count = NESTED_PAREN_PATTERN.subn(r'ï¼ˆ\1ï¼‰', text)
    if nested_count > 0:
        issues.append(f"ä¿®å¤åµŒå¥—æ‹¬å·{nested_count}å¤„")

    # ========== æ¸…ç†ç©ºæ‹¬å·æˆ–çº¯æ ‡ç‚¹æ‹¬å· ==========
    def clean_empty_paren(m):
        content = m.group(1).strip('ï¼Œã€,;ï¼›:ï¼šã€‚ï¼ï¼Ÿ.!? ')
        if not content:
            issues.append("åˆ é™¤ç©ºæ‹¬å·æˆ–ä»…å«æ ‡ç‚¹æ‹¬å·")
            return ''
        return f'ï¼ˆ{content}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', clean_empty_paren, text)

    # ========== å»é‡ ==========
    seen = set()

    def dedup(m):
        c = m.group(1)
        if c in seen:
            issues.append(f"é‡å¤æ‹¬å·å†…å®¹ï¼š'{c}'")
            return ''
        seen.add(c)
        return f'ï¼ˆ{c}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', dedup, text)

    # ========== å¤šä½™æ ‡ç‚¹ç®€åŒ– ==========
    text = REGEX_PATTERNS['excess_punct'].sub(lambda m: m.group(0)[0], text)

    # ========== é”™åˆ«å­—ä¿®æ­£ ==========
    for typo, corr in TYPO_DICT.items():
        if typo in text:
            text = text.replace(typo, corr)
            issues.append(f"é”™åˆ«å­—ï¼š'{typo}'â†’'{corr}'")

    return text, issues


def process_chunk(chunk):
    """å¤„ç†æ•°æ®å—"""
    # å­¦æ ¡åç§°æ£€æŸ¥
    if 'å­¦æ ¡åç§°' in chunk.columns:
        chunk['å­¦æ ¡åŒ¹é…ç»“æœ'] = chunk['å­¦æ ¡åç§°'].apply(check_school_name)

    # ä¸“ä¸šåŒ¹é…æ£€æŸ¥
    if 'æ‹›ç”Ÿä¸“ä¸š' in chunk.columns and 'ä¸€çº§å±‚æ¬¡' in chunk.columns:
        chunk['æ‹›ç”Ÿä¸“ä¸šåŒ¹é…ç»“æœ'] = chunk.apply(
            lambda r: check_major_combo(r['æ‹›ç”Ÿä¸“ä¸š'], r['ä¸€çº§å±‚æ¬¡']), axis=1)

    # å¤‡æ³¨å¤„ç† - ä¿®æ”¹è¿™éƒ¨åˆ†
    if 'ä¸“ä¸šå¤‡æ³¨' in chunk.columns:
        def process_remark(remark):
            if pd.isna(remark) or not str(remark).strip():
                return 'æ— é—®é¢˜', ''
            fixed_text, issues = analyze_and_fix(remark)
            return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜', fixed_text

        chunk[['å¤‡æ³¨æ£€æŸ¥ç»“æœ', 'ä¿®æ”¹åå¤‡æ³¨']] = chunk['ä¸“ä¸šå¤‡æ³¨'].apply(
            lambda x: pd.Series(process_remark(x)))

    # åˆ†æ•°æ£€æŸ¥
    score_columns = ['æœ€é«˜åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†']
    if all(col in chunk.columns for col in score_columns):
        chunk['åˆ†æ•°æ£€æŸ¥ç»“æœ'] = chunk.apply(check_score_consistency, axis=1)

    # é€‰ç§‘è¦æ±‚å¤„ç†
    if 'é€‰ç§‘è¦æ±‚' in chunk.columns:
        def proc_req(req):
            if pd.isna(req) or not str(req).strip():
                return ["", ""]
            s = str(req).strip()
            if "ä¸é™" in s:
                return ["ä¸é™ç§‘ç›®ä¸“ä¸šç»„", ""]
            if len(s) == 1:
                return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s]
            if "ä¸”" in s:
                return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s.replace("ä¸”", "")]
            if "æˆ–" in s:
                return ["å¤šé—¨é€‰è€ƒ", s.replace("æˆ–", "")]
            return ["", ""]

        chunk[['é€‰ç§‘è¦æ±‚è¯´æ˜', 'æ¬¡é€‰']] = chunk['é€‰ç§‘è¦æ±‚'].apply(
            lambda x: pd.Series(proc_req(x)))

    # æ‹›ç”Ÿç§‘ç±»å¤„ç†
    if 'æ‹›ç”Ÿç§‘ç±»' in chunk.columns:
        chunk['æ‹›ç”Ÿç§‘ç±»'] = chunk['æ‹›ç”Ÿç§‘ç±»'].replace({'ç‰©ç†': 'ç‰©ç†ç±»', 'å†å²': 'å†å²ç±»'})
        chunk['é¦–é€‰ç§‘ç›®'] = chunk['æ‹›ç”Ÿç§‘ç±»'].apply(
            lambda x: str(x)[0] if x in ['ç‰©ç†ç±»', 'å†å²ç±»'] else "")

    return chunk


# ============================
# é™¢æ ¡åˆ†æå–ç›¸å…³å‡½æ•°ï¼ˆæ™®é€šç±»ï¼‰
# ============================
expected_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡',
    'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æ•°æ®æ¥æº',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
]
columns_to_convert = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'
]


def process_score_file(file_path):
    # é¦–å…ˆè¯»å–å¹´ä»½ï¼ˆä»B2å•å…ƒæ ¼ï¼‰
    try:
        wb = openpyxl.load_workbook(file_path, data_only=True)
        ws = wb.active
        year_value = ws['B2'].value
        if year_value is None:
            # å¦‚æœB2ä¸ºç©ºï¼Œå°è¯•ä»æ•°æ®ä¸­æå–å¹´ä»½
            year_value = ''
        else:
            year_value = str(year_value).strip()
        wb.close()
    except Exception as e:
        year_value = ''

    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€é«˜åˆ†': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰': str,
            'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    missing_columns = [col for col in expected_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æœ€é«˜åˆ†'] = pd.to_numeric(df['æœ€é«˜åˆ†'], errors='coerce')
    df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df = df.dropna(subset=['æœ€ä½åˆ†'])

    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'].fillna('')

    # é¦–é€‰ç§‘ç›®è½¬æ¢é€»è¾‘
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()  # å»é™¤å‰åç©ºæ ¼
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',  # ç¡®ä¿å·²ç»æ˜¯"å†å²"çš„ä¸å˜
            'ç‰©ç†': 'ç‰©ç†'  # ç¡®ä¿å·²ç»æ˜¯"ç‰©ç†"çš„ä¸å˜
        })

    try:
        # åˆ¤æ–­æ˜¯å¦æœ‰ä¸“ä¸šç»„ä»£ç åˆ—ï¼Œä¸”ä¸å…¨ä¸ºç©º
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # æ¯ç»„æœ€é«˜åˆ†
        max_scores = df.groupby(group_fields)['æœ€é«˜åˆ†'].max()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

        # è¡¥å……æœ€é«˜åˆ†
        def get_max_score(row):
            key = tuple(row[col] for col in group_fields)
            return max_scores.get(key, None)

        result['æœ€é«˜åˆ†'] = result.apply(get_max_score, axis=1)

        # æ‹›ç”Ÿäººæ•°ã€å½•å–äººæ•°æŒ‰åˆ†ç»„æ€»å’Œ
        enroll_groups = df.groupby(group_fields)['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()
        code_groups = df.groupby(group_fields)['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()

        def get_group_total(row, column_name):
            key = tuple(row[col] for col in group_fields)
            if column_name == 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return enroll_groups.get(key, '')
            elif column_name == 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return code_groups.get(key, '')
            return ''

        result['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)
        result['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # æ„å»ºæ–°çš„æ•°æ®æ¡†ï¼ŒæŒ‰ç…§æ–°çš„åˆ—é¡ºåº
    new_columns = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§',
        'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡',
        'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨',
        'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç '
    ]

    # åˆ›å»ºæ–°çš„DataFrameï¼Œç¡®ä¿æ‰€æœ‰åˆ—éƒ½æœ‰æ­£ç¡®çš„é•¿åº¦
    num_rows = len(result)
    new_result = pd.DataFrame(index=range(num_rows))

    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†åˆ—å€¼ï¼Œå°†NaNè½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆç”¨äºæ–‡æœ¬åˆ—ï¼‰
    def get_col_values(col_name, default=''):
        if col_name in result.columns:
            values = result[col_name].fillna(default).astype(str).values
            # å°†'nan'å­—ç¬¦ä¸²è½¬æ¢å›ç©ºå­—ç¬¦ä¸²
            values = ['' if str(v).lower() == 'nan' else v for v in values]
            return values
        else:
            return [default] * num_rows

    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æ•°å­—åˆ—å€¼ï¼Œä¿æŒæ•°å­—ç±»å‹
    def get_numeric_values(col_name, default=0):
        if col_name in result.columns:
            values = result[col_name].fillna(default)
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œæ— æ³•è½¬æ¢çš„ä¿æŒåŸå€¼æˆ–è®¾ä¸ºé»˜è®¤å€¼
            try:
                return pd.to_numeric(values, errors='coerce').fillna(default).values
            except:
                return [default] * num_rows
        else:
            return [default] * num_rows

    new_result['å­¦æ ¡åç§°'] = get_col_values('å­¦æ ¡åç§°')
    new_result['çœä»½'] = get_col_values('çœä»½')
    new_result['æ‹›ç”Ÿç±»åˆ«'] = get_col_values('æ‹›ç”Ÿç§‘ç±»')
    new_result['æ‹›ç”Ÿæ‰¹æ¬¡'] = get_col_values('æ‹›ç”Ÿæ‰¹æ¬¡')
    new_result['æ‹›ç”Ÿç±»å‹'] = get_col_values('æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰')
    new_result['é€‰æµ‹ç­‰çº§'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜åˆ†'] = get_col_values('æœ€é«˜åˆ†')
    new_result['æœ€ä½åˆ†'] = get_col_values('æœ€ä½åˆ†')
    new_result['å¹³å‡åˆ†'] = [''] * num_rows  # åˆ é™¤å¹³å‡åˆ†æå–é€»è¾‘ï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€ä½ä½æ¬¡'] = get_col_values('æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰')
    new_result['å¹³å‡ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['å½•å–äººæ•°'] = get_numeric_values('å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ‹›ç”Ÿäººæ•°'] = get_numeric_values('æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ•°æ®æ¥æº'] = get_col_values('æ•°æ®æ¥æº')
    new_result['çœæ§çº¿ç§‘ç±»'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿æ‰¹æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿å¤‡æ³¨'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['ä¸“ä¸šç»„ä»£ç '] = get_col_values('ä¸“ä¸šç»„ä»£ç ')
    new_result['é¦–é€‰ç§‘ç›®'] = get_col_values('é¦–é€‰ç§‘ç›®')
    new_result['é™¢æ ¡æ‹›ç”Ÿä»£ç '] = get_col_values('æ‹›ç”Ÿä»£ç ')

    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
        remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    åŒ—äº¬ã€å¤©æ´¥ã€è¾½å®ã€ä¸Šæµ·ã€å±±ä¸œã€å¹¿ä¸œã€æµ·å—é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼ˆæœ€å¤šä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
5.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—
6.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
7.é¦–é€‰ç§‘ç›®ï¼šæ–°å…«çœå¿…å¡«ï¼Œåªèƒ½å¡«å†™ï¼ˆå†å²æˆ–ç‰©ç†ï¼‰"""

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # å…ˆå†™å…¥æ•°æ®ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼Œä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            new_result.to_excel(writer, index=False, header=False, startrow=3)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']

            # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
            worksheet.merge_cells('A1:U1')
            worksheet['A1'] = remark_text
            worksheet['A1'].alignment = Alignment(wrap_text=True, vertical='top')
            # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º215ç£…
            worksheet.row_dimensions[1].height = 215

            # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=å¹´ä»½ï¼ŒC2="1"ï¼ŒD2="æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰"
            worksheet['A2'] = 'æ‹›ç”Ÿå¹´'
            # B2å’ŒC2è®¾ç½®ä¸ºæ•°å­—æ ¼å¼
            try:
                # å°è¯•å°†å¹´ä»½è½¬æ¢ä¸ºæ•°å­—
                if year_value and str(year_value).strip():
                    year_num = int(float(str(year_value).strip()))
                    worksheet['B2'] = year_num
                else:
                    worksheet['B2'] = ''
            except:
                worksheet['B2'] = year_value
            worksheet['C2'] = 1  # ç›´æ¥è®¾ç½®ä¸ºæ•°å­—1
            worksheet['D2'] = 'æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰'

            # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
            headers = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§',
                       'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡',
                       'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨',
                       'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ']
            for col_idx, header in enumerate(headers, start=1):
                worksheet.cell(row=3, column=col_idx, value=header)

            # è®¾ç½®æ–‡æœ¬æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼Œå³æ•°æ®è¡Œï¼‰
            # éœ€è¦è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼çš„åˆ—ï¼ˆä½¿ç”¨æ–°åˆ—åï¼Œä¸åŒ…æ‹¬æ‹›ç”Ÿäººæ•°å’Œå½•å–äººæ•°ï¼‰
            text_format_cols = ['ä¸“ä¸šç»„ä»£ç ', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½ä½æ¬¡']
            for col in text_format_cols:
                if col in new_result.columns:
                    col_idx = new_result.columns.get_loc(col) + 1
                    for row in range(4, len(new_result) + 4):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT

            # ç¡®ä¿B2å’ŒC2å•å…ƒæ ¼ä¿æŒæ•°å­—æ ¼å¼
            if worksheet['B2'].value is not None and str(worksheet['B2'].value).strip():
                try:
                    worksheet['B2'].value = int(float(str(worksheet['B2'].value)))
                except:
                    pass
            worksheet['C2'].value = 1

            # ç¡®ä¿"å½•å–äººæ•°"å’Œ"æ‹›ç”Ÿäººæ•°"åˆ—ä¿æŒæ•°å­—æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            if 'å½•å–äººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('å½•å–äººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass

            if 'æ‹›ç”Ÿäººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('æ‹›ç”Ÿäººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")


# ============================
# ä¿æŒæ–‡æœ¬æ ¼å¼
# ============================
def process_remarks_file(file_path, progress_callback=None):
    try:
        # è¯»å–æ–‡ä»¶æ—¶ï¼Œç¡®ä¿è¿™äº›å­—æ®µå§‹ç»ˆä»¥å­—ç¬¦ä¸²æ ¼å¼è¯»å–
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
        }, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")
    for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
        if col in df.columns:
            df[col] = df[col].astype(str)
    target_col = None
    for col in df.columns:
        if "ä¸“ä¸šå¤‡æ³¨" in str(col):
            target_col = col
            break
    if not target_col:
        raise Exception("æœªæ‰¾åˆ°'ä¸“ä¸šå¤‡æ³¨'ç›¸å…³åˆ—")
    if target_col != 'ä¸“ä¸šå¤‡æ³¨':
        df = df.rename(columns={target_col: 'ä¸“ä¸šå¤‡æ³¨'})
    chunks = []
    for i in range(0, len(df), 1000):
        chunks.append(df.iloc[i:i + 1000].copy())
    results = {}
    total_chunks = len(chunks)
    with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
        future_to_index = {executor.submit(process_chunk, chunk): idx for idx, chunk in enumerate(chunks)}
        for count, future in enumerate(as_completed(future_to_index)):
            idx = future_to_index[future]
            results[idx] = future.result()
            if progress_callback:
                progress_callback(count + 1, total_chunks)
    ordered_results = [results[i] for i in sorted(results.keys())]
    final_result = pd.concat(ordered_results)
    output_path = file_path.replace('.xlsx', '_æ£€æŸ¥ç»“æœ.xlsx')
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            final_result.to_excel(writer, index=False)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']
            # ä¿æŒæŒ‡å®šåˆ—ä»ç¬¬ä¸‰è¡Œå¼€å§‹æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in final_result.columns:
                    col_idx = final_result.columns.get_loc(col) + 1  # è½¬æ¢ä¸ºExcelåˆ—å·ï¼ˆA=1ï¼‰
                    # ä»ç¬¬ä¸‰è¡Œå¼€å§‹è®¾ç½®æ ¼å¼ï¼ˆExcelè¡Œå·ä¸º3ï¼Œå¯¹åº”Pythonçš„ç´¢å¼•ä¸º2ï¼‰
                    for row in range(3, len(final_result) + 2):  # å·¥ä½œè¡¨è¡Œå·ä»3å¼€å§‹ï¼ˆç´¢å¼•2ï¼‰
                        cell = worksheet.cell(row=row, column=col_idx)
                        cell.value = final_result.iloc[row - 3][col]  # æ•°æ®ä»ç¬¬ä¸‰è¡Œå¼€å§‹å¡«å……
                        cell.number_format = numbers.FORMAT_TEXT
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶é”™è¯¯ï¼š{e}")
    return output_path


# ============================
# é™¢æ ¡åˆ†æ•°æ®å¤„ç†ï¼ˆè‰ºä½“ç±»ï¼‰
# ============================

expected_new_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡',
    'ä¸“ä¸šç±»åˆ«', 'æ˜¯å¦æ ¡è€ƒ', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'æ‹›ç”Ÿä»£ç ', 'æ ¡ç»Ÿè€ƒåˆ†',
    'æ ¡æ–‡åŒ–åˆ†', 'ä¸“ä¸šä»£ç ', 'æ•°æ®æ¥æº'
]
columns_to_convert_new = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ ¡ç»Ÿè€ƒåˆ†', 'æ ¡æ–‡åŒ–åˆ†'
]


def process_new_template_file(file_path):
    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ ¡ç»Ÿè€ƒåˆ†': str,
            'æ ¡æ–‡åŒ–åˆ†': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    # æ£€æŸ¥å¿…éœ€åˆ—
    missing_columns = [col for col in expected_new_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    # æ•°å€¼åˆ—è½¬ä¸ºæ•°å€¼å‹
    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æ ¡ç»Ÿè€ƒåˆ†'] = pd.to_numeric(df['æ ¡ç»Ÿè€ƒåˆ†'], errors='coerce')
    df['æ ¡æ–‡åŒ–åˆ†'] = pd.to_numeric(df['æ ¡æ–‡åŒ–åˆ†'], errors='coerce')

    # åˆ é™¤æœ€ä½åˆ†ä¸ºç©ºçš„è¡Œ
    df = df.dropna(subset=['æœ€ä½åˆ†'])
    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    # é¦–é€‰ç§‘ç›®æ¸…æ´—
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',
            'ç‰©ç†': 'ç‰©ç†'
        })

    try:
        # åˆ¤æ–­åˆ†ç»„å­—æ®µ
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡',
                            'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # ä¿ç•™æœŸæœ›åˆ—
    selected_columns = [col for col in expected_new_columns if col in result.columns]
    result = result[selected_columns]

    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            result.to_excel(writer, index=False)
            worksheet = writer.sheets['Sheet1']

            # è®¾ç½®æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in result.columns:
                    col_idx = result.columns.get_loc(col) + 1
                    for row in range(2, len(result) + 2):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT

            for col in columns_to_convert_new:
                if col in result.columns and col not in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                    col_idx = result.columns.get_loc(col) + 1
                    for cell in \
                    list(worksheet.iter_cols(min_col=col_idx, max_col=col_idx, min_row=2, values_only=False))[0]:
                        cell.number_format = numbers.FORMAT_TEXT

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")


# ============================
# ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†
# ============================

def process_segmentation_file(file_path):
    output_path = os.path.splitext(file_path)[0] + "_æ ¡éªŒç»“æœ.xlsx"
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active

    ws['E7'] = 'ç´¯è®¡äººæ•°æ ¡éªŒç»“æœ'
    ws['F7'] = 'åˆ†æ•°æ ¡éªŒç»“æœ'
    ws['F2'] = 'å¹´ä»½æ ¡éªŒ'

    # æ ¡éªŒ B2 æ˜¯å¦ä¸º 2025
    if ws['B2'].value != 2025:
        ws['G2'] = f"Ã— åº”ä¸º2025ï¼Œå½“å‰ä¸ºï¼š{ws['B2'].value}"
    else:
        ws['G2'] = "âˆš"

    region = ws['B3'].value
    suffix = "-750"
    if region == "ä¸Šæµ·":
        suffix = "-660"
    elif region == "æµ·å—":
        suffix = "-900"

    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    # ---------- ç¬¬8è¡Œç‰¹æ®Šå¤„ç† ----------
    row = 8
    curr_score = ws[f"A{row}"].value
    curr_num = ws[f"B{row}"].value
    curr_total = ws[f"C{row}"].value

    try:
        score_int = int(float(str(curr_score).split('-')[0]))
    except:
        score_int = None

    inserted = False
    if curr_total is not None:
        if curr_num is None or curr_num == "":
            # æ²¡æœ‰äººæ•° â†’ è‡ªåŠ¨è®¡ç®—
            if row == 8:
                ws[f"B{row}"] = curr_total
            else:
                prev_total = ws[f"C{row - 1}"].value
                if prev_total is not None:
                    ws[f"B{row}"] = curr_total - prev_total
        else:
            # æœ‰äººæ•°å’Œç´¯è®¡äººæ•°ä¸ä¸€è‡´æ—¶æ’å…¥è¡¥æ–­ç‚¹è¡Œ
            if curr_num != curr_total:
                try:
                    insert_score = score_int + 1
                    insert_num = curr_total - curr_num
                    ws.insert_rows(row)
                    ws[f"A{row}"] = f"{insert_score}{suffix}"  # âœ… ä»…åŠ åç¼€åœ¨æ–°å¢è¡Œ
                    ws[f"B{row}"] = insert_num
                    ws[f"C{row}"] = insert_num
                    for col in ['A', 'B', 'C', 'E', 'F']:
                        ws[f"{col}{row}"].fill = yellow_fill
                    ws[f"E{row}"] = "è¡¥æ–­ç‚¹"
                    ws[f"F{row}"] = "è¡¥æ–­ç‚¹"
                    inserted = True
                except:
                    pass

    # ä»…å½“æ²¡æœ‰æ’å…¥è¡Œæ—¶ï¼Œç¬¬8è¡ŒåŠ åç¼€
    if not inserted and score_int is not None:
        ws[f"A{row}"] = f"{score_int}{suffix}"

    # ---------- è¡¥æ–­ç‚¹é€»è¾‘ ----------
    while row < ws.max_row:
        curr = ws[f"A{row}"].value
        next = ws[f"A{row + 1}"].value
        try:
            curr_score_int = int(str(curr).split('-')[0])
            next_score_int = int(str(next).split('-')[0])
        except:
            row += 1
            continue

        if curr_score_int - next_score_int > 1:
            missing_score = curr_score_int - 1
            ws.insert_rows(row + 1)
            ws[f"A{row + 1}"] = missing_score
            ws[f"B{row + 1}"] = 0
            ws[f"C{row + 1}"] = ws[f"C{row}"].value
            for col in ['A', 'B', 'C', 'E', 'F']:
                ws[f"{col}{row + 1}"].fill = yellow_fill
            ws[f"E{row + 1}"] = "è¡¥æ–­ç‚¹"
            ws[f"F{row + 1}"] = "è¡¥æ–­ç‚¹"
        else:
            row += 1

    # ---------- æ ¡éªŒä¸è‡ªåŠ¨è¡¥äººæ•° ----------
    for row in range(8, ws.max_row + 1):
        curr_score = ws[f"A{row}"].value
        curr_num = ws[f"B{row}"].value
        curr_total = ws[f"C{row}"].value
        prev_total = ws[f"C{row - 1}"].value if row > 8 else None
        prev_score = ws[f"A{row - 1}"].value if row > 8 else None

        # è‡ªåŠ¨è¡¥äººæ•°
        if (curr_num is None or curr_num == "") and curr_total is not None:
            if row == 8:
                ws[f"B{row}"] = curr_total
                curr_num = curr_total
            elif prev_total is not None:
                try:
                    calc = curr_total - prev_total
                    ws[f"B{row}"] = calc
                    curr_num = calc
                except:
                    pass

        # æ ¡éªŒç´¯è®¡äººæ•°
        if row == 8:
            # ç¬¬8è¡Œç›´æ¥æ ‡è®°æ­£ç¡®ï¼ˆå‡è®¾ç¬¬8è¡Œç´¯è®¡äººæ•°æ­£ç¡®ï¼‰
            if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"E{row}"] = "âˆš"
            correct_total = curr_total
        else:
            if curr_num is not None and curr_total is not None and correct_total is not None:
                expected_total = correct_total + curr_num
                if expected_total == curr_total:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = "âˆš"
                    correct_total = curr_total  # æœ¬è¡Œç´¯è®¡æ­£ç¡®ï¼Œç”¨å®ƒæ›´æ–°åŸºå‡†
                else:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = f"Ã— åº”ä¸º{expected_total}"
                    correct_total = expected_total

        # æ ¡éªŒåˆ†æ•°å·®
        try:
            curr_score_num = float(str(curr_score).split('-')[0])
            prev_score_num = float(str(prev_score).split('-')[0])
        except:
            curr_score_num = prev_score_num = None

        if curr_score_num is not None and prev_score_num is not None:
            diff = prev_score_num - curr_score_num
            if diff == 1:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = "âˆš"
            else:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = f"Ã— å·®å€¼{diff}"
        else:
            if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"F{row}"] = "Ã— åˆ†æ•°éæ•°å­—ï¼Œæ— æ³•æ ¡éªŒ"

    wb.save(output_path)
    return output_path


# ============================
# ä¸“ä¸šç»„ä»£ç åŒ¹é…
# ============================

tableA_fields = [
    "å­¦æ ¡åç§°", "çœä»½", "æ‹›ç”Ÿä¸“ä¸š", "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰",
    "ä¸€çº§å±‚æ¬¡", "æ‹›ç”Ÿç§‘ç±»", "æ‹›ç”Ÿæ‰¹æ¬¡", "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰"
]

rename_mapping_B = {
    "å­¦æ ¡": "å­¦æ ¡åç§°",
    "çœä»½": "çœä»½",
    "å±‚æ¬¡": "ä¸€çº§å±‚æ¬¡",
    "ç§‘ç±»": "æ‹›ç”Ÿç§‘ç±»",
    "æ‰¹æ¬¡": "æ‹›ç”Ÿæ‰¹æ¬¡",
    "æ‹›ç”Ÿç±»å‹": "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰",
    "ä¸“ä¸š": "æ‹›ç”Ÿä¸“ä¸š",
    "å¤‡æ³¨": "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"
}


def process_data(dfA, dfB):
    dfB.rename(columns=rename_mapping_B, inplace=True)

    # æ„å»ºç»„åˆé”®ï¼ˆä¸å«å¤‡æ³¨ï¼‰ï¼šå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-æ‹›ç”Ÿç±»å‹-ä¸“ä¸š
    key_fields = [f for f in tableA_fields if f != "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"]
    dfA["ç»„åˆé”®"] = dfA[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)
    dfB["ç»„åˆé”®"] = dfB[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)

    # æ£€æŸ¥Aè¡¨å’ŒBè¡¨ä¸­ç»„åˆé”®çš„é‡å¤æ€§
    # ç»Ÿè®¡Aè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    a_key_counts = dfA["ç»„åˆé”®"].value_counts()
    # ç»Ÿè®¡Bè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    b_key_counts = dfB["ç»„åˆé”®"].value_counts()

    # æ‰¾å‡ºAè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    a_duplicate_keys = set(a_key_counts[a_key_counts > 1].index)
    # æ‰¾å‡ºBè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    b_duplicate_keys = set(b_key_counts[b_key_counts > 1].index)

    # æ„å»ºBè¡¨å­—å…¸ï¼šç»„åˆé”® â†’ è®°å½•åˆ—è¡¨
    b_dict = dfB.groupby("ç»„åˆé”®").apply(lambda x: x.to_dict("records")).to_dict()

    # å­˜å‚¨éœ€è¦æ‰‹åŠ¨è¡¥å……çš„è®°å½•ä¿¡æ¯
    manual_fill_records = []

    def get_code(row):
        key = row["ç»„åˆé”®"]
        candidates = b_dict.get(key, [])

        # æƒ…å†µ1ï¼šæ— å€™é€‰è®°å½•
        if not candidates:
            return None, None

        # æ£€æŸ¥è¯¥ç»„åˆé”®åœ¨Aè¡¨æˆ–Bè¡¨ä¸­æ˜¯å¦æœ‰é‡å¤
        has_duplicate_in_a = key in a_duplicate_keys
        has_duplicate_in_b = key in b_duplicate_keys

        # å¦‚æœAè¡¨æˆ–Bè¡¨ä¸­ä»»ä½•ä¸€ä¸ªæœ‰é‡å¤ï¼Œéœ€è¦æ‰‹åŠ¨è¡¥å……
        if has_duplicate_in_a or has_duplicate_in_b:
            # è¿”å›å®Œæ•´çš„å€™é€‰è®°å½•åˆ—è¡¨ï¼ˆåŒ…å«æ‰€æœ‰å­—æ®µä¿¡æ¯ï¼‰
            return None, candidates

        # Aè¡¨å’ŒBè¡¨ä¸­éƒ½æ²¡æœ‰é‡å¤ï¼Œä¸”Bè¡¨ä¸­åªæœ‰å”¯ä¸€å€™é€‰è®°å½•ï¼Œå¯ä»¥ç›´æ¥åŒ¹é…
        if len(candidates) == 1:
            return candidates[0]["ä¸“ä¸šç»„ä»£ç "], None

        # å¦‚æœBè¡¨ä¸­æœ‰å¤šä¸ªå€™é€‰è®°å½•ï¼ˆè¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‡ºç°ï¼Œå› ä¸ºBè¡¨æ²¡æœ‰é‡å¤ï¼‰ï¼Œè¿”å›None
        return None, None

    # åº”ç”¨åŒ¹é…é€»è¾‘
    results = dfA.apply(get_code, axis=1)
    dfA["ä¸“ä¸šç»„ä»£ç "] = results.apply(lambda x: x[0] if x[0] is not None else "")
    
    # æ”¶é›†éœ€è¦æ‰‹åŠ¨è¡¥å……çš„è®°å½•ï¼ˆåŒ…å«å®Œæ•´çš„å€™é€‰è®°å½•ä¿¡æ¯ï¼‰
    for idx, row in dfA.iterrows():
        result = results.iloc[idx]
        candidates = result[1] if result[1] is not None else []
        
        if candidates:  # æœ‰å€™é€‰è®°å½•ï¼Œè¯´æ˜éœ€è¦æ‰‹åŠ¨è¡¥å……
            # æå–å€™é€‰è®°å½•çš„è¯¦ç»†ä¿¡æ¯
            candidate_records = []
            for candidate in candidates:
                candidate_records.append({
                    "ä¸“ä¸šç»„ä»£ç ": candidate.get("ä¸“ä¸šç»„ä»£ç ", ""),
                    "å­¦æ ¡åç§°": candidate.get("å­¦æ ¡åç§°", ""),
                    "çœä»½": candidate.get("çœä»½", ""),
                    "æ‹›ç”Ÿä¸“ä¸š": candidate.get("æ‹›ç”Ÿä¸“ä¸š", ""),
                    "ä¸€çº§å±‚æ¬¡": candidate.get("ä¸€çº§å±‚æ¬¡", ""),
                    "æ‹›ç”Ÿç§‘ç±»": candidate.get("æ‹›ç”Ÿç§‘ç±»", ""),
                    "æ‹›ç”Ÿæ‰¹æ¬¡": candidate.get("æ‹›ç”Ÿæ‰¹æ¬¡", ""),
                    "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰": candidate.get("æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰", ""),
                    "å¤‡æ³¨ï¼ˆæ‹›ç”Ÿè®¡åˆ’ï¼‰": candidate.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", ""),  # Bè¡¨é‡å‘½ååçš„å¤‡æ³¨å­—æ®µ
                })
            
            manual_fill_records.append({
                "ç´¢å¼•": idx,
                "å­¦æ ¡åç§°": row.get("å­¦æ ¡åç§°", ""),
                "çœä»½": row.get("çœä»½", ""),
                "æ‹›ç”Ÿä¸“ä¸š": row.get("æ‹›ç”Ÿä¸“ä¸š", ""),
                "ä¸€çº§å±‚æ¬¡": row.get("ä¸€çº§å±‚æ¬¡", ""),
                "æ‹›ç”Ÿç§‘ç±»": row.get("æ‹›ç”Ÿç§‘ç±»", ""),
                "æ‹›ç”Ÿæ‰¹æ¬¡": row.get("æ‹›ç”Ÿæ‰¹æ¬¡", ""),
                "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰": row.get("æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰", ""),
                "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰": row.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", ""),  # Aè¡¨çš„ä¸“ä¸šå¤‡æ³¨å­—æ®µ
                "å€™é€‰è®°å½•": candidate_records  # å®Œæ•´çš„å€™é€‰è®°å½•åˆ—è¡¨
            })

    return dfA, manual_fill_records


# ========== å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå– ==========

def fetch_images_static(url, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    image_paths = []
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        imgs = soup.find_all("img")
        for idx, img in enumerate(imgs, 1):
            src = img.get("src")
            if not src:
                continue
            full_url = urljoin(url, src)
            # è·³è¿‡ base64 æˆ– blob ç±»å‹
            if full_url.startswith("data:") or full_url.startswith("blob:"):
                continue
            ext = os.path.splitext(urlparse(full_url).path)[1] or ".jpg"
            filename = f"img_{idx:03d}{ext}"
            path = os.path.join(output_folder, filename)
            try:
                img_resp = requests.get(full_url, timeout=10)
                if img_resp.status_code != 200:
                    continue
                content_type = img_resp.headers.get("content-type", "")
                # ä»…ä¿å­˜çœŸæ­£çš„å›¾ç‰‡ç±»å‹
                if not content_type.startswith("image/"):
                    continue
                img_data = img_resp.content
                # éªŒè¯å›¾ç‰‡æ˜¯å¦å¯è¯†åˆ«
                try:
                    Image.open(io.BytesIO(img_data))
                except Exception:
                    continue
                with open(path, "wb") as f:
                    f.write(img_data)
                image_paths.append(path)
            except Exception:
                continue
    except Exception as e:
        raise Exception(f"é™æ€æ¨¡å¼åŠ è½½å¤±è´¥: {e}")
    return image_paths


def images_to_pdf(image_paths, pdf_path):
    images = []
    for path in sorted(image_paths):
        try:
            img = Image.open(path).convert("RGB")
            images.append(img)
        except Exception:
            continue
    if images:
        images[0].save(pdf_path, save_all=True, append_images=images[1:])
        return True
    return False


# ============================
# Streamlité¡µé¢å¸ƒå±€
# ============================
# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š æ•°æ®å¤„ç†å·¥å…·")
st.markdown("---")

# åŠŸèƒ½è¯´æ˜
with st.expander("ğŸ“Œ åŠŸèƒ½è¯´æ˜", expanded=True):
    st.markdown("""
    1. ä¸Šä¼ çš„æ–‡ä»¶ä½¿ç”¨åº“ä¸­ä¸“ä¸šåˆ†ã€é™¢æ ¡åˆ†ã€æ‹›ç”Ÿè®¡åˆ’ã€ä¸€åˆ†ä¸€æ®µçš„æ¨¡æ¿ï¼Œç›´æ¥ä¸Šä¼ å³å¯ï¼Œæ— éœ€åˆ å‡
    2. å¤‡æ³¨æ£€æŸ¥ä¸­ï¼Œæ£€æŸ¥å‡ºæ¥æ‹¬å·æœ‰é—®é¢˜çš„å†…å®¹è¿˜éœ€è¦è‡ªå·±å†è¿‡ä¸€éï¼›æ•´ä¸ªæ–‡ä»¶çš„å¤‡æ³¨éœ€è¦å¤§æ¦‚çœ‹çœ‹æœ‰æ²¡æœ‰é”™åˆ«å­—
    3. æ ¡éªŒä¸€åˆ†ä¸€æ®µæ—¶ï¼Œå†…å®¹ä¸èƒ½ä¸ºæ–‡æœ¬æ ¼å¼
    4. ä½¿ç”¨ä¸“ä¸šç»„ä»£ç åŒ¹é…æ—¶ï¼Œä¸¤ä»½æ–‡ä»¶ä¸­çš„â€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹â€è¿™äº›å­—æ®µéœ€è¦ä¿æŒä¸€è‡´
    """)

# æ›´æ–°æ—¥å¿—å¯¹è¯æ¡†
with st.expander("ğŸ“¢ ç‰ˆæœ¬æ›´æ–°ï¼ˆ2025.9.26æ›´æ–°ï¼‰ï¼ˆå¿…çœ‹ï¼ï¼‰", expanded=False):
    st.markdown("""
    ### 2025.9.26æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†ä¸­æœ€é«˜åˆ†çš„æå–é€»è¾‘  
    â€¢ æ–°å¢äº†è‰ºä½“ç±»é™¢æ ¡åˆ†æå–åŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ è‰ºä½“ç±»ä¸“ä¸šåˆ†æ¨¡æ¿ï¼ˆå¯æŠŠç‰¹æ®Šç±»å‹<å¦‚ï¼šä¸­å¤–åˆä½œåŠå­¦>çš„å¤‡æ³¨åœ¨ä¸“ä¸šåˆ†ä¸­æ”¾åˆ°ä¸“ä¸šæ–¹å‘å†æå–ï¼‰

    ### å†å²æ›´æ–°

    #### 2025.4.14æ›´æ–°
    â€¢ æ‹›ç”Ÿä»£ç å’Œä¸“ä¸šä»£ç ä¿æŒæ–‡æœ¬æ ¼å¼  
    â€¢ å¢åŠ åŠŸèƒ½è¯´æ˜  
    â€¢ ä¼˜åŒ–å·¥å…·ç•Œé¢  

    #### 2025.4.16æ›´æ–°
    â€¢ ä¼˜åŒ–äº†é™¢æ ¡åˆ†æå–å¤„ç†é€»è¾‘  

    #### 2025.5.22æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†æå–ä¸­å½•å–äººæ•°çš„å¤„ç†é€»è¾‘ï¼ˆå»ºè®®è¿›è¡ŒæŠ½æŸ¥ï¼‰  
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†æœ€é«˜åˆ†ã€å¹³å‡åˆ†ã€æœ€ä½åˆ†çš„æ ¡éªŒï¼Œä¼šåœ¨æœ€ååŠ ä¸€åˆ—æ ¡éªŒç»“æœ  

    #### 2025.5.23æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†å­¦æ ¡åç§°å’Œæ‹›ç”Ÿä¸“ä¸šçš„åŒ¹é…  

    #### 2025.5.27æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­ï¼Œå¢åŠ äº†"æ‹›ç”Ÿç§‘ç±»"ã€"é¦–é€‰ç§‘ç›®"ã€"é€‰ç§‘è¦æ±‚"ï¼Œ"æ¬¡é€‰ç§‘ç›®"çš„å¤„ç†  
      - å­¦ä¸šæ¡¥æä¾›çš„"3+1+2"çœä»½çš„æ‹›ç”Ÿç§‘ç±»ä¸º"ç‰©ç†"ã€"å†å²"ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†çš„"ç‰©ç†ç±»"ã€"å†å²ç±»"  
      - "3+1+2"çœä»½çš„é¦–é€‰ç§‘ç›®å¯ä»¥ç›´æ¥æ ¹æ®æ‹›ç”Ÿç§‘ç±»æå–  
      - æ–°å¢äº†é€‰ç§‘è¦æ±‚ã€æ¬¡é€‰ç§‘ç›®çš„å¤„ç†ï¼Œå¯ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ï¼ˆå¤„ç†åçš„æ•°æ®åœ¨æ–‡æ¡£æœ€åå‡ åˆ—ï¼‰  

    #### 2025.5.30æ›´æ–°
    æ–°å¢"ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"  
      - å¯ç›´æ¥æ ¡éªŒåˆ†æ•°ã€ç´¯è®¡äººæ•°  
      - è‡ªåŠ¨è¡¥æ–­ç‚¹  
      - è‡ªåŠ¨å¢åŠ "æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  

    ### 2025.6.6æ›´æ–°
    "ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"ä¼˜åŒ–  
      - è‡ªåŠ¨è¡¥å……"æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  
      - åªæœ‰ç´¯è®¡äººæ•°æ²¡æœ‰äººæ•°æ—¶ï¼Œå¯è®¡ç®—äººæ•°ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ  
      - è¡¥æ–­ç‚¹çš„åˆ†æ•°æ ‡æ³¨é¢œè‰²ï¼Œå¹¶åœ¨åˆ†æ•°å’Œäººæ•°æ ¡éªŒä¸­æ ‡æ³¨"è¡¥æ–­ç‚¹"

    ### 2025.6.12æ›´æ–°
    é™¢æ ¡åˆ†æå–é€»è¾‘æ›´æ–°  
      - æå–æœ€é«˜åˆ†æ”¹ä¸ºå–åŒä¸€ä¸ªâ€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹ï¼ˆ-ä¸“ä¸šç»„ä»£ç ï¼‰â€ä¸‹çš„æœ€é«˜åˆ†

    ### 2025.6.14æ›´æ–°
    ä¸“ä¸šç»„ä»£ç åŒ¹é…åŠŸèƒ½  
      - éœ€è¦ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿å’Œåº“ä¸­æ‹›ç”Ÿè®¡åˆ’å¯¼å‡ºæ¨¡æ¿
      - æŠŠåº“ä¸­å¯¼å‡ºæ‹›ç”Ÿè®¡åˆ’ç±»å‹å°½é‡è¡¥å……å®Œæ•´ï¼Œå¦åˆ™å®¹æ˜“å‡ºé”™
      - åŒ¹é…ç»“æœéœ€è¦æ£€æŸ¥

    ### 2025.7.7æ›´æ–°
    å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æŠ“å–åŠŸèƒ½  
      - æŠ“å–å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡
      - å¦‚æœæŠ“å–åˆ°çš„å›¾ç‰‡æ¯”è¾ƒå¤šï¼Œâ€œä¸‹è½½PDFâ€çš„å¼¹æ¡†ä¼šå‡ºç°æ¯”è¾ƒæ…¢
      - æ³¨æ„ï¼šåªèƒ½æŠ“å–é™æ€é¡µé¢çš„å›¾ç‰‡ï¼ŒåŠ¨æ€é¡µé¢å’Œæœ‰é™åˆ¶çš„ç½‘é¡µæ— æ³•æŠ“å–


    """)

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
    [
        "é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰",
        "é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰",
        "å­¦ä¸šæ¡¥æ•°æ®å¤„ç†",
        "ä¸€åˆ†ä¸€æ®µæ ¡éªŒ",
        "ä¸“ä¸šç»„ä»£ç åŒ¹é…ï¼ˆå¯ä»¥ç”¨ï¼Œéœ€è¦æ£€æŸ¥ï¼ï¼‰",
        "å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–",
        "æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹"
    ]
)

# ====================== é™¢æ ¡åˆ†æå– ======================
with tab1:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="score_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_score_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_score_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰ ======================
with tab2:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file_new = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="new_score_file")

    if uploaded_file_new is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file_new.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_new_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_new_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file_new.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # è°ƒç”¨æ–°æ¨¡æ¿å¤„ç†å‡½æ•°
                    if percent_complete == 100:
                        output_path = process_new_template_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†ï¼ˆè‰ºä½“ç±»ï¼‰æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== å­¦ä¸šæ¡¥æ•°æ®å¤„ç† ======================
with tab3:
    st.header("å­¦ä¸šæ¡¥æ•°æ®å¤„ç†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="remarks_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_remarks"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_remarks.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())


                # è¿›åº¦å›è°ƒå‡½æ•°
                def update_progress(current, total):
                    percent = int((current / total) * 100)
                    progress_bar.progress(percent)
                    status_text.text(f"å¤„ç†ä¸­... {percent}%")


                # å¤„ç†æ–‡ä»¶
                output_path = process_remarks_file(temp_file, progress_callback=update_progress)

                # å¤„ç†å®Œæˆ
                progress_bar.progress(100)
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸€åˆ†ä¸€æ®µæ ¡éªŒ ======================
with tab4:
    st.header("ä¸€åˆ†ä¸€æ®µæ ¡éªŒ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="segmentation_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_segmentation"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "ä¸€åˆ†ä¸€æ®µ.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_segmentation_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_segmentation_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()

                b64 = base64.b64encode(bytes_data).decode()

                # ä» output_path æå–åŸæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                base_name = os.path.splitext(os.path.basename(output_path))[0]

                # æ‹¼æ¥æ–°æ–‡ä»¶å
                new_filename = f"{base_name}.xlsx"

                # æ„é€ ä¸‹è½½é“¾æ¥
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="{new_filename}">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'

                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸“ä¸šç»„ä»£ç åŒ¹é… ======================
with tab5:
    st.header("ä¸“ä¸šç»„ä»£ç åŒ¹é…ï¼ˆéœ€è¦æ£€æŸ¥ï¼ï¼‰")

    # åˆå§‹åŒ–session state
    if 'match_result_df' not in st.session_state:
        st.session_state.match_result_df = None
    if 'manual_fill_records' not in st.session_state:
        st.session_state.manual_fill_records = []
    if 'manual_selections' not in st.session_state:
        st.session_state.manual_selections = {}
    if 'temp_fileA_path' not in st.session_state:
        st.session_state.temp_fileA_path = None
    if 'temp_fileB_path' not in st.session_state:
        st.session_state.temp_fileB_path = None

    uploaded_fileA = st.file_uploader("ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿", type=["xls", "xlsx"], key="fileA")
    uploaded_fileB = st.file_uploader("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ•°æ®å¯¼å‡ºæ–‡ä»¶", type=["xls", "xlsx"], key="fileB")

    if uploaded_fileA and uploaded_fileB:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶ï¼š{uploaded_fileA.name} å’Œ {uploaded_fileB.name}")

        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("ç­‰å¾…å¼€å§‹å¤„ç†...")

        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="start_match"):
            try:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_fileA = "tempA.xlsx"
                temp_fileB = "tempB.xlsx"
                with open(temp_fileA, "wb") as f:
                    f.write(uploaded_fileA.getbuffer())
                with open(temp_fileB, "wb") as f:
                    f.write(uploaded_fileB.getbuffer())

                st.session_state.temp_fileA_path = temp_fileA
                st.session_state.temp_fileB_path = temp_fileB

                status_text.text("è¯»å–æ–‡ä»¶...")
                progress_bar.progress(10)

                dfA = pd.read_excel(temp_fileA, header=2)
                dfB = pd.read_excel(temp_fileB)

                status_text.text("å¼€å§‹å¤„ç†æ•°æ®...")
                progress_bar.progress(30)

                result_df, manual_fill_records = process_data(dfA, dfB)

                st.session_state.match_result_df = result_df.copy()
                st.session_state.manual_fill_records = manual_fill_records
                st.session_state.manual_selections = {}

                status_text.text("å¤„ç†å®Œæˆï¼")
                progress_bar.progress(100)

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                total_count = len(result_df)
                matched_count = len(result_df[result_df["ä¸“ä¸šç»„ä»£ç "].notna() & (result_df["ä¸“ä¸šç»„ä»£ç "] != "")])
                manual_count = len(manual_fill_records)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", total_count)
                with col2:
                    st.metric("è‡ªåŠ¨åŒ¹é…æˆåŠŸ", matched_count)
                with col3:
                    st.metric("éœ€è¦æ‰‹åŠ¨è¡¥å……", manual_count, delta=f"{manual_count}æ¡")

                if manual_count > 0:
                    st.warning(f"âš ï¸ å‘ç° {manual_count} æ¡è®°å½•éœ€è¦æ‰‹åŠ¨è¡¥å……ä¸“ä¸šç»„ä»£ç ")

            except Exception as e:
                st.error(f"å¤„ç†é”™è¯¯ï¼š{e}")
                import traceback
                st.error(traceback.format_exc())

        # æ˜¾ç¤ºæ‰‹åŠ¨è¡¥å……ç•Œé¢ï¼ˆå¼¹æ¡†å½¢å¼ï¼‰
        if st.session_state.match_result_df is not None and len(st.session_state.manual_fill_records) > 0:
            st.markdown("---")
            st.subheader("ğŸ“ æ‰‹åŠ¨è¡¥å……ä¸“ä¸šç»„ä»£ç ")
            
            # åˆå§‹åŒ–å½“å‰å¤„ç†çš„è®°å½•ç´¢å¼•
            if 'current_record_idx' not in st.session_state:
                st.session_state.current_record_idx = 0
            
            total_records = len(st.session_state.manual_fill_records)
            current_record = st.session_state.manual_fill_records[st.session_state.current_record_idx]
            idx = current_record["ç´¢å¼•"]
            key = f"manual_select_{idx}"
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_text = f"å¤„ç†è¿›åº¦ï¼š{st.session_state.current_record_idx + 1} / {total_records}"
            st.progress((st.session_state.current_record_idx + 1) / total_records, text=progress_text)
            
            # å¼¹æ¡†å½¢å¼æ˜¾ç¤ºå½“å‰è®°å½•
            with st.expander(f"ğŸ“‹ è®°å½• {st.session_state.current_record_idx + 1}ï¼š{current_record['å­¦æ ¡åç§°']} - {current_record['æ‹›ç”Ÿä¸“ä¸š']}", expanded=True):
                st.markdown("### å½“å‰è®°å½•ä¿¡æ¯ï¼ˆä¸“ä¸šåˆ†æ–‡ä»¶ï¼‰")
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**å­¦æ ¡åç§°ï¼š** {current_record['å­¦æ ¡åç§°']}")
                    st.write(f"**çœä»½ï¼š** {current_record['çœä»½']}")
                    st.write(f"**æ‹›ç”Ÿä¸“ä¸šï¼š** {current_record['æ‹›ç”Ÿä¸“ä¸š']}")
                    st.write(f"**ä¸€çº§å±‚æ¬¡ï¼š** {current_record['ä¸€çº§å±‚æ¬¡']}")
                with col2:
                    st.write(f"**æ‹›ç”Ÿç§‘ç±»ï¼š** {current_record['æ‹›ç”Ÿç§‘ç±»']}")
                    st.write(f"**æ‹›ç”Ÿæ‰¹æ¬¡ï¼š** {current_record['æ‹›ç”Ÿæ‰¹æ¬¡']}")
                    st.write(f"**æ‹›ç”Ÿç±»å‹ï¼š** {current_record['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰']}")
                    # æ˜¾ç¤ºå½“å‰å·²é€‰æ‹©çš„å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
                    current_value = st.session_state.manual_selections.get(key, "")
                    if current_value:
                        st.success(f"**å·²é€‰æ‹©ï¼š** {current_value}")
                
                # æ˜¾ç¤ºä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰å­—æ®µ
                if current_record.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"):
                    st.markdown("**ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰ï¼š**")
                    st.info(current_record.get("ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰", ""))
                
                st.markdown("---")
                st.markdown("### æ‹›ç”Ÿè®¡åˆ’ä¸­çš„å€™é€‰è®°å½•")
                
                # æ˜¾ç¤ºå€™é€‰è®°å½•
                candidate_records = current_record.get("å€™é€‰è®°å½•", [])
                if candidate_records and len(candidate_records) > 0:
                    # æ˜¾ç¤ºå€™é€‰è®°å½•çš„è¯¦ç»†ä¿¡æ¯è¡¨æ ¼
                    st.markdown("**å€™é€‰è®°å½•è¯¦æƒ…ï¼š**")
                    candidate_df = pd.DataFrame(candidate_records)
                    # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œä¸“ä¸šç»„ä»£ç æ”¾åœ¨æœ€å‰é¢
                    if 'ä¸“ä¸šç»„ä»£ç ' in candidate_df.columns:
                        cols = ['ä¸“ä¸šç»„ä»£ç '] + [c for c in candidate_df.columns if c != 'ä¸“ä¸šç»„ä»£ç ']
                        candidate_df = candidate_df[cols]
                    st.dataframe(candidate_df, use_container_width=True, hide_index=True)
                    
                    # æ„å»ºé€‰é¡¹åˆ—è¡¨ï¼ˆæ˜¾ç¤ºä¸“ä¸šç»„ä»£ç ï¼‰
                    candidate_options = []
                    for i, cand in enumerate(candidate_records):
                        code = cand.get("ä¸“ä¸šç»„ä»£ç ", "")
                        if code and str(code).strip():
                            candidate_options.append(str(code).strip())
                    
                    # å»é‡
                    candidate_options = list(set(candidate_options))
                    
                    if candidate_options:
                        # æ·»åŠ "è¯·é€‰æ‹©"é€‰é¡¹
                        options = ["è¯·é€‰æ‹©"] + candidate_options
                        # è·å–å½“å‰é€‰æ‹©ï¼ˆå¦‚æœæœ‰ï¼‰
                        current_selection = st.session_state.manual_selections.get(key, "è¯·é€‰æ‹©")
                        default_index = 0
                        if current_selection in options:
                            default_index = options.index(current_selection)
                        
                        selected_code = st.selectbox(
                            "é€‰æ‹©ä¸“ä¸šç»„ä»£ç ",
                            options,
                            index=default_index,
                            key=key
                        )
                        
                        if selected_code != "è¯·é€‰æ‹©":
                            st.session_state.manual_selections[key] = selected_code
                        else:
                            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†"è¯·é€‰æ‹©"ï¼Œæ¸…é™¤ä¹‹å‰çš„é€‰æ‹©
                            if key in st.session_state.manual_selections:
                                del st.session_state.manual_selections[key]
                    else:
                        st.warning("âš ï¸ å€™é€‰è®°å½•ä¸­æ²¡æœ‰ä¸“ä¸šç»„ä»£ç ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥")
                        input_key = f"{key}_input"
                        prev_value = st.session_state.get(input_key, "")
                        manual_input = st.text_input(
                            "æ‰‹åŠ¨è¾“å…¥ä¸“ä¸šç»„ä»£ç ",
                            value=prev_value,
                            key=input_key
                        )
                        if manual_input and manual_input.strip():
                            st.session_state.manual_selections[key] = manual_input.strip()
                        elif key in st.session_state.manual_selections:
                            del st.session_state.manual_selections[key]
                else:
                    st.warning("âš ï¸ è¯¥è®°å½•æ²¡æœ‰å€™é€‰è®°å½•ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥")
                    input_key = f"{key}_input"
                    prev_value = st.session_state.get(input_key, "")
                    manual_input = st.text_input(
                        "æ‰‹åŠ¨è¾“å…¥ä¸“ä¸šç»„ä»£ç ",
                        value=prev_value,
                        key=input_key
                    )
                    if manual_input and manual_input.strip():
                        st.session_state.manual_selections[key] = manual_input.strip()
                    elif key in st.session_state.manual_selections:
                        del st.session_state.manual_selections[key]
            
            # å¯¼èˆªæŒ‰é’®
            col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
            with col1:
                if st.button("â®ï¸ ç¬¬ä¸€æ¡", disabled=st.session_state.current_record_idx == 0):
                    st.session_state.current_record_idx = 0
                    st.rerun()
            with col2:
                if st.button("â—€ï¸ ä¸Šä¸€æ¡", disabled=st.session_state.current_record_idx == 0):
                    st.session_state.current_record_idx -= 1
                    st.rerun()
            with col3:
                if st.button("â–¶ï¸ ä¸‹ä¸€æ¡", disabled=st.session_state.current_record_idx >= total_records - 1):
                    st.session_state.current_record_idx += 1
                    st.rerun()
            with col4:
                if st.button("â­ï¸ æœ€åä¸€æ¡", disabled=st.session_state.current_record_idx >= total_records - 1):
                    st.session_state.current_record_idx = total_records - 1
                    st.rerun()
            
            st.markdown("---")
            
            # åº”ç”¨æ‰€æœ‰æ‰‹åŠ¨é€‰æ‹©å¹¶å®Œæˆ
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("âœ… åº”ç”¨å½“å‰é€‰æ‹©å¹¶ç»§ç»­", type="primary", use_container_width=True):
                    # åº”ç”¨å½“å‰è®°å½•çš„é€‰æ‹©
                    selected_code = None
                    if key in st.session_state.manual_selections:
                        selected_code = st.session_state.manual_selections[key]
                    elif f"{key}_input" in st.session_state:
                        input_value = st.session_state[f"{key}_input"]
                        if input_value and input_value.strip():
                            selected_code = input_value.strip()
                    
                    if selected_code and selected_code.strip():
                        updated_df = st.session_state.match_result_df.copy()
                        updated_df.at[idx, "ä¸“ä¸šç»„ä»£ç "] = selected_code.strip()
                        st.session_state.match_result_df = updated_df
                        st.success(f"âœ… å·²åº”ç”¨è®°å½• {st.session_state.current_record_idx + 1} çš„é€‰æ‹©ï¼š{selected_code.strip()}")
                    
                    # ç§»åŠ¨åˆ°ä¸‹ä¸€æ¡
                    if st.session_state.current_record_idx < total_records - 1:
                        st.session_state.current_record_idx += 1
                    st.rerun()
            
            with col2:
                if st.button("âœ… åº”ç”¨æ‰€æœ‰é€‰æ‹©å¹¶å®Œæˆ", type="primary", use_container_width=True):
                    # æ›´æ–°ç»“æœæ•°æ®æ¡†
                    updated_df = st.session_state.match_result_df.copy()
                    applied_count = 0
                    
                    for record in st.session_state.manual_fill_records:
                        idx = record["ç´¢å¼•"]
                        key = f"manual_select_{idx}"
                        input_key = f"{key}_input"
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰é€‰æ‹©
                        selected_code = None
                        
                        # å…ˆæ£€æŸ¥selectboxçš„é€‰æ‹©
                        if key in st.session_state.manual_selections:
                            selected_code = st.session_state.manual_selections[key]
                            if selected_code == "è¯·é€‰æ‹©":
                                selected_code = None
                        elif key in st.session_state:
                            selected_code = st.session_state[key]
                            if selected_code == "è¯·é€‰æ‹©":
                                selected_code = None
                        
                        # å¦‚æœæ²¡æœ‰selectboxé€‰æ‹©ï¼Œæ£€æŸ¥text_input
                        if not selected_code and input_key in st.session_state:
                            input_value = st.session_state[input_key]
                            if input_value and input_value.strip():
                                selected_code = input_value.strip()
                        
                        # åº”ç”¨é€‰æ‹©
                        if selected_code and selected_code.strip():
                            updated_df.at[idx, "ä¸“ä¸šç»„ä»£ç "] = selected_code.strip()
                            applied_count += 1

                    st.session_state.match_result_df = updated_df
                    if applied_count > 0:
                        st.success(f"âœ… å·²åº”ç”¨ {applied_count} æ¡è®°å½•çš„æ‰‹åŠ¨é€‰æ‹©ï¼")
                    else:
                        st.warning("âš ï¸ æ²¡æœ‰åº”ç”¨ä»»ä½•é€‰æ‹©")
                    st.rerun()

        # å¯¼å‡ºç»“æœ
        if st.session_state.match_result_df is not None:
            st.markdown("---")
            st.subheader("ğŸ“¥ å¯¼å‡ºç»“æœ")
            
            # ç§»é™¤ä¸´æ—¶åˆ—
            export_df = st.session_state.match_result_df.drop(columns=["ç»„åˆé”®"], errors='ignore')
            
            # å¯¼å‡ºç»“æœåˆ°å†…å­˜
            output = BytesIO()
            export_df.to_excel(output, index=False)
            output.seek(0)

            b64 = base64.b64encode(output.read()).decode()
            href = f'<a href="data:application/octet-stream;base64,{b64}" download="ä¸“ä¸šç»„ä»£ç åŒ¹é…ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½åŒ¹é…ç»“æœ</a>'
            st.markdown(href, unsafe_allow_html=True)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶æŒ‰é’®
            if st.button("æ¸…ç†ä¸´æ—¶æ–‡ä»¶", key="cleanup_temp"):
                if st.session_state.temp_fileA_path and os.path.exists(st.session_state.temp_fileA_path):
                    os.remove(st.session_state.temp_fileA_path)
                if st.session_state.temp_fileB_path and os.path.exists(st.session_state.temp_fileB_path):
                    os.remove(st.session_state.temp_fileB_path)
                st.session_state.temp_fileA_path = None
                st.session_state.temp_fileB_path = None
                st.success("ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")

    else:
        st.info("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶")

# ====================== tab5ï¼šç½‘é¡µå›¾ç‰‡æå–PDF ======================
with tab6:
    st.header("å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–")

    url = st.text_input("è¯·è¾“å…¥å°±ä¸šè´¨é‡æŠ¥å‘Šç½‘é¡µé“¾æ¥", placeholder="ä¾‹å¦‚ï¼šhttps://www.example.com/report.html")

    if st.button("å¼€å§‹æå–å›¾ç‰‡"):
        if not url:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘é¡µé“¾æ¥")
        else:
            output_folder = tempfile.mkdtemp()
            with st.spinner("æ­£åœ¨æŠ“å–å›¾ç‰‡..."):
                try:
                    image_paths = fetch_images_static(url, output_folder)
                except Exception as e:
                    st.error(f"æŠ“å–å¤±è´¥: {e}")
                    image_paths = []

            if image_paths:
                st.success(f"æˆåŠŸæå–åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

                with st.expander(f"ç‚¹å‡»æŸ¥çœ‹ {len(image_paths)} å¼ å›¾ç‰‡é¢„è§ˆ", expanded=False):
                    cols = st.columns(5)
                    for i, path in enumerate(image_paths):
                        cols[i % 5].image(path, width=120)

                pdf_path = os.path.join(output_folder, "å›¾ç‰‡åˆé›†.pdf")
                if images_to_pdf(image_paths, pdf_path):
                    with open(pdf_path, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è½½åˆæˆPDF", f, file_name="å°±ä¸šè´¨é‡æŠ¥å‘Š.pdf", mime="application/pdf")
                else:
                    st.warning("PDFåˆæˆå¤±è´¥")
            else:
                st.warning("æœªæŠ“å–åˆ°ä»»ä½•å›¾ç‰‡")


# ============================
# æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ä¸è½¬æ¢å·¥å…·ç›¸å…³å‡½æ•°
# ============================

def generate_plan_score_key(item):
    """ç”Ÿæˆæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†çš„ç»„åˆé”®"""
    year = str(item.get('å¹´ä»½', '') or '').strip()
    province = str(item.get('çœä»½', '') or '').strip()
    school = str(item.get('å­¦æ ¡', '') or '').strip()
    subject = str(item.get('ç§‘ç±»', '') or '').strip()
    batch = str(item.get('æ‰¹æ¬¡', '') or '').strip()
    major = str(item.get('ä¸“ä¸š', '') or '').strip()
    level = str(item.get('å±‚æ¬¡', '') or '').strip()
    group_code = str(item.get('ä¸“ä¸šç»„ä»£ç ', '') or '').strip()
    return f"{year}|{province}|{school}|{subject}|{batch}|{major}|{level}|{group_code}"


def generate_plan_college_key(item):
    """ç”Ÿæˆæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†çš„ç»„åˆé”®"""
    year = str(item.get('å¹´ä»½', '') or '').strip()
    province = str(item.get('çœä»½', '') or '').strip()
    school = str(item.get('å­¦æ ¡', '') or '').strip()
    subject = str(item.get('ç§‘ç±»', '') or '').strip()
    batch = str(item.get('æ‰¹æ¬¡', '') or '').strip()
    group_code = str(item.get('ä¸“ä¸šç»„ä»£ç ', '') or '').strip()
    return f"{year}|{province}|{school}|{subject}|{batch}|{group_code}"


def compare_plan_vs_score(plan_df, score_df):
    """æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†"""
    plan_score_results = []
    score_key_set = set()

    # ä¸ºä¸“ä¸šåˆ†æ•°æ®å»ºç«‹ç´¢å¼•
    for _, item in score_df.iterrows():
        key = generate_plan_score_key(item.to_dict())
        score_key_set.add(key)

    # æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’æ•°æ®
    for idx, row in plan_df.iterrows():
        item = row.to_dict()
        key = generate_plan_score_key(item)
        exists = key in score_key_set

        plan_score_results.append({
            'index': idx + 1,
            'originalIndex': idx,
            'keyFields': {
                'å¹´ä»½': item.get('å¹´ä»½', '') or '',
                'çœä»½': item.get('çœä»½', '') or '',
                'å­¦æ ¡': item.get('å­¦æ ¡', '') or '',
                'ç§‘ç±»': item.get('ç§‘ç±»', '') or '',
                'æ‰¹æ¬¡': item.get('æ‰¹æ¬¡', '') or '',
                'ä¸“ä¸š': item.get('ä¸“ä¸š', '') or '',
                'å±‚æ¬¡': item.get('å±‚æ¬¡', '') or '',
                'ä¸“ä¸šç»„ä»£ç ': item.get('ä¸“ä¸šç»„ä»£ç ', '') or ''
            },
            'exists': exists,
            'otherInfo': {
                'æ‹›ç”Ÿäººæ•°': item.get('æ‹›ç”Ÿäººæ•°', '') or '',
                'å­¦è´¹': item.get('å­¦è´¹', '') or '',
                'å­¦åˆ¶': item.get('å­¦åˆ¶', '') or '',
                'ä¸“ä¸šä»£ç ': item.get('ä¸“ä¸šä»£ç ', '') or '',
                'æ‹›ç”Ÿä»£ç ': item.get('æ‹›ç”Ÿä»£ç ', '') or '',
                'æ•°æ®æ¥æº': item.get('æ•°æ®æ¥æº', '') or '',
                'å¤‡æ³¨': item.get('å¤‡æ³¨', '') or '',
                'æ‹›ç”Ÿç±»å‹': item.get('æ‹›ç”Ÿç±»å‹', '') or '',
                'ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', '') or '',
                'ä¸“ä¸šé€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '') or ''
            }
        })

    return plan_score_results


def compare_plan_vs_college(plan_df, college_df):
    """æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†"""
    plan_college_results = []
    college_key_set = set()

    # ä¸ºé™¢æ ¡åˆ†æ•°æ®å»ºç«‹ç´¢å¼•
    for _, item in college_df.iterrows():
        key = generate_plan_college_key(item.to_dict())
        college_key_set.add(key)

    # æ¯”å¯¹æ‹›ç”Ÿè®¡åˆ’æ•°æ®
    for idx, row in plan_df.iterrows():
        item = row.to_dict()
        key = generate_plan_college_key(item)
        exists = key in college_key_set

        plan_college_results.append({
            'index': idx + 1,
            'originalIndex': idx,
            'keyFields': {
                'å¹´ä»½': item.get('å¹´ä»½', '') or '',
                'çœä»½': item.get('çœä»½', '') or '',
                'å­¦æ ¡': item.get('å­¦æ ¡', '') or '',
                'ç§‘ç±»': item.get('ç§‘ç±»', '') or '',
                'æ‰¹æ¬¡': item.get('æ‰¹æ¬¡', '') or '',
                'ä¸“ä¸šç»„ä»£ç ': item.get('ä¸“ä¸šç»„ä»£ç ', '') or ''
            },
            'exists': exists,
            'otherInfo': {
                'ä¸“ä¸š': item.get('ä¸“ä¸š', '') or '',
                'å±‚æ¬¡': item.get('å±‚æ¬¡', '') or '',
                'æ‹›ç”Ÿäººæ•°': item.get('æ‹›ç”Ÿäººæ•°', '') or '',
                'å­¦è´¹': item.get('å­¦è´¹', '') or '',
                'å­¦åˆ¶': item.get('å­¦åˆ¶', '') or '',
                'ä¸“ä¸šä»£ç ': item.get('ä¸“ä¸šä»£ç ', '') or '',
                'æ‹›ç”Ÿä»£ç ': item.get('æ‹›ç”Ÿä»£ç ', '') or '',
                'æ•°æ®æ¥æº': item.get('æ•°æ®æ¥æº', '') or '',
                'å¤‡æ³¨': item.get('å¤‡æ³¨', '') or '',
                'æ‹›ç”Ÿç±»å‹': item.get('æ‹›ç”Ÿç±»å‹', '') or '',
                'ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', '') or '',
                'ä¸“ä¸šé€‰ç§‘è¦æ±‚': item.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '') or ''
            }
        })

    return plan_college_results


def get_first_subject(category):
    """è·å–é¦–é€‰ç§‘ç›®ï¼šæ ¹æ®æ‹›ç”Ÿç§‘ç±»çš„ç¬¬ä¸€ä¸ªå­—"""
    if not category:
        return ''
    category_str = str(category)
    if 'ç‰©ç†ç±»' in category_str or 'ç‰©ç†' in category_str:
        return 'ç‰©'
    elif 'å†å²ç±»' in category_str or 'å†å²' in category_str:
        return 'å†'
    return ''


def convert_level(level):
    """è½¬æ¢å±‚æ¬¡å­—æ®µ"""
    if not level:
        return ''
    level_str = str(level).lower()
    if 'ä¸“ç§‘' in level_str or 'é«˜èŒ' in level_str:
        return 'ä¸“ç§‘(é«˜èŒ)'
    elif 'æœ¬ç§‘' in level_str:
        return 'æœ¬ç§‘(æ™®é€š)'
    return level


def extract_required_subjects(text):
    """æå–å¿…é€‰ç§‘ç›®ï¼ˆå¤„ç†"ç‰©åŒ–ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼ï¼‰"""
    if not text:
        return []

    subjects = []
    subject_map = {
        'ç‰©ç†': 'ç‰©', 'åŒ–å­¦': 'åŒ–', 'ç”Ÿç‰©': 'ç”Ÿ', 'å†å²': 'å†',
        'åœ°ç†': 'åœ°', 'æ”¿æ²»': 'æ”¿', 'æŠ€æœ¯': 'æŠ€'
    }

    # æ¸…ç†æ–‡æœ¬ï¼Œä¿ç•™ä¸­æ–‡å’Œé¡¿å·ã€é€—å·
    import re
    clean_text = re.sub(r'[^\u4e00-\u9fa5ã€ï¼Œ,]', '', str(text)).strip()

    # å¤„ç†"ç‰©åŒ–ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼ï¼šç›´æ¥æå–æ‹¬å·å‰çš„å†…å®¹
    if 'å¿…é€‰' in text and 'ï¼ˆ' in text and text.index('å¿…é€‰') > text.index('ï¼ˆ'):
        before_bracket = text.split('ï¼ˆ')[0]
        clean_text = before_bracket

    # å¤„ç†"ç‰©ã€åŒ–ã€ç”Ÿï¼ˆ3ç§‘å¿…é€‰ï¼‰"æ ¼å¼ï¼šé¡¿å·åˆ†éš”çš„ç§‘ç›®
    if 'ã€' in clean_text or 'ï¼Œ' in clean_text or ',' in clean_text:
        normalized_text = re.sub(r'[ã€ï¼Œ]', ',', clean_text)
        parts = [p.strip() for p in normalized_text.split(',') if p.strip()]
        for part in parts:
            for full_name, short_name in subject_map.items():
                if full_name in part or part in full_name:
                    if short_name not in subjects:
                        subjects.append(short_name)
                    break
    else:
        # å¤„ç†"ç‰©åŒ–ç”Ÿ"è¿™æ ·çš„è¿ç»­å­—ç¬¦ä¸²
        for full_name, short_name in subject_map.items():
            if full_name in clean_text:
                if short_name not in subjects:
                    subjects.append(short_name)

        # å¦‚æœæ²¡åŒ¹é…åˆ°å…¨åï¼Œå°è¯•æŒ‰å­—ç¬¦åŒ¹é…
        if len(subjects) == 0 and len(clean_text) > 0:
            char_to_short_map = {
                'ç‰©': 'ç‰©', 'åŒ–': 'åŒ–', 'ç”Ÿ': 'ç”Ÿ', 'å†': 'å†',
                'åœ°': 'åœ°', 'æ”¿': 'æ”¿', 'æŠ€': 'æŠ€'
            }
            for char in clean_text:
                if char in char_to_short_map and char_to_short_map[char] not in subjects:
                    subjects.append(char_to_short_map[char])

    return subjects


def convert_selection_requirement(group_requirement, major_requirement):
    """è½¬æ¢é€‰ç§‘è¦æ±‚"""
    selection_requirement = ''
    second_subject = ''

    # åˆå¹¶ä¸¤ä¸ªè¦æ±‚å­—æ®µ
    requirement = (str(group_requirement) if group_requirement else '') + (
        str(major_requirement) if major_requirement else '')

    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
    import re
    requirement = re.sub(r'^\^+', '', requirement).replace('^', 'ã€').strip()

    if not requirement or requirement == '' or requirement == 'ã€':
        return selection_requirement, second_subject

    # æ ¹æ®é™„ä»¶2ç¤ºä¾‹å¤„ç†å„ç§æƒ…å†µ
    if 'ä¸é™' in requirement or 'å†é€‰ä¸é™' in requirement:
        selection_requirement = 'ä¸é™ç§‘ç›®ä¸“ä¸šç»„'
    elif 'å¿…é€‰' in requirement:
        required_subjects = extract_required_subjects(requirement)
        if len(required_subjects) > 0:
            selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
            second_subject = ''.join(required_subjects)

        # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœåŒ…å«"é¦–é€‰"ï¼Œå¯èƒ½éœ€è¦æ’é™¤é¦–é€‰ç§‘ç›®
        if 'é¦–é€‰' in requirement:
            preferred_subjects = []
            if 'é¦–é€‰ç‰©ç†' in requirement:
                preferred_subjects.append('ç‰©')
            if 'é¦–é€‰å†å²' in requirement:
                preferred_subjects.append('å†')

            filtered_subjects = [s for s in required_subjects if s not in preferred_subjects]
            if len(filtered_subjects) > 0:
                second_subject = ''.join(filtered_subjects)
    elif 'é¦–é€‰' in requirement and 'å†é€‰' in requirement:
        re_select_part = requirement.split('å†é€‰')[1] if 'å†é€‰' in requirement else ''
        re_select_subjects = extract_required_subjects(re_select_part)
        if len(re_select_subjects) > 0:
            selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'
            second_subject = ''.join(re_select_subjects)
    elif 'æˆ–' in requirement or 'é€‰1' in requirement:
        subjects = extract_required_subjects(requirement)
        filtered_subjects = [s for s in subjects if s not in ['ç‰©', 'å†']]
        if len(filtered_subjects) > 0:
            selection_requirement = 'å¤šé—¨é€‰è€ƒ'
            second_subject = ''.join(filtered_subjects)
    else:
        subjects = extract_required_subjects(requirement)
        filtered_subjects = [s for s in subjects if s not in ['ç‰©', 'å†']]
        second_subject = ''.join(filtered_subjects)
        if len(filtered_subjects) > 0:
            selection_requirement = 'å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ'

    return selection_requirement, second_subject


def convert_to_text(value):
    """è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
    if not value and value != 0:
        return ''
    text = str(value).lstrip('^').strip()
    if text == '':
        return ''
    text = text.lstrip("'")
    return text


def convert_data(source_data):
    """è½¬æ¢æ•°æ®ä¸»å‡½æ•°"""
    converted = []

    for row in source_data:
        new_row = {}

        # åŸºç¡€å­—æ®µæ˜ å°„
        new_row['å­¦æ ¡åç§°'] = row.get('å­¦æ ¡', '') or ''
        new_row['çœä»½'] = row.get('çœä»½', '') or ''
        new_row['æ‹›ç”Ÿä¸“ä¸š'] = row.get('ä¸“ä¸š', '') or ''
        new_row['æ‹›ç”Ÿç§‘ç±»'] = row.get('ç§‘ç±»', '') or ''
        new_row['æ‹›ç”Ÿæ‰¹æ¬¡'] = row.get('æ‰¹æ¬¡', '') or ''
        new_row['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = row.get('æ‹›ç”Ÿç±»å‹', '') or ''
        new_row['ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰'] = row.get('å¤‡æ³¨', '') or ''
        new_row['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = row.get('æ‹›ç”Ÿäººæ•°', '') or ''
        new_row['æ•°æ®æ¥æº'] = row.get('æ•°æ®æ¥æº', '') or ''

        # å¤„ç†å±‚æ¬¡å­—æ®µ
        new_row['ä¸€çº§å±‚æ¬¡'] = convert_level(row.get('å±‚æ¬¡', ''))

        # å¤„ç†ä»£ç å­—æ®µï¼ˆä¿æŒæ–‡æœ¬æ ¼å¼ï¼‰
        new_row['æ‹›ç”Ÿä»£ç '] = convert_to_text(row.get('æ‹›ç”Ÿä»£ç ', ''))
        new_row['ä¸“ä¸šä»£ç '] = convert_to_text(row.get('ä¸“ä¸šä»£ç ', ''))
        new_row['ä¸“ä¸šç»„ä»£ç '] = convert_to_text(row.get('ä¸“ä¸šç»„ä»£ç ', ''))

        # å¤„ç†é¦–é€‰ç§‘ç›®
        new_row['é¦–é€‰ç§‘ç›®'] = get_first_subject(row.get('ç§‘ç±»', ''))

        # å¤„ç†é€‰ç§‘è¦æ±‚
        selection_requirement, second_subject = convert_selection_requirement(
            row.get('ä¸“ä¸šç»„é€‰ç§‘è¦æ±‚', ''),
            row.get('ä¸“ä¸šé€‰ç§‘è¦æ±‚(æ–°é«˜è€ƒä¸“ä¸šçœä»½)', '')
        )
        new_row['é€‰ç§‘è¦æ±‚'] = selection_requirement
        new_row['æ¬¡é€‰ç§‘ç›®'] = second_subject

        # å…¶ä»–å­—æ®µï¼ˆç•™ç©ºï¼‰
        new_row['ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰'] = ''
        new_row['æœ€é«˜åˆ†'] = ''
        new_row['æœ€ä½åˆ†'] = ''
        new_row['å¹³å‡åˆ†'] = ''
        new_row['æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´é«˜'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½'] = ''
        new_row['æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜'] = ''
        new_row['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = ''

        converted.append(new_row)

    return converted


def convert_to_college_score_format(conversion_data):
    """å°†æ‹›ç”Ÿè®¡åˆ’æ•°æ®è½¬æ¢ä¸ºé™¢æ ¡åˆ†æ ¼å¼"""
    if not conversion_data:
        return []

    # è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨åœ°å¤„ç†ç©ºå€¼ï¼Œå°†Noneã€NaNç­‰è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²
    def safe_str(value, default=''):
        """å®‰å…¨åœ°å°†å€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç†Noneã€NaNç­‰æƒ…å†µ"""
        if value is None:
            return default
        if pd.isna(value):
            return default
        value_str = str(value).strip()
        # æ£€æŸ¥æ˜¯å¦ä¸º'nan'ã€'None'ç­‰å­—ç¬¦ä¸²
        if value_str.lower() in ['nan', 'none', '']:
            return default
        return value_str

    # æ„å»ºåˆ†ç»„é”®ï¼šçœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€æ‹›ç”Ÿç±»å‹ã€å±‚æ¬¡ã€ä¸“ä¸šç»„ä»£ç 
    # å¦‚æœä¸“ä¸šç»„ä»£ç ä¸ºç©ºï¼Œåˆ™ä¸åŒ…å«åœ¨åˆ†ç»„é”®ä¸­
    def get_group_key(item):
        province = safe_str(item.get('çœä»½', ''))
        school = safe_str(item.get('å­¦æ ¡', ''))
        subject = safe_str(item.get('ç§‘ç±»', ''))
        batch = safe_str(item.get('æ‰¹æ¬¡', ''))
        recruit_type = safe_str(item.get('æ‹›ç”Ÿç±»å‹', ''))
        level = safe_str(item.get('å±‚æ¬¡', ''))
        group_code = safe_str(item.get('ä¸“ä¸šç»„ä»£ç ', ''))

        # å¦‚æœä¸“ä¸šç»„ä»£ç ä¸ºç©ºæˆ–åªæœ‰^ï¼Œåˆ™ä¸åŒ…å«åœ¨åˆ†ç»„é”®ä¸­
        if not group_code or group_code == '^' or group_code == '':
            return (province, school, subject, batch, recruit_type, level)
        else:
            return (province, school, subject, batch, recruit_type, level, group_code)

    # æŒ‰åˆ†ç»„é”®åˆ†ç»„
    grouped_data = {}
    for item in conversion_data:
        key = get_group_key(item)
        if key not in grouped_data:
            grouped_data[key] = []
        grouped_data[key].append(item)

    # è½¬æ¢ä¸ºé™¢æ ¡åˆ†æ ¼å¼
    college_score_data = []
    for key, items in grouped_data.items():
        # å–ç¬¬ä¸€æ¡è®°å½•ä½œä¸ºåŸºç¡€æ•°æ®
        base_item = items[0]

        # è®¡ç®—æ‹›ç”Ÿäººæ•°æ€»å’Œ
        total_recruit_num = 0
        for item in items:
            recruit_num = item.get('æ‹›ç”Ÿäººæ•°', '') or ''
            if recruit_num and not pd.isna(recruit_num):
                try:
                    total_recruit_num += float(str(recruit_num))
                except:
                    pass

        # å¤„ç†ä¸“ä¸šç»„ä»£ç ï¼šå¦‚æœä¸ºç©ºæˆ–åªæœ‰^ï¼Œåˆ™è®¾ä¸ºç©ºå­—ç¬¦ä¸²
        group_code = safe_str(base_item.get('ä¸“ä¸šç»„ä»£ç ', '')).lstrip('^')
        if not group_code or group_code == '^':
            group_code = ''

        # å¤„ç†é™¢æ ¡æ‹›ç”Ÿä»£ç ï¼šå»é™¤å¼€å¤´çš„^ç¬¦å·
        recruit_code = safe_str(base_item.get('æ‹›ç”Ÿä»£ç ', '')).lstrip('^')

        # å¤„ç†æ‹›ç”Ÿäººæ•°ï¼šä¿æŒä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
        recruit_num_str = str(int(total_recruit_num)) if total_recruit_num > 0 else ''

        # æ„å»ºé™¢æ ¡åˆ†è®°å½•
        college_record = {
            'å­¦æ ¡åç§°': safe_str(base_item.get('å­¦æ ¡', '')),
            'çœä»½': safe_str(base_item.get('çœä»½', '')),
            'æ‹›ç”Ÿç±»åˆ«': safe_str(base_item.get('ç§‘ç±»', '')),
            'æ‹›ç”Ÿæ‰¹æ¬¡': safe_str(base_item.get('æ‰¹æ¬¡', '')),
            'æ‹›ç”Ÿç±»å‹': safe_str(base_item.get('æ‹›ç”Ÿç±»å‹', '')),
            'é€‰æµ‹ç­‰çº§': '',
            'æœ€é«˜åˆ†': '',
            'æœ€ä½åˆ†': '',
            'å¹³å‡åˆ†': '',
            'æœ€é«˜ä½æ¬¡': '',
            'æœ€ä½ä½æ¬¡': '',
            'å¹³å‡ä½æ¬¡': '',
            'å½•å–äººæ•°': '',
            'æ‹›ç”Ÿäººæ•°': recruit_num_str,
            'æ•°æ®æ¥æº': safe_str(base_item.get('æ•°æ®æ¥æº', '')),
            'çœæ§çº¿ç§‘ç±»': '',
            'çœæ§çº¿æ‰¹æ¬¡': '',
            'çœæ§çº¿å¤‡æ³¨': '',
            'ä¸“ä¸šç»„ä»£ç ': group_code,
            'é¦–é€‰ç§‘ç›®': '',
            'é™¢æ ¡æ‹›ç”Ÿä»£ç ': recruit_code
        }

        # å¤„ç†é¦–é€‰ç§‘ç›®ï¼šåªæœ‰æ‹›ç”Ÿç±»åˆ«ä¸ºç‰©ç†ç±»/å†å²ç±»æ—¶æ‰å¡«å…¥
        category = college_record['æ‹›ç”Ÿç±»åˆ«']
        if 'ç‰©ç†ç±»' in category or category == 'ç‰©ç†':
            college_record['é¦–é€‰ç§‘ç›®'] = 'ç‰©ç†'
        elif 'å†å²ç±»' in category or category == 'å†å²':
            college_record['é¦–é€‰ç§‘ç›®'] = 'å†å²'

        college_score_data.append(college_record)

    return college_score_data


def export_college_score_data_to_excel(college_score_data, conversion_data, output_path):
    """å¯¼å‡ºé™¢æ ¡åˆ†æ ¼å¼çš„Excelæ–‡ä»¶"""
    # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
    remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    åŒ—äº¬ã€å¤©æ´¥ã€è¾½å®ã€ä¸Šæµ·ã€å±±ä¸œã€å¹¿ä¸œã€æµ·å—é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼ˆæœ€å¤šä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
5.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—
6.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
7.é¦–é€‰ç§‘ç›®ï¼šæ–°å…«çœå¿…å¡«ï¼Œåªèƒ½å¡«å†™ï¼ˆå†å²æˆ–ç‰©ç†ï¼‰"""

    # åˆ›å»ºå·¥ä½œç°¿
    wb = openpyxl.Workbook()
    ws = wb.active

    # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
    ws.merge_cells('A1:U1')
    ws['A1'] = remark_text
    ws['A1'].alignment = Alignment(wrap_text=True, vertical='top')
    # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º220ç£…
    ws.row_dimensions[1].height = 220

    # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=å¹´ä»½ï¼ŒC2="1"ï¼ŒD2="æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰"
    ws['A2'] = 'æ‹›ç”Ÿå¹´'
    # ä»conversion_dataä¸­æå–å¹´ä»½
    year_value = ''
    if conversion_data and len(conversion_data) > 0:
        year_value = conversion_data[0].get('å¹´ä»½', '') or ''
        if year_value:
            year_value = str(year_value).strip()

    # B2è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼
    ws['B2'] = year_value
    ws['B2'].number_format = numbers.FORMAT_TEXT
    ws['C2'] = 1
    ws['D2'] = 'æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰'

    # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
    headers = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§',
               'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡',
               'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨',
               'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ']
    for col_idx, header in enumerate(headers, start=1):
        ws.cell(row=3, column=col_idx, value=header)

    # æ•°æ®è¡Œï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
    for row_idx, row_data in enumerate(college_score_data, start=4):
        for col_idx, header in enumerate(headers, start=1):
            value = row_data.get(header, '')

            # å¤„ç†ç©ºå€¼ï¼šå°†Noneã€NaNã€'nan'å­—ç¬¦ä¸²ç­‰è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²
            if value is None or pd.isna(value):
                value = ''
            elif isinstance(value, str):
                # æ£€æŸ¥æ˜¯å¦ä¸º'nan'ã€'None'ç­‰å­—ç¬¦ä¸²
                if value.lower() in ['nan', 'none']:
                    value = ''

            cell = ws.cell(row=row_idx, column=col_idx, value=value)

            # è®¾ç½®æ–‡æœ¬æ ¼å¼çš„åˆ—ï¼šæ‹›ç”Ÿäººæ•°ã€ä¸“ä¸šç»„ä»£ç ã€é™¢æ ¡æ‹›ç”Ÿä»£ç 
            # è¿™äº›åˆ—éœ€è¦ä¿æŒæ–‡æœ¬æ ¼å¼ï¼Œå³ä½¿å†…å®¹å¼€å¤´ä¸º0ä¹Ÿä¸èƒ½æŠ¹æ‰
            if header == 'ä¸“ä¸šç»„ä»£ç ' or header == 'é™¢æ ¡æ‹›ç”Ÿä»£ç ' or header == 'æ‹›ç”Ÿäººæ•°':
                # ç¡®ä¿å€¼ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼
                if value is not None and value != '':
                    cell.value = str(value)
                else:
                    cell.value = ''  # ç¡®ä¿ç©ºå€¼å†™å…¥ä¸ºç©ºå­—ç¬¦ä¸²
                cell.number_format = numbers.FORMAT_TEXT

    wb.save(output_path)


def export_converted_data_to_excel(data, conversion_data, output_path):
    """å¯¼å‡ºè½¬æ¢åçš„æ•°æ®ä¸ºExcelï¼ˆä¿æŒä¸HTMLä¸­ç›¸åŒçš„æ ¼å¼ï¼‰"""
    from datetime import datetime

    # åˆ›å»ºå·¥ä½œç°¿
    wb = openpyxl.Workbook()
    ws = wb.active

    # ç¬¬1è¡Œï¼šå¤‡æ³¨ï¼ˆåˆå¹¶å•å…ƒæ ¼ï¼‰
    remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æ‹›ç”Ÿäººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
5.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼Œä¿ç•™å°æ•°åä¸¤ä½ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
6.ä¸€çº§å±‚æ¬¡ï¼šé™å®š"æœ¬ç§‘ã€ä¸“ç§‘ï¼ˆé«˜èŒï¼‰"ï¼Œè¯¥éƒ¨åˆ†ä¸ºæ‹›ç”Ÿä¸“ä¸šå¯¹åº”çš„ä¸“ä¸šå±‚æ¬¡
7.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—;
8.æ•°æ®æ¥æºï¼šå¿…é¡»é™å®šâ€”â€”å®˜æ–¹è€ƒè¯•é™¢ã€å¤§çº¢æœ¬æ•°æ®ã€å­¦æ ¡å®˜ç½‘ã€é”€å”®ã€æŠ“å–ã€åœ£è¾¾ä¿¡ã€ä¼˜å¿—æ„¿ã€å­¦ä¸šæ¡¥
9.é€‰ç§‘è¦æ±‚ï¼šä¸é™ç§‘ç›®ä¸“ä¸šç»„;å¤šé—¨é€‰è€ƒ;å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ
10.é€‰ç§‘ç§‘ç›®å¿…é¡»æ˜¯ç§‘ç›®çš„ç®€å†™ï¼ˆç‰©ã€åŒ–ã€ç”Ÿã€å†ã€åœ°ã€æ”¿ã€æŠ€ï¼‰

11.2020åŒ—äº¬ã€æµ·å—ï¼Œ17-19ä¸Šæµ·ä»…é™åˆ¶æœ¬ç§‘ä¸“ä¸šç»„ä»£ç å¿…å¡«
12.æ–°å…«çœé¦–é€‰ç§‘ç›®å¿…é¡»é€‰æ‹©ï¼ˆç‰©ç†æˆ–å†å²ï¼‰
13.åˆ†æ•°åŒºé—´ä»…é™åŒ—äº¬"""

    ws.merge_cells('A1:Y1')
    ws['A1'] = remark_text
    ws['A1'].alignment = Alignment(wrap_text=True, vertical='top')
    ws.row_dimensions[1].height = 220

    # ç¬¬2è¡Œï¼šæ‹›ç”Ÿå¹´ä»½
    admission_year = ''
    if conversion_data and len(conversion_data) > 0 and conversion_data[0].get('å¹´ä»½'):
        admission_year = conversion_data[0]['å¹´ä»½']
    ws['A2'] = 'æ‹›ç”Ÿå¹´ä»½'
    ws['B2'] = admission_year

    # ç¬¬3è¡Œï¼šè¡¨å¤´
    headers = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰',
        'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†',
        'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰',
        'æ•°æ®æ¥æº', 'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®',
        'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†æ•°åŒºé—´ä½', 'æœ€ä½åˆ†æ•°åŒºé—´é«˜',
        'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡ä½', 'æœ€ä½åˆ†æ•°åŒºé—´ä½æ¬¡é«˜', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
    ]
    for col_idx, header in enumerate(headers, start=1):
        ws.cell(row=3, column=col_idx, value=header)

    # æ•°æ®è¡Œ
    for row_idx, row_data in enumerate(data, start=4):
        for col_idx, header in enumerate(headers, start=1):
            value = row_data.get(header, '')
            cell = ws.cell(row=row_idx, column=col_idx, value=value)
            # è®¾ç½®ä»£ç åˆ—ä¸ºæ–‡æœ¬æ ¼å¼
            if header in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                cell.number_format = numbers.FORMAT_TEXT

    # è®¾ç½®åˆ—å®½
    for col_idx in range(1, len(headers) + 1):
        ws.column_dimensions[openpyxl.utils.get_column_letter(col_idx)].width = 9.36

    wb.save(output_path)


# ====================== tab7ï¼šæ‹›ç”Ÿè®¡åˆ’å·¥å…·======================
with tab7:
    st.header("æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ä¸è½¬æ¢å·¥å…·")
    st.markdown("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’ã€ä¸“ä¸šåˆ†å’Œé™¢æ ¡åˆ†æ–‡ä»¶è¿›è¡Œæ¯”å¯¹ï¼Œå¯¼å‡ºæœªåŒ¹é…æ•°æ®ä¸ºä¸“ä¸šåˆ†æ ¼å¼")

    # åˆå§‹åŒ–session state
    if 'plan_data' not in st.session_state:
        st.session_state.plan_data = None
    if 'score_data' not in st.session_state:
        st.session_state.score_data = None
    if 'college_data' not in st.session_state:
        st.session_state.college_data = None
    if 'plan_score_results' not in st.session_state:
        st.session_state.plan_score_results = []
    if 'plan_college_results' not in st.session_state:
        st.session_state.plan_college_results = []

    # å·¥ä½œæµæ­¥éª¤æ˜¾ç¤º
    col1, col2, col3, col4, col5 = st.columns([1, 0.3, 1, 0.3, 1])
    with col1:
        st.markdown("""
        <div style="text-align: center; padding: 10px; background: #e3f2fd; border-radius: 10px;">
            <div style="font-size: 24px; font-weight: bold;">1</div>
            <div>ä¸Šä¼ æ–‡ä»¶</div>
        </div>
        """, unsafe_allow_html=True)
    with col3:
        st.markdown("""
        <div style="text-align: center; padding: 10px; background: #f5f5f5; border-radius: 10px;">
            <div style="font-size: 24px; font-weight: bold;">2</div>
            <div>æ•°æ®æ¯”å¯¹</div>
        </div>
        """, unsafe_allow_html=True)
    with col5:
        st.markdown("""
        <div style="text-align: center; padding: 10px; background: #f5f5f5; border-radius: 10px;">
            <div style="font-size: 24px; font-weight: bold;">3</div>
            <div>å¯¼å‡ºæœªåŒ¹é…æ•°æ®</div>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")

    # å­—æ®µè¯´æ˜
    with st.expander("ğŸ“‹ æ¯”å¯¹å­—æ®µè¯´æ˜", expanded=False):
        st.markdown("""
        **æ¯”å¯¹1ï¼ˆæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†ï¼‰ï¼š** æ£€æŸ¥æ‹›ç”Ÿè®¡åˆ’çš„è®°å½•æ˜¯å¦åœ¨ä¸“ä¸šåˆ†ä¸­å­˜åœ¨
        - åŒ¹é…å­—æ®µï¼šå¹´ä»½ã€çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šã€å±‚æ¬¡ã€ä¸“ä¸šç»„ä»£ç 

        **æ¯”å¯¹2ï¼ˆæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†ï¼‰ï¼š** æ£€æŸ¥æ‹›ç”Ÿè®¡åˆ’çš„è®°å½•æ˜¯å¦åœ¨é™¢æ ¡åˆ†ä¸­å­˜åœ¨
        - åŒ¹é…å­—æ®µï¼šå¹´ä»½ã€çœä»½ã€å­¦æ ¡ã€ç§‘ç±»ã€æ‰¹æ¬¡ã€ä¸“ä¸šç»„ä»£ç 
        """)

    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    col1, col2, col3 = st.columns(3)

    with col1:
        st.subheader("æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
        plan_file = st.file_uploader("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶", type=["xlsx", "xls"], key="tab7_plan_file")
        if plan_file is not None:
            try:
                plan_df = pd.read_excel(plan_file, engine='openpyxl')
                st.session_state.plan_data = plan_df
                st.success(f"âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ\næ–‡ä»¶å: {plan_file.name}\nè®°å½•æ•°: {len(plan_df)} æ¡")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    with col2:
        st.subheader("ä¸“ä¸šåˆ†æ–‡ä»¶")
        score_file = st.file_uploader("ä¸Šä¼ ä¸“ä¸šåˆ†æ–‡ä»¶", type=["xlsx", "xls"], key="tab7_score_file")
        if score_file is not None:
            try:
                score_df = pd.read_excel(score_file, engine='openpyxl')
                st.session_state.score_data = score_df
                st.success(f"âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ\næ–‡ä»¶å: {score_file.name}\nè®°å½•æ•°: {len(score_df)} æ¡")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    with col3:
        st.subheader("é™¢æ ¡åˆ†æ–‡ä»¶")
        college_file = st.file_uploader("ä¸Šä¼ é™¢æ ¡åˆ†æ–‡ä»¶", type=["xlsx", "xls"], key="tab7_college_file")
        if college_file is not None:
            try:
                college_df = pd.read_excel(college_file, engine='openpyxl')
                st.session_state.college_data = college_df
                st.success(f"âœ“ æ–‡ä»¶åŠ è½½æˆåŠŸ\næ–‡ä»¶å: {college_file.name}\nè®°å½•æ•°: {len(college_df)} æ¡")
            except Exception as e:
                st.error(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    st.markdown("---")

    # æ¯”å¯¹æŒ‰é’®
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
    with col1:
        compare_plan_score_btn = st.button("æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†", type="primary", use_container_width=True)
    with col2:
        compare_plan_college_btn = st.button("æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†", type="primary", use_container_width=True)
    with col3:
        compare_all_btn = st.button("å…¨éƒ¨æ¯”å¯¹", type="primary", use_container_width=True)
    with col4:
        reset_btn = st.button("é‡ç½®", use_container_width=True)

    # æ‰§è¡Œæ¯”å¯¹
    if compare_plan_score_btn:
        if st.session_state.plan_data is None:
            st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
        elif st.session_state.score_data is None:
            st.error("è¯·å…ˆä¸Šä¼ ä¸“ä¸šåˆ†æ–‡ä»¶")
        else:
            with st.spinner("æ­£åœ¨æ¯”å¯¹æ•°æ®..."):
                st.session_state.plan_score_results = compare_plan_vs_score(
                    st.session_state.plan_data, st.session_state.score_data
                )
            st.success("æ¯”å¯¹1å®Œæˆï¼")
            st.balloons()

    if compare_plan_college_btn:
        if st.session_state.plan_data is None:
            st.error("è¯·å…ˆä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ–‡ä»¶")
        elif st.session_state.college_data is None:
            st.error("è¯·å…ˆä¸Šä¼ é™¢æ ¡åˆ†æ–‡ä»¶")
        else:
            with st.spinner("æ­£åœ¨æ¯”å¯¹æ•°æ®..."):
                st.session_state.plan_college_results = compare_plan_vs_college(
                    st.session_state.plan_data, st.session_state.college_data
                )
            st.success("æ¯”å¯¹2å®Œæˆï¼")
            st.balloons()

    if compare_all_btn:
        comparisons = []
        if st.session_state.plan_data is not None and st.session_state.score_data is not None:
            comparisons.append("æ¯”å¯¹1")
        if st.session_state.plan_data is not None and st.session_state.college_data is not None:
            comparisons.append("æ¯”å¯¹2")

        if len(comparisons) == 0:
            st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªæ–‡ä»¶ä»¥è¿›è¡Œæ¯”å¯¹")
        else:
            with st.spinner("æ­£åœ¨æ‰§è¡Œå…¨éƒ¨æ¯”å¯¹..."):
                if "æ¯”å¯¹1" in comparisons:
                    st.session_state.plan_score_results = compare_plan_vs_score(
                        st.session_state.plan_data, st.session_state.score_data
                    )
                if "æ¯”å¯¹2" in comparisons:
                    st.session_state.plan_college_results = compare_plan_vs_college(
                        st.session_state.plan_data, st.session_state.college_data
                    )
            st.success("å…¨éƒ¨æ¯”å¯¹å®Œæˆï¼")
            st.balloons()

    if reset_btn:
        st.session_state.plan_data = None
        st.session_state.score_data = None
        st.session_state.college_data = None
        st.session_state.plan_score_results = []
        st.session_state.plan_college_results = []
        st.success("é‡ç½®å®Œæˆï¼")
        st.rerun()

    # æ˜¾ç¤ºæ¯”å¯¹ç»“æœ
    if len(st.session_state.plan_score_results) > 0 or len(st.session_state.plan_college_results) > 0:
        st.markdown("---")

        # åˆ›å»ºæ ‡ç­¾é¡µ
        tab_plan_score, tab_plan_college = st.tabs([
            "æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†",
            "æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†"
        ])

        # æ¯”å¯¹1ç»“æœ
        with tab_plan_score:
            if len(st.session_state.plan_score_results) > 0:
                results = st.session_state.plan_score_results
                total = len(results)
                matched = sum(1 for r in results if r['exists'])
                unmatched = total - matched
                rate = (matched / total * 100) if total > 0 else 0

                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", total)
                with col2:
                    st.metric("åŒ¹é…è®°å½•æ•°", matched, delta=f"{rate:.1f}%")
                with col3:
                    st.metric("æœªåŒ¹é…è®°å½•æ•°", unmatched)
                with col4:
                    st.metric("åŒ¹é…ç‡", f"{rate:.1f}%")

                # ç­›é€‰æ§ä»¶
                st.markdown("### ç­›é€‰æ¡ä»¶")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    provinces = sorted(set(r['keyFields']['çœä»½'] for r in results if r['keyFields']['çœä»½']))
                    province_filter = st.selectbox("çœä»½", ["å…¨éƒ¨"] + provinces, key="ps_province")
                with col2:
                    batches = sorted(set(r['keyFields']['æ‰¹æ¬¡'] for r in results if r['keyFields']['æ‰¹æ¬¡']))
                    batch_filter = st.selectbox("æ‰¹æ¬¡", ["å…¨éƒ¨"] + batches, key="ps_batch")
                with col3:
                    match_status_filter = st.selectbox("åŒ¹é…çŠ¶æ€", ["å…¨éƒ¨", "åŒ¹é…", "æœªåŒ¹é…"], key="ps_status")
                with col4:
                    display_option = st.selectbox("æ˜¾ç¤ºé€‰é¡¹", ["å…¨éƒ¨", "å‰100æ¡", "å‰500æ¡"], key="ps_display")

                # åº”ç”¨ç­›é€‰
                filtered_results = results
                if province_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['çœä»½'] == province_filter]
                if batch_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['æ‰¹æ¬¡'] == batch_filter]
                if match_status_filter == "åŒ¹é…":
                    filtered_results = [r for r in filtered_results if r['exists']]
                elif match_status_filter == "æœªåŒ¹é…":
                    filtered_results = [r for r in filtered_results if not r['exists']]

                display_count = len(filtered_results)
                if display_option == "å‰100æ¡":
                    display_count = min(100, len(filtered_results))
                elif display_option == "å‰500æ¡":
                    display_count = min(500, len(filtered_results))

                # æ˜¾ç¤ºè¡¨æ ¼
                st.markdown(
                    f"### æ¯”å¯¹ç»“æœï¼ˆæ˜¾ç¤º {min(display_count, len(filtered_results))} / {len(filtered_results)} æ¡ï¼‰")
                display_results = filtered_results[:display_count]

                if len(display_results) > 0:
                    # å‡†å¤‡è¡¨æ ¼æ•°æ®
                    table_data = []
                    for r in display_results:
                        table_data.append({
                            'åºå·': r['index'],
                            'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                            'çœä»½': r['keyFields']['çœä»½'],
                            'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                            'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                            'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                            'ä¸“ä¸š': r['keyFields']['ä¸“ä¸š'],
                            'å±‚æ¬¡': r['keyFields']['å±‚æ¬¡'],
                            'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '] or '-',
                            'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'] or '-',
                            'åŒ¹é…çŠ¶æ€': 'âœ“ å­˜åœ¨' if r['exists'] else 'âœ— ä¸å­˜åœ¨'
                        })

                    df_display = pd.DataFrame(table_data)
                    st.dataframe(df_display, use_container_width=True, hide_index=True)

                # å¯¼å‡ºæŒ‰é’®
                if st.button("å¯¼å‡ºæ¯”å¯¹1ç»“æœ", key="export_ps", use_container_width=True):
                    try:
                        export_data = []
                        for r in results:
                            export_data.append({
                                'åºå·': r['index'],
                                'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                                'çœä»½': r['keyFields']['çœä»½'],
                                'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                'ä¸“ä¸š': r['keyFields']['ä¸“ä¸š'],
                                'å±‚æ¬¡': r['keyFields']['å±‚æ¬¡'],
                                'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                'å­¦è´¹': r['otherInfo']['å­¦è´¹'],
                                'å­¦åˆ¶': r['otherInfo']['å­¦åˆ¶'],
                                'ä¸“ä¸šä»£ç ': r['otherInfo']['ä¸“ä¸šä»£ç '],
                                'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                            })

                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            pd.DataFrame(export_data).to_excel(writer, index=False, sheet_name='æ¯”å¯¹1_æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†')

                        output.seek(0)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½æ¯”å¯¹1ç»“æœ",
                            output,
                            file_name=f"æ¯”å¯¹1_æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            else:
                st.info("æš‚æ— æ¯”å¯¹ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œæ¯”å¯¹")

        # æ¯”å¯¹2ç»“æœ
        with tab_plan_college:
            if len(st.session_state.plan_college_results) > 0:
                results = st.session_state.plan_college_results
                total = len(results)
                matched = sum(1 for r in results if r['exists'])
                unmatched = total - matched
                rate = (matched / total * 100) if total > 0 else 0

                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»è®°å½•æ•°", total)
                with col2:
                    st.metric("åŒ¹é…è®°å½•æ•°", matched, delta=f"{rate:.1f}%")
                with col3:
                    st.metric("æœªåŒ¹é…è®°å½•æ•°", unmatched)
                with col4:
                    st.metric("åŒ¹é…ç‡", f"{rate:.1f}%")

                # ç­›é€‰æ§ä»¶
                st.markdown("### ç­›é€‰æ¡ä»¶")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    provinces = sorted(set(r['keyFields']['çœä»½'] for r in results if r['keyFields']['çœä»½']))
                    province_filter = st.selectbox("çœä»½", ["å…¨éƒ¨"] + provinces, key="pc_province")
                with col2:
                    batches = sorted(set(r['keyFields']['æ‰¹æ¬¡'] for r in results if r['keyFields']['æ‰¹æ¬¡']))
                    batch_filter = st.selectbox("æ‰¹æ¬¡", ["å…¨éƒ¨"] + batches, key="pc_batch")
                with col3:
                    match_status_filter = st.selectbox("åŒ¹é…çŠ¶æ€", ["å…¨éƒ¨", "åŒ¹é…", "æœªåŒ¹é…"], key="pc_status")
                with col4:
                    display_option = st.selectbox("æ˜¾ç¤ºé€‰é¡¹", ["å…¨éƒ¨", "å‰100æ¡", "å‰500æ¡"], key="pc_display")

                # åº”ç”¨ç­›é€‰
                filtered_results = results
                if province_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['çœä»½'] == province_filter]
                if batch_filter != "å…¨éƒ¨":
                    filtered_results = [r for r in filtered_results if r['keyFields']['æ‰¹æ¬¡'] == batch_filter]
                if match_status_filter == "åŒ¹é…":
                    filtered_results = [r for r in filtered_results if r['exists']]
                elif match_status_filter == "æœªåŒ¹é…":
                    filtered_results = [r for r in filtered_results if not r['exists']]

                display_count = len(filtered_results)
                if display_option == "å‰100æ¡":
                    display_count = min(100, len(filtered_results))
                elif display_option == "å‰500æ¡":
                    display_count = min(500, len(filtered_results))

                # æ˜¾ç¤ºè¡¨æ ¼
                st.markdown(
                    f"### æ¯”å¯¹ç»“æœï¼ˆæ˜¾ç¤º {min(display_count, len(filtered_results))} / {len(filtered_results)} æ¡ï¼‰")
                display_results = filtered_results[:display_count]

                if len(display_results) > 0:
                    # å‡†å¤‡è¡¨æ ¼æ•°æ®
                    table_data = []
                    for r in display_results:
                        table_data.append({
                            'åºå·': r['index'],
                            'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                            'çœä»½': r['keyFields']['çœä»½'],
                            'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                            'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                            'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                            'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '] or '-',
                            'ä¸“ä¸š': r['otherInfo']['ä¸“ä¸š'] or '-',
                            'åŒ¹é…çŠ¶æ€': 'âœ“ å­˜åœ¨' if r['exists'] else 'âœ— ä¸å­˜åœ¨'
                        })

                    df_display = pd.DataFrame(table_data)
                    st.dataframe(df_display, use_container_width=True, hide_index=True)

                # å¯¼å‡ºæŒ‰é’®
                if st.button("å¯¼å‡ºæ¯”å¯¹2ç»“æœ", key="export_pc", use_container_width=True):
                    try:
                        export_data = []
                        for r in results:
                            export_data.append({
                                'åºå·': r['index'],
                                'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                                'çœä»½': r['keyFields']['çœä»½'],
                                'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                'ä¸“ä¸š': r['otherInfo']['ä¸“ä¸š'],
                                'å±‚æ¬¡': r['otherInfo']['å±‚æ¬¡'],
                                'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                            })

                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            pd.DataFrame(export_data).to_excel(writer, index=False, sheet_name='æ¯”å¯¹2_æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†')

                        output.seek(0)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½æ¯”å¯¹2ç»“æœ",
                            output,
                            file_name=f"æ¯”å¯¹2_æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
            else:
                st.info("æš‚æ— æ¯”å¯¹ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œæ¯”å¯¹")

        # å…¨å±€å¯¼å‡ºåŒºåŸŸ
        if len(st.session_state.plan_score_results) > 0 or len(st.session_state.plan_college_results) > 0:
            st.markdown("---")
            st.markdown("### ğŸ“¤ å…¨å±€å¯¼å‡ºåŠŸèƒ½")

            # æ”¶é›†æ‰€æœ‰æœªåŒ¹é…çš„æ•°æ®
            all_unmatched_results = []
            if len(st.session_state.plan_score_results) > 0:
                all_unmatched_results.extend([r for r in st.session_state.plan_score_results if not r['exists']])
            if len(st.session_state.plan_college_results) > 0:
                all_unmatched_results.extend([r for r in st.session_state.plan_college_results if not r['exists']])

            # ä½¿ç”¨ä¸‰åˆ—å¸ƒå±€ï¼Œæ·»åŠ é™¢æ ¡åˆ†æ ¼å¼å¯¼å‡º
            col1, col2, col3 = st.columns([1, 1, 1])

            with col1:
                if st.button("ğŸ“Š å¯¼å‡ºå…¨éƒ¨ç»“æœ", use_container_width=True):
                    try:
                        output = BytesIO()
                        with pd.ExcelWriter(output, engine='openpyxl') as writer:
                            # æ¯”å¯¹1ç»“æœ
                            if len(st.session_state.plan_score_results) > 0:
                                export_data = []
                                for r in st.session_state.plan_score_results:
                                    export_data.append({
                                        'åºå·': r['index'],
                                        'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                                        'çœä»½': r['keyFields']['çœä»½'],
                                        'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                        'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                        'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                        'ä¸“ä¸š': r['keyFields']['ä¸“ä¸š'],
                                        'å±‚æ¬¡': r['keyFields']['å±‚æ¬¡'],
                                        'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                        'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                        'å­¦è´¹': r['otherInfo']['å­¦è´¹'],
                                        'å­¦åˆ¶': r['otherInfo']['å­¦åˆ¶'],
                                        'ä¸“ä¸šä»£ç ': r['otherInfo']['ä¸“ä¸šä»£ç '],
                                        'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                        'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨ä¸“ä¸šåˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                                    })
                                pd.DataFrame(export_data).to_excel(writer, index=False,
                                                                   sheet_name='æ¯”å¯¹1_æ‹›ç”Ÿè®¡åˆ’vsä¸“ä¸šåˆ†')

                            # æ¯”å¯¹2ç»“æœ
                            if len(st.session_state.plan_college_results) > 0:
                                export_data = []
                                for r in st.session_state.plan_college_results:
                                    export_data.append({
                                        'åºå·': r['index'],
                                        'å¹´ä»½': r['keyFields']['å¹´ä»½'],
                                        'çœä»½': r['keyFields']['çœä»½'],
                                        'å­¦æ ¡': r['keyFields']['å­¦æ ¡'],
                                        'ç§‘ç±»': r['keyFields']['ç§‘ç±»'],
                                        'æ‰¹æ¬¡': r['keyFields']['æ‰¹æ¬¡'],
                                        'ä¸“ä¸šç»„ä»£ç ': r['keyFields']['ä¸“ä¸šç»„ä»£ç '],
                                        'ä¸“ä¸š': r['otherInfo']['ä¸“ä¸š'],
                                        'å±‚æ¬¡': r['otherInfo']['å±‚æ¬¡'],
                                        'æ‹›ç”Ÿäººæ•°': r['otherInfo']['æ‹›ç”Ÿäººæ•°'],
                                        'åŒ¹é…çŠ¶æ€': 'å­˜åœ¨' if r['exists'] else 'ä¸å­˜åœ¨',
                                        'åŒ¹é…è¯´æ˜': 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­å­˜åœ¨' if r['exists'] else 'è¯¥è®°å½•åœ¨é™¢æ ¡åˆ†æ–‡ä»¶ä¸­ä¸å­˜åœ¨'
                                    })
                                pd.DataFrame(export_data).to_excel(writer, index=False,
                                                                   sheet_name='æ¯”å¯¹2_æ‹›ç”Ÿè®¡åˆ’vsé™¢æ ¡åˆ†')

                            # ç»Ÿè®¡æŠ¥å‘Š
                            summary_data = {
                                'æ¯”å¯¹ç±»å‹': ['æ¯”å¯¹1ï¼šæ‹›ç”Ÿè®¡åˆ’ vs ä¸“ä¸šåˆ†', 'æ¯”å¯¹2ï¼šæ‹›ç”Ÿè®¡åˆ’ vs é™¢æ ¡åˆ†'],
                                'æ€»è®°å½•æ•°': [
                                    len(st.session_state.plan_score_results),
                                    len(st.session_state.plan_college_results)
                                ],
                                'åŒ¹é…è®°å½•æ•°': [
                                    sum(1 for r in st.session_state.plan_score_results if r['exists']),
                                    sum(1 for r in st.session_state.plan_college_results if r['exists'])
                                ],
                                'åŒ¹é…ç‡': [
                                    f"{(sum(1 for r in st.session_state.plan_score_results if r['exists']) / len(st.session_state.plan_score_results) * 100):.1f}%" if len(
                                        st.session_state.plan_score_results) > 0 else "0%",
                                    f"{(sum(1 for r in st.session_state.plan_college_results if r['exists']) / len(st.session_state.plan_college_results) * 100):.1f}%" if len(
                                        st.session_state.plan_college_results) > 0 else "0%"
                                ]
                            }
                            pd.DataFrame(summary_data).to_excel(writer, index=False, sheet_name='ç»Ÿè®¡æŠ¥å‘Š')

                        output.seek(0)
                        st.download_button(
                            "ğŸ“¥ ä¸‹è½½å…¨éƒ¨ç»“æœ",
                            output,
                            file_name=f"æ•°æ®æ¯”å¯¹ç»“æœæ±‡æ€»_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")

            with col2:
                if len(all_unmatched_results) > 0:
                    if st.button("â­ å¯¼å‡ºæœªåŒ¹é…æ•°æ®ä¸ºä¸“ä¸šåˆ†æ ¼å¼", type="primary", use_container_width=True):
                        try:
                            # æå–åŸå§‹æ•°æ®ï¼ˆå»é‡ï¼Œå› ä¸ºåŒä¸€ä¸ªè®°å½•å¯èƒ½åœ¨æ¯”å¯¹1å’Œæ¯”å¯¹2ä¸­éƒ½æœªåŒ¹é…ï¼‰
                            seen_indices = set()
                            conversion_data = []
                            for r in all_unmatched_results:
                                original_idx = r['originalIndex']
                                if original_idx not in seen_indices:
                                    seen_indices.add(original_idx)
                                    conversion_data.append(st.session_state.plan_data.iloc[original_idx].to_dict())

                            # è½¬æ¢æ•°æ®
                            converted_data = convert_data(conversion_data)

                            # å¯¼å‡º
                            output = BytesIO()
                            temp_path = "temp_converted.xlsx"
                            export_converted_data_to_excel(converted_data, conversion_data, temp_path)

                            with open(temp_path, 'rb') as f:
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½è½¬æ¢åçš„ä¸“ä¸šåˆ†æ•°æ®",
                                    f.read(),
                                    file_name=f"ä¸“ä¸šåˆ†æ•°æ®_æœªåŒ¹é…æ•°æ®_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )

                            os.remove(temp_path)
                            st.success(f"è½¬æ¢å®Œæˆï¼å…±è½¬æ¢ {len(converted_data)} æ¡æ•°æ®ï¼ˆå·²å»é‡ï¼‰")
                        except Exception as e:
                            st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
                else:
                    st.info("æš‚æ— æœªåŒ¹é…æ•°æ®")

            with col3:
                if len(all_unmatched_results) > 0:
                    if st.button("â­ å¯¼å‡ºæœªåŒ¹é…æ•°æ®ä¸ºé™¢æ ¡åˆ†æ ¼å¼", type="primary", use_container_width=True):
                        try:
                            # æå–åŸå§‹æ•°æ®ï¼ˆå»é‡ï¼Œå› ä¸ºåŒä¸€ä¸ªè®°å½•å¯èƒ½åœ¨æ¯”å¯¹1å’Œæ¯”å¯¹2ä¸­éƒ½æœªåŒ¹é…ï¼‰
                            seen_indices = set()
                            conversion_data = []
                            for r in all_unmatched_results:
                                original_idx = r['originalIndex']
                                if original_idx not in seen_indices:
                                    seen_indices.add(original_idx)
                                    conversion_data.append(st.session_state.plan_data.iloc[original_idx].to_dict())

                            # è½¬æ¢æ•°æ®ä¸ºé™¢æ ¡åˆ†æ ¼å¼
                            college_score_data = convert_to_college_score_format(conversion_data)

                            # å¯¼å‡º
                            temp_path = "temp_college_score.xlsx"
                            export_college_score_data_to_excel(college_score_data, conversion_data, temp_path)

                            with open(temp_path, 'rb') as f:
                                st.download_button(
                                    "ğŸ“¥ ä¸‹è½½è½¬æ¢åçš„é™¢æ ¡åˆ†æ•°æ®",
                                    f.read(),
                                    file_name=f"é™¢æ ¡åˆ†æ•°æ®_æœªåŒ¹é…æ•°æ®_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )

                            os.remove(temp_path)
                            st.success(f"è½¬æ¢å®Œæˆï¼å…±è½¬æ¢ {len(college_score_data)} æ¡æ•°æ®ï¼ˆå·²å»é‡å¹¶åˆ†ç»„ï¼‰")
                        except Exception as e:
                            st.error(f"è½¬æ¢å¤±è´¥: {str(e)}")
                else:
                    st.info("æš‚æ— æœªåŒ¹é…æ•°æ®")

# é¡µè„š
st.markdown("---")
st.markdown("Â© æ•°æ®å¤„ç†", unsafe_allow_html=True)
