import streamlit as st
import pandas as pd
import os
import logging
import re
import streamlit.components.v1 as components
from difflib import SequenceMatcher
from concurrent.futures import ThreadPoolExecutor, as_completed
import openpyxl
from openpyxl.styles import PatternFill, Alignment
from openpyxl.styles import numbers
import base64
import sys
from io import BytesIO
import requests
import tempfile
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup
from PIL import Image
import io


# ============================
# åˆå§‹åŒ–è®¾ç½®
# ============================
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†å·¥å…·â€”â€”æµ‹è¯•",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logging.info("å¯åŠ¨æ•°æ®å¤„ç†å·¥å…·ã€‚")


# ============================
# å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°
# ============================

# ======== è·¯å¾„å…¼å®¹å‡½æ•° =========
def resource_path(relative_path):
    """å…¼å®¹ PyCharm å¼€å‘ç¯å¢ƒ å’Œ PyInstaller æ‰“åŒ…åçš„è·¯å¾„"""
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    return os.path.join(os.path.abspath("."), relative_path)


# ======== åŠ è½½å­¦æ ¡æ•°æ® =========
try:
    school_data_path = resource_path("school_data.xlsx")
    school_df = pd.read_excel(school_data_path)
    VALID_SCHOOL_NAMES = set(school_df['å­¦æ ¡åç§°'].dropna().str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_SCHOOL_NAMES)} ä¸ªæœ‰æ•ˆå­¦æ ¡åç§°")
except Exception as e:
    logging.error(f"è¯»å– school_data.xlsx å‡ºé”™ï¼š{e}")
    VALID_SCHOOL_NAMES = set()
    st.warning("å­¦æ ¡æ•°æ®åŠ è½½å¤±è´¥ï¼Œå­¦æ ¡åç§°æ£€æŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨")

# ======== åŠ è½½æ‹›ç”Ÿä¸“ä¸šæ•°æ® =========
try:
    major_data_path = resource_path("æ‹›ç”Ÿä¸“ä¸š.xlsx")
    major_df = pd.read_excel(major_data_path)
    VALID_MAJOR_COMBOS = set(major_df['æ‹›ç”Ÿä¸“ä¸š'].dropna().astype(str).str.strip())
    logging.info(f"æˆåŠŸåŠ è½½ {len(VALID_MAJOR_COMBOS)} ä¸ªæœ‰æ•ˆä¸“ä¸šç»„åˆ")
except Exception as e:
    logging.error(f"è¯»å– æ‹›ç”Ÿä¸“ä¸š.xlsx å‡ºé”™ï¼š{e}")
    VALID_MAJOR_COMBOS = set()
    st.warning("ä¸“ä¸šæ•°æ®åŠ è½½å¤±è´¥ï¼Œä¸“ä¸šåŒ¹é…åŠŸèƒ½å°†ä¸å¯ç”¨")


def check_school_name(name):
    if pd.isna(name) or not str(name).strip():
        return 'å­¦æ ¡åç§°ä¸ºç©º'
    return 'åŒ¹é…' if name.strip() in VALID_SCHOOL_NAMES else 'ä¸åŒ¹é…'


def check_major_combo(major, level):
    if pd.isna(major) or pd.isna(level):
        return "æ•°æ®ç¼ºå¤±"
    combo = f"{str(major).strip()}{str(level).strip()}"
    return "åŒ¹é…" if combo in VALID_MAJOR_COMBOS else "ä¸åŒ¹é…"


CUSTOM_WHITELIST = {
    "å®ç¦æ ¡åŒº", "æ²™æ²³æ ¡åŒº", "ä¸­å¤–åˆä½œåŠå­¦", "ç æµ·æ ¡åŒº", "æ±ŸåŒ—æ ¡åŒº", "æ´¥å—æ ¡åŒº", "å¼€å°æ ¡åŒº",
    "è”åˆåŠå­¦", "æ ¡ä¼åˆä½œ", "åˆä½œåŠå­¦", "å¨æµ·æ ¡åŒº", "æ·±åœ³æ ¡åŒº", "è‹å·æ ¡åŒº", "å¹³æœæ ¡åŒº",
    "æ±Ÿå—æ ¡åŒº", "åˆå·æ ¡åŒº", "é•¿å®‰æ ¡åŒº", "å´‡å®‰æ ¡åŒº", "å—æ ¡åŒº", "ä¸œæ ¡åŒº", "éƒ½å¸‚å›­è‰º", "ç”˜è‚ƒå…°å·"
}

TYPO_DICT = {
    "æ•™åŠ©": "æ•‘åŠ©",
    "æŒ‡è¾‰": "æŒ‡æŒ¥",
    "æ–™å­¦": "ç§‘å­¦",
    "è¯è¨€": "è¯­è¨€",
    "5å3": "5+3",
    "5å3ä¸€ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "â€œ5å3â€ä¸€ä½“åŒ–": "â€œ5+3â€ä¸€ä½“åŒ–",
    "5+31ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "5+3ä½“åŒ–": "5+3ä¸€ä½“åŒ–",
    "è‰²è¨€": "è‰²ç›²",
    "NIT": "NIIT",
    "è‰²è‚²": "è‰²ç›²",
    "äººå›´": "å…¥å›´",
    "é¡¹æœˆ": "é¡¹ç›®",
    "å¸èŒƒç±»": "å¸ˆèŒƒç±»",
    "æŠ•è¯¾": "æˆè¯¾",
    "å°±è–„": "å°±è¯»",
    "ç”µè¯·": "ç”³è¯·",
    "ä¸­å›½é¢": "ä¸­å›½ç”»",
    "ç«æ•°æ°‘æ—": "å°‘æ•°æ°‘æ—",
    "è‰²è‡ª": "è‰²ç›²",
    "è‰²ç›²è‰²å¼±ç”³æŠ¥": "è‰²ç›²è‰²å¼±æ…æŠ¥",
    "æ•°å­¦ä¸åº”ç”¨æ•°ç¬‘": "æ•°å­¦ä¸åº”ç”¨æ•°å­¦",
    "æ³•å­¦å": "æ³•å­¦+",
    "æµ£æµ·æ ¡åŒº": "æ»¨æµ·æ ¡åŒº",
    "ä¸­æº´": "ä¸­æ¾³"
}

REGEX_PATTERNS = {
    'excess_punct': re.compile(r'[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+'),
    'outer_punct': re.compile(r'^[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+|[ï¼Œã€ã€‚ï¼ï¼Ÿï¼›,;.!? ]+$'),
    'consecutive_right': re.compile(r'ï¼‰{2,}')
}
NESTED_PAREN_PATTERN = re.compile(r'ï¼ˆï¼ˆ(.*?)ï¼‰ï¼‰')
CONSECUTIVE_REPEAT_PATTERN = re.compile(r'ï¼ˆ(.+?)ï¼‰\s*ï¼ˆ\1ï¼‰')


def similar(a, b):
    return SequenceMatcher(None, a, b).ratio()


def normalize_brackets(text):
    """ç»Ÿä¸€å„ç§æ‹¬å·ä¸ºä¸­æ–‡æ‹¬å·å¹¶å¤„ç†ä¸å®Œæ•´æ‹¬å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()

    # æ›¿æ¢æ‰€æœ‰æ‹¬å·å˜ä½“ä¸ºä¸­æ–‡æ‹¬å·
    text = re.sub(r'[{\[ã€]', 'ï¼ˆ', text)  # å·¦æ‹¬å·
    text = re.sub(r'[}\]ã€‘]', 'ï¼‰', text)  # å³æ‹¬å·
    text = re.sub(r'[<ã€Š]', 'ï¼ˆ', text)  # å·¦ä¹¦åå·æ›¿æ¢ä¸ºå·¦æ‹¬å·
    text = re.sub(r'[>ã€‹]', 'ï¼‰', text)  # å³ä¹¦åå·æ›¿æ¢ä¸ºå³æ‹¬å·

    return text


def clean_outer_punctuation(text):
    """æ¸…ç†æœ€å¤–å±‚æ‹¬å·å¤–çš„æ ‡ç‚¹ç¬¦å·"""
    if pd.isna(text) or not str(text).strip():
        return text
    text = str(text).strip()
    text = REGEX_PATTERNS['outer_punct'].sub('', text)
    parts = re.split(r'(ï¼ˆ.*?ï¼‰)', text)
    cleaned_parts = []
    for part in parts:
        if part.startswith('ï¼ˆ') and part.endswith('ï¼‰'):
            cleaned_parts.append(part)
        else:
            cleaned_parts.append(REGEX_PATTERNS['outer_punct'].sub('', part))
    return ''.join(cleaned_parts)


def check_score_consistency(row):
    """æ£€æŸ¥åˆ†æ•°ä¸€è‡´æ€§ï¼šæœ€é«˜åˆ† >= å¹³å‡åˆ† >= æœ€ä½åˆ†"""
    issues = []
    try:
        max_score = float(row['æœ€é«˜åˆ†']) if pd.notna(row['æœ€é«˜åˆ†']) else None
        avg_score = float(row['å¹³å‡åˆ†']) if pd.notna(row['å¹³å‡åˆ†']) else None
        min_score = float(row['æœ€ä½åˆ†']) if pd.notna(row['æœ€ä½åˆ†']) else None

        if max_score is not None and avg_score is not None and max_score < avg_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < å¹³å‡åˆ†({avg_score})")

        if max_score is not None and min_score is not None and max_score < min_score:
            issues.append(f"æœ€é«˜åˆ†({max_score}) < æœ€ä½åˆ†({min_score})")

        if avg_score is not None and min_score is not None and avg_score < min_score:
            issues.append(f"å¹³å‡åˆ†({avg_score}) < æœ€ä½åˆ†({min_score})")

    except (ValueError, TypeError) as e:
        issues.append(f"åˆ†æ•°æ ¼å¼é”™è¯¯: {str(e)}")

    return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜'


def analyze_and_fix(text):
    if pd.isna(text) or not str(text).strip():
        return text, []

    text = normalize_brackets(text)
    text = clean_outer_punctuation(text)
    issues = []

    if text in CUSTOM_WHITELIST:
        return text, []

    # ========== æ‹¬å·æˆå¯¹ä¿®æ­£ ==========
    text_list = list(text)
    stack = []
    unmatched_right = []

    for i, char in enumerate(text_list):
        if char == 'ï¼ˆ':
            stack.append(i)
        elif char == 'ï¼‰':
            if stack:
                stack.pop()
            else:
                unmatched_right.append(i)

    for i in reversed(unmatched_right):
        del text_list[i]
        issues.append("åˆ é™¤å¤šä½™å³æ‹¬å·1ä¸ª")

    if stack:
        text_list.extend(['ï¼‰'] * len(stack))
        issues.append(f"è¡¥å……ç¼ºå¤±å³æ‹¬å·{len(stack)}ä¸ª")

    text = ''.join(text_list)

    # åµŒå¥—ä¿®æ­£
    text, nested_count = NESTED_PAREN_PATTERN.subn(r'ï¼ˆ\1ï¼‰', text)
    if nested_count > 0:
        issues.append(f"ä¿®å¤åµŒå¥—æ‹¬å·{nested_count}å¤„")

    # ========== æ¸…ç†ç©ºæ‹¬å·æˆ–çº¯æ ‡ç‚¹æ‹¬å· ==========
    def clean_empty_paren(m):
        content = m.group(1).strip('ï¼Œã€,;ï¼›:ï¼šã€‚ï¼ï¼Ÿ.!? ')
        if not content:
            issues.append("åˆ é™¤ç©ºæ‹¬å·æˆ–ä»…å«æ ‡ç‚¹æ‹¬å·")
            return ''
        return f'ï¼ˆ{content}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', clean_empty_paren, text)

    # ========== å»é‡ ==========
    seen = set()
    def dedup(m):
        c = m.group(1)
        if c in seen:
            issues.append(f"é‡å¤æ‹¬å·å†…å®¹ï¼š'{c}'")
            return ''
        seen.add(c)
        return f'ï¼ˆ{c}ï¼‰'

    text = re.sub(r'ï¼ˆ(.*?)ï¼‰', dedup, text)

    # ========== å¤šä½™æ ‡ç‚¹ç®€åŒ– ==========
    text = REGEX_PATTERNS['excess_punct'].sub(lambda m: m.group(0)[0], text)

    # ========== é”™åˆ«å­—ä¿®æ­£ ==========
    for typo, corr in TYPO_DICT.items():
        if typo in text:
            text = text.replace(typo, corr)
            issues.append(f"é”™åˆ«å­—ï¼š'{typo}'â†’'{corr}'")

    return text, issues



def process_chunk(chunk):
    """å¤„ç†æ•°æ®å—"""
    # å­¦æ ¡åç§°æ£€æŸ¥
    if 'å­¦æ ¡åç§°' in chunk.columns:
        chunk['å­¦æ ¡åŒ¹é…ç»“æœ'] = chunk['å­¦æ ¡åç§°'].apply(check_school_name)

    # ä¸“ä¸šåŒ¹é…æ£€æŸ¥
    if 'æ‹›ç”Ÿä¸“ä¸š' in chunk.columns and 'ä¸€çº§å±‚æ¬¡' in chunk.columns:
        chunk['æ‹›ç”Ÿä¸“ä¸šåŒ¹é…ç»“æœ'] = chunk.apply(
            lambda r: check_major_combo(r['æ‹›ç”Ÿä¸“ä¸š'], r['ä¸€çº§å±‚æ¬¡']), axis=1)

    # å¤‡æ³¨å¤„ç† - ä¿®æ”¹è¿™éƒ¨åˆ†
    if 'ä¸“ä¸šå¤‡æ³¨' in chunk.columns:
        def process_remark(remark):
            if pd.isna(remark) or not str(remark).strip():
                return 'æ— é—®é¢˜', ''
            fixed_text, issues = analyze_and_fix(remark)
            return 'ï¼›'.join(issues) if issues else 'æ— é—®é¢˜', fixed_text

        chunk[['å¤‡æ³¨æ£€æŸ¥ç»“æœ', 'ä¿®æ”¹åå¤‡æ³¨']] = chunk['ä¸“ä¸šå¤‡æ³¨'].apply(
            lambda x: pd.Series(process_remark(x)))

    # åˆ†æ•°æ£€æŸ¥
    score_columns = ['æœ€é«˜åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†']
    if all(col in chunk.columns for col in score_columns):
        chunk['åˆ†æ•°æ£€æŸ¥ç»“æœ'] = chunk.apply(check_score_consistency, axis=1)

    # é€‰ç§‘è¦æ±‚å¤„ç†
    if 'é€‰ç§‘è¦æ±‚' in chunk.columns:
        def proc_req(req):
            if pd.isna(req) or not str(req).strip():
                return ["", ""]
            s = str(req).strip()
            if "ä¸é™" in s:
                return ["ä¸é™ç§‘ç›®ä¸“ä¸šç»„", ""]
            if len(s) == 1:
                return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s]
            if "ä¸”" in s:
                return ["å•ç§‘ã€å¤šç§‘å‡éœ€é€‰è€ƒ", s.replace("ä¸”", "")]
            if "æˆ–" in s:
                return ["å¤šé—¨é€‰è€ƒ", s.replace("æˆ–", "")]
            return ["", ""]

        chunk[['é€‰ç§‘è¦æ±‚è¯´æ˜', 'æ¬¡é€‰']] = chunk['é€‰ç§‘è¦æ±‚'].apply(
            lambda x: pd.Series(proc_req(x)))

    # æ‹›ç”Ÿç§‘ç±»å¤„ç†
    if 'æ‹›ç”Ÿç§‘ç±»' in chunk.columns:
        chunk['æ‹›ç”Ÿç§‘ç±»'] = chunk['æ‹›ç”Ÿç§‘ç±»'].replace({'ç‰©ç†': 'ç‰©ç†ç±»', 'å†å²': 'å†å²ç±»'})
        chunk['é¦–é€‰ç§‘ç›®'] = chunk['æ‹›ç”Ÿç§‘ç±»'].apply(
            lambda x: str(x)[0] if x in ['ç‰©ç†ç±»', 'å†å²ç±»'] else "")

    return chunk



# ============================
# é™¢æ ¡åˆ†æå–ç›¸å…³å‡½æ•°ï¼ˆæ™®é€šç±»ï¼‰
# ============================
expected_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡',
    'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰', 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', 'æ•°æ®æ¥æº',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'
]
columns_to_convert = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'
]

def process_score_file(file_path):
    # é¦–å…ˆè¯»å–å¹´ä»½ï¼ˆä»B2å•å…ƒæ ¼ï¼‰
    try:
        wb = openpyxl.load_workbook(file_path, data_only=True)
        ws = wb.active
        year_value = ws['B2'].value
        if year_value is None:
            # å¦‚æœB2ä¸ºç©ºï¼Œå°è¯•ä»æ•°æ®ä¸­æå–å¹´ä»½
            year_value = ''
        else:
            year_value = str(year_value).strip()
        wb.close()
    except Exception as e:
        year_value = ''

    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€é«˜åˆ†': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰': str,
            'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    missing_columns = [col for col in expected_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æœ€é«˜åˆ†'] = pd.to_numeric(df['æœ€é«˜åˆ†'], errors='coerce')
    df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = pd.to_numeric(df['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'], errors='coerce')
    df = df.dropna(subset=['æœ€ä½åˆ†'])

    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'] = df['æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰'].fillna('')


    # é¦–é€‰ç§‘ç›®è½¬æ¢é€»è¾‘
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()  # å»é™¤å‰åç©ºæ ¼
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',  # ç¡®ä¿å·²ç»æ˜¯"å†å²"çš„ä¸å˜
            'ç‰©ç†': 'ç‰©ç†'  # ç¡®ä¿å·²ç»æ˜¯"ç‰©ç†"çš„ä¸å˜
        })

    try:
        # åˆ¤æ–­æ˜¯å¦æœ‰ä¸“ä¸šç»„ä»£ç åˆ—ï¼Œä¸”ä¸å…¨ä¸ºç©º
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸€çº§å±‚æ¬¡', 'æ‹›ç”Ÿç§‘ç±»', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # æ¯ç»„æœ€é«˜åˆ†
        max_scores = df.groupby(group_fields)['æœ€é«˜åˆ†'].max()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

        # è¡¥å……æœ€é«˜åˆ†
        def get_max_score(row):
            key = tuple(row[col] for col in group_fields)
            return max_scores.get(key, None)

        result['æœ€é«˜åˆ†'] = result.apply(get_max_score, axis=1)

        # æ‹›ç”Ÿäººæ•°ã€å½•å–äººæ•°æŒ‰åˆ†ç»„æ€»å’Œ
        enroll_groups = df.groupby(group_fields)['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()
        code_groups = df.groupby(group_fields)['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'].sum()

        def get_group_total(row, column_name):
            key = tuple(row[col] for col in group_fields)
            if column_name == 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return enroll_groups.get(key, '')
            elif column_name == 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰':
                return code_groups.get(key, '')
            return ''

        result['æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)
        result['å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'] = result.apply(lambda row: get_group_total(row, 'å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰'), axis=1)

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # æ„å»ºæ–°çš„æ•°æ®æ¡†ï¼ŒæŒ‰ç…§æ–°çš„åˆ—é¡ºåº
    new_columns = [
        'å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§', 
        'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡', 
        'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨', 
        'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç '
    ]
    
    # åˆ›å»ºæ–°çš„DataFrameï¼Œç¡®ä¿æ‰€æœ‰åˆ—éƒ½æœ‰æ­£ç¡®çš„é•¿åº¦
    num_rows = len(result)
    new_result = pd.DataFrame(index=range(num_rows))
    
    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†åˆ—å€¼ï¼Œå°†NaNè½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆç”¨äºæ–‡æœ¬åˆ—ï¼‰
    def get_col_values(col_name, default=''):
        if col_name in result.columns:
            values = result[col_name].fillna(default).astype(str).values
            # å°†'nan'å­—ç¬¦ä¸²è½¬æ¢å›ç©ºå­—ç¬¦ä¸²
            values = ['' if str(v).lower() == 'nan' else v for v in values]
            return values
        else:
            return [default] * num_rows
    
    # è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æ•°å­—åˆ—å€¼ï¼Œä¿æŒæ•°å­—ç±»å‹
    def get_numeric_values(col_name, default=0):
        if col_name in result.columns:
            values = result[col_name].fillna(default)
            # å°è¯•è½¬æ¢ä¸ºæ•°å­—ï¼Œæ— æ³•è½¬æ¢çš„ä¿æŒåŸå€¼æˆ–è®¾ä¸ºé»˜è®¤å€¼
            try:
                return pd.to_numeric(values, errors='coerce').fillna(default).values
            except:
                return [default] * num_rows
        else:
            return [default] * num_rows
    
    new_result['å­¦æ ¡åç§°'] = get_col_values('å­¦æ ¡åç§°')
    new_result['çœä»½'] = get_col_values('çœä»½')
    new_result['æ‹›ç”Ÿç±»åˆ«'] = get_col_values('æ‹›ç”Ÿç§‘ç±»')
    new_result['æ‹›ç”Ÿæ‰¹æ¬¡'] = get_col_values('æ‹›ç”Ÿæ‰¹æ¬¡')
    new_result['æ‹›ç”Ÿç±»å‹'] = get_col_values('æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰')
    new_result['é€‰æµ‹ç­‰çº§'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜åˆ†'] = get_col_values('æœ€é«˜åˆ†')
    new_result['æœ€ä½åˆ†'] = get_col_values('æœ€ä½åˆ†')
    new_result['å¹³å‡åˆ†'] = [''] * num_rows  # åˆ é™¤å¹³å‡åˆ†æå–é€»è¾‘ï¼Œè®¾ä¸ºç©º
    new_result['æœ€é«˜ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['æœ€ä½ä½æ¬¡'] = get_col_values('æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰')
    new_result['å¹³å‡ä½æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['å½•å–äººæ•°'] = get_numeric_values('å½•å–äººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ‹›ç”Ÿäººæ•°'] = get_numeric_values('æ‹›ç”Ÿäººæ•°ï¼ˆé€‰å¡«ï¼‰', default=0)  # ä¿æŒæ•°å­—æ ¼å¼
    new_result['æ•°æ®æ¥æº'] = get_col_values('æ•°æ®æ¥æº')
    new_result['çœæ§çº¿ç§‘ç±»'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿æ‰¹æ¬¡'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['çœæ§çº¿å¤‡æ³¨'] = [''] * num_rows  # æ–°å­—æ®µï¼Œè®¾ä¸ºç©º
    new_result['ä¸“ä¸šç»„ä»£ç '] = get_col_values('ä¸“ä¸šç»„ä»£ç ')
    new_result['é¦–é€‰ç§‘ç›®'] = get_col_values('é¦–é€‰ç§‘ç›®')
    new_result['é™¢æ ¡æ‹›ç”Ÿä»£ç '] = get_col_values('æ‹›ç”Ÿä»£ç ')

    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        # åˆ›å»ºå¤‡æ³¨æ–‡æœ¬
        remark_text = """å¤‡æ³¨ï¼šè¯·åˆ é™¤ç¤ºä¾‹åå†å¡«å†™ï¼›
1.çœä»½ï¼šå¿…é¡»å¡«å†™å„çœä»½ç®€ç§°ï¼Œä¾‹å¦‚ï¼šåŒ—äº¬ã€å†…è’™å¤ï¼Œä¸èƒ½å¸¦æœ‰å¸‚ã€çœã€è‡ªæ²»åŒºã€ç©ºæ ¼ã€ç‰¹æ®Šå­—ç¬¦ç­‰
2.ç§‘ç±»ï¼šæµ™æ±Ÿã€ä¸Šæµ·é™å®š"ç»¼åˆã€è‰ºæœ¯ç±»ã€ä½“è‚²ç±»"ï¼Œå†…è’™å¤é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è’™æˆæ–‡ç§‘ã€è’™æˆç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†ã€è’™æˆè‰ºæœ¯ã€è’™æˆä½“è‚²"ï¼Œå…¶ä»–çœä»½é™å®š"æ–‡ç§‘ã€ç†ç§‘ã€è‰ºæœ¯ç±»ã€è‰ºæœ¯æ–‡ã€è‰ºæœ¯ç†ã€ä½“è‚²ç±»ã€ä½“è‚²æ–‡ã€ä½“è‚²ç†"
3.æ‰¹æ¬¡ï¼šï¼ˆä»¥ä¸‹ä¸º19å¹´ä½¿ç”¨æ‰¹æ¬¡ï¼‰
    åŒ—äº¬ã€å¤©æ´¥ã€è¾½å®ã€ä¸Šæµ·ã€å±±ä¸œã€å¹¿ä¸œã€æµ·å—é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æ²³åŒ—ã€å†…è’™å¤ã€å‰æ—ã€æ±Ÿè‹ã€å®‰å¾½ã€ç¦å»ºã€æ±Ÿè¥¿ã€æ²³å—ã€æ¹–åŒ—ã€å¹¿è¥¿ã€é‡åº†ã€å››å·ã€è´µå·ã€äº‘å—ã€è¥¿è—ã€é™•è¥¿ã€ç”˜è‚ƒã€å®å¤ã€æ–°ç–†é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    é»‘é¾™æ±Ÿã€æ¹–å—ã€é’æµ·é™å®šæœ¬ç§‘æå‰æ‰¹ã€æœ¬ç§‘ä¸€æ‰¹ã€æœ¬ç§‘äºŒæ‰¹ã€æœ¬ç§‘ä¸‰æ‰¹ã€ä¸“ç§‘æå‰æ‰¹ã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    å±±è¥¿é™å®šæœ¬ç§‘ä¸€æ‰¹Aæ®µã€æœ¬ç§‘ä¸€æ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Aæ®µã€æœ¬ç§‘äºŒæ‰¹Bæ®µã€æœ¬ç§‘äºŒæ‰¹Cæ®µã€ä¸“ç§‘æ‰¹ã€å›½å®¶ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ã€åœ°æ–¹ä¸“é¡¹è®¡åˆ’æœ¬ç§‘æ‰¹ï¼›
    æµ™æ±Ÿé™å®šæ™®é€šç±»æå‰æ‰¹ã€å¹³è¡Œå½•å–ä¸€æ®µã€å¹³è¡Œå½•å–äºŒæ®µã€å¹³è¡Œå½•å–ä¸‰æ®µ
4.æœ€é«˜åˆ†ã€æœ€ä½åˆ†ã€å¹³å‡åˆ†ï¼šä»…èƒ½å¡«å†™æ•°å­—ï¼ˆæœ€å¤šä¿ç•™2ä½å°æ•°ï¼‰ï¼Œä¸”ä¸‰è€…é¡ºåºä¸èƒ½æ”¹å˜ï¼Œæœ€ä½åˆ†ä¸ºå¿…å¡«é¡¹ï¼Œå…¶ä¸­è‰ºæœ¯ç±»å’Œä½“è‚²ç±»åˆ†æ•°ä¸ºæ–‡åŒ–è¯¾åˆ†æ•°
5.æœ€ä½åˆ†ä½æ¬¡ï¼šä»…èƒ½å¡«å†™æ•°å­—
6.å½•å–äººæ•°ï¼šä»…èƒ½å¡«å†™æ•°å­—
7.é¦–é€‰ç§‘ç›®ï¼šæ–°å…«çœå¿…å¡«ï¼Œåªèƒ½å¡«å†™ï¼ˆå†å²æˆ–ç‰©ç†ï¼‰"""

        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            # å…ˆå†™å…¥æ•°æ®ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼Œä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            new_result.to_excel(writer, index=False, header=False, startrow=3)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']

            # ç¬¬ä¸€è¡Œï¼šåˆå¹¶A1-U1å¹¶å†™å…¥å¤‡æ³¨
            worksheet.merge_cells('A1:U1')
            worksheet['A1'] = remark_text
            worksheet['A1'].alignment = Alignment(wrap_text=True, vertical='top')
            # è®¾ç½®ç¬¬ä¸€è¡Œè¡Œé«˜ä¸º215ç£…
            worksheet.row_dimensions[1].height = 215
            
            # ç¬¬äºŒè¡Œï¼šA2="æ‹›ç”Ÿå¹´"ï¼ŒB2=å¹´ä»½ï¼ŒC2="1"ï¼ŒD2="æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰"
            worksheet['A2'] = 'æ‹›ç”Ÿå¹´'
            # B2å’ŒC2è®¾ç½®ä¸ºæ•°å­—æ ¼å¼
            try:
                # å°è¯•å°†å¹´ä»½è½¬æ¢ä¸ºæ•°å­—
                if year_value and str(year_value).strip():
                    year_num = int(float(str(year_value).strip()))
                    worksheet['B2'] = year_num
                else:
                    worksheet['B2'] = ''
            except:
                worksheet['B2'] = year_value
            worksheet['C2'] = 1  # ç›´æ¥è®¾ç½®ä¸ºæ•°å­—1
            worksheet['D2'] = 'æ¨¡æ¿ç±»å‹ï¼ˆæ¨¡æ¿æ ‡è¯†ä¸è¦æ›´æ”¹ï¼‰'
            
            # ç¬¬ä¸‰è¡Œï¼šæ ‡é¢˜è¡Œ
            headers = ['å­¦æ ¡åç§°', 'çœä»½', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æ‹›ç”Ÿç±»å‹', 'é€‰æµ‹ç­‰çº§', 
                      'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'å¹³å‡åˆ†', 'æœ€é«˜ä½æ¬¡', 'æœ€ä½ä½æ¬¡', 'å¹³å‡ä½æ¬¡', 
                      'å½•å–äººæ•°', 'æ‹›ç”Ÿäººæ•°', 'æ•°æ®æ¥æº', 'çœæ§çº¿ç§‘ç±»', 'çœæ§çº¿æ‰¹æ¬¡', 'çœæ§çº¿å¤‡æ³¨', 
                      'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ']
            for col_idx, header in enumerate(headers, start=1):
                worksheet.cell(row=3, column=col_idx, value=header)

            # è®¾ç½®æ–‡æœ¬æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼Œå³æ•°æ®è¡Œï¼‰
            # éœ€è¦è®¾ç½®ä¸ºæ–‡æœ¬æ ¼å¼çš„åˆ—ï¼ˆä½¿ç”¨æ–°åˆ—åï¼Œä¸åŒ…æ‹¬æ‹›ç”Ÿäººæ•°å’Œå½•å–äººæ•°ï¼‰
            text_format_cols = ['ä¸“ä¸šç»„ä»£ç ', 'é™¢æ ¡æ‹›ç”Ÿä»£ç ', 'æœ€é«˜åˆ†', 'æœ€ä½åˆ†', 'æœ€ä½ä½æ¬¡']
            for col in text_format_cols:
                if col in new_result.columns:
                    col_idx = new_result.columns.get_loc(col) + 1
                    for row in range(4, len(new_result) + 4):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT
            
            # ç¡®ä¿B2å’ŒC2å•å…ƒæ ¼ä¿æŒæ•°å­—æ ¼å¼
            if worksheet['B2'].value is not None and str(worksheet['B2'].value).strip():
                try:
                    worksheet['B2'].value = int(float(str(worksheet['B2'].value)))
                except:
                    pass
            worksheet['C2'].value = 1
            
            # ç¡®ä¿"å½•å–äººæ•°"å’Œ"æ‹›ç”Ÿäººæ•°"åˆ—ä¿æŒæ•°å­—æ ¼å¼ï¼ˆä»ç¬¬4è¡Œå¼€å§‹ï¼‰
            if 'å½•å–äººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('å½•å–äººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass
            
            if 'æ‹›ç”Ÿäººæ•°' in new_result.columns:
                col_idx = new_result.columns.get_loc('æ‹›ç”Ÿäººæ•°') + 1
                for row in range(4, len(new_result) + 4):
                    cell = worksheet.cell(row=row, column=col_idx)
                    if cell.value is not None:
                        try:
                            cell.value = float(cell.value) if str(cell.value).strip() else 0
                        except:
                            pass

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")

# ============================
# ä¿æŒæ–‡æœ¬æ ¼å¼
# ============================
def process_remarks_file(file_path, progress_callback=None):
    try:
        # è¯»å–æ–‡ä»¶æ—¶ï¼Œç¡®ä¿è¿™äº›å­—æ®µå§‹ç»ˆä»¥å­—ç¬¦ä¸²æ ¼å¼è¯»å–
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
        }, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")
    for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
        if col in df.columns:
            df[col] = df[col].astype(str)
    target_col = None
    for col in df.columns:
        if "ä¸“ä¸šå¤‡æ³¨" in str(col):
            target_col = col
            break
    if not target_col:
        raise Exception("æœªæ‰¾åˆ°'ä¸“ä¸šå¤‡æ³¨'ç›¸å…³åˆ—")
    if target_col != 'ä¸“ä¸šå¤‡æ³¨':
        df = df.rename(columns={target_col: 'ä¸“ä¸šå¤‡æ³¨'})
    chunks = []
    for i in range(0, len(df), 1000):
        chunks.append(df.iloc[i:i + 1000].copy())
    results = {}
    total_chunks = len(chunks)
    with ThreadPoolExecutor(max_workers=os.cpu_count() or 4) as executor:
        future_to_index = {executor.submit(process_chunk, chunk): idx for idx, chunk in enumerate(chunks)}
        for count, future in enumerate(as_completed(future_to_index)):
            idx = future_to_index[future]
            results[idx] = future.result()
            if progress_callback:
                progress_callback(count + 1, total_chunks)
    ordered_results = [results[i] for i in sorted(results.keys())]
    final_result = pd.concat(ordered_results)
    output_path = file_path.replace('.xlsx', '_æ£€æŸ¥ç»“æœ.xlsx')
    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            final_result.to_excel(writer, index=False)
            workbook = writer.book
            worksheet = writer.sheets['Sheet1']
            # ä¿æŒæŒ‡å®šåˆ—ä»ç¬¬ä¸‰è¡Œå¼€å§‹æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in final_result.columns:
                    col_idx = final_result.columns.get_loc(col) + 1  # è½¬æ¢ä¸ºExcelåˆ—å·ï¼ˆA=1ï¼‰
                    # ä»ç¬¬ä¸‰è¡Œå¼€å§‹è®¾ç½®æ ¼å¼ï¼ˆExcelè¡Œå·ä¸º3ï¼Œå¯¹åº”Pythonçš„ç´¢å¼•ä¸º2ï¼‰
                    for row in range(3, len(final_result) + 2):  # å·¥ä½œè¡¨è¡Œå·ä»3å¼€å§‹ï¼ˆç´¢å¼•2ï¼‰
                        cell = worksheet.cell(row=row, column=col_idx)
                        cell.value = final_result.iloc[row - 3][col]  # æ•°æ®ä»ç¬¬ä¸‰è¡Œå¼€å§‹å¡«å……
                        cell.number_format = numbers.FORMAT_TEXT
    except Exception as e:
        raise Exception(f"ä¿å­˜æ–‡ä»¶é”™è¯¯ï¼š{e}")
    return output_path

# ============================
# é™¢æ ¡åˆ†æ•°æ®å¤„ç†ï¼ˆè‰ºä½“ç±»ï¼‰
# ============================

expected_new_columns = [
    'å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸š', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡',
    'ä¸“ä¸šç±»åˆ«', 'æ˜¯å¦æ ¡è€ƒ', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'ä¸“ä¸šç»„ä»£ç ', 'é¦–é€‰ç§‘ç›®', 'é€‰ç§‘è¦æ±‚', 'æ¬¡é€‰ç§‘ç›®', 'æ‹›ç”Ÿä»£ç ', 'æ ¡ç»Ÿè€ƒåˆ†',
    'æ ¡æ–‡åŒ–åˆ†', 'ä¸“ä¸šä»£ç ', 'æ•°æ®æ¥æº'
]
columns_to_convert_new = [
    'ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ', 'æœ€ä½åˆ†', 'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰',
    'æ ¡ç»Ÿè€ƒåˆ†', 'æ ¡æ–‡åŒ–åˆ†'
]

def process_new_template_file(file_path):
    try:
        df = pd.read_excel(file_path, header=2, dtype={
            'ä¸“ä¸šç»„ä»£ç ': str,
            'ä¸“ä¸šä»£ç ': str,
            'æ‹›ç”Ÿä»£ç ': str,
            'æœ€ä½åˆ†': str,
            'æœ€ä½åˆ†ä½æ¬¡ï¼ˆé€‰å¡«ï¼‰': str,
            'æ ¡ç»Ÿè€ƒåˆ†': str,
            'æ ¡æ–‡åŒ–åˆ†': str
        }, keep_default_na=False, engine='openpyxl')
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶é”™è¯¯ï¼š{e}")

    # æ£€æŸ¥å¿…éœ€åˆ—
    missing_columns = [col for col in expected_new_columns if col not in df.columns]
    if missing_columns:
        raise Exception(f"æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹åˆ—ï¼š{missing_columns}")

    # æ•°å€¼åˆ—è½¬ä¸ºæ•°å€¼å‹
    df['æœ€ä½åˆ†'] = pd.to_numeric(df['æœ€ä½åˆ†'], errors='coerce')
    df['æ ¡ç»Ÿè€ƒåˆ†'] = pd.to_numeric(df['æ ¡ç»Ÿè€ƒåˆ†'], errors='coerce')
    df['æ ¡æ–‡åŒ–åˆ†'] = pd.to_numeric(df['æ ¡æ–‡åŒ–åˆ†'], errors='coerce')

    # åˆ é™¤æœ€ä½åˆ†ä¸ºç©ºçš„è¡Œ
    df = df.dropna(subset=['æœ€ä½åˆ†'])
    if df.empty:
        raise Exception("æ•°æ®å¤„ç†åä¸ºç©ºã€‚")

    # é¦–é€‰ç§‘ç›®æ¸…æ´—
    if 'é¦–é€‰ç§‘ç›®' in df.columns:
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].str.strip()
        df['é¦–é€‰ç§‘ç›®'] = df['é¦–é€‰ç§‘ç›®'].replace({
            'å†': 'å†å²',
            'ç‰©': 'ç‰©ç†',
            'å†å²': 'å†å²',
            'ç‰©ç†': 'ç‰©ç†'
        })

    try:
        # åˆ¤æ–­åˆ†ç»„å­—æ®µ
        if 'ä¸“ä¸šç»„ä»£ç ' in df.columns and df['ä¸“ä¸šç»„ä»£ç '].notna().any():
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡', 'ä¸“ä¸šç»„ä»£ç ']
        else:
            group_fields = ['å­¦æ ¡åç§°', 'çœä»½', 'ä¸“ä¸šæ–¹å‘ï¼ˆé€‰å¡«ï¼‰', 'ä¸“ä¸šå±‚æ¬¡', 'ä¸“ä¸šç±»åˆ«', 'æ‹›ç”Ÿç±»åˆ«', 'æ‹›ç”Ÿæ‰¹æ¬¡']

        # æ¯ç»„æœ€ä½åˆ†æ‰€åœ¨è¡Œ
        min_indices = df.groupby(group_fields)['æœ€ä½åˆ†'].idxmin()

        # å–æœ€ä½åˆ†è¡Œ
        result = df.loc[min_indices].copy()

    except Exception as e:
        raise Exception(f"åˆ†ç»„å­—æ®µé”™è¯¯ï¼š{e}")

    if result.empty:
        raise Exception("ç­›é€‰ç»“æœä¸ºç©ºã€‚")

    # ä¿ç•™æœŸæœ›åˆ—
    selected_columns = [col for col in expected_new_columns if col in result.columns]
    result = result[selected_columns]

    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_path = file_path.replace('.xlsx', '_é™¢æ ¡åˆ†.xlsx')

    try:
        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
            result.to_excel(writer, index=False)
            worksheet = writer.sheets['Sheet1']

            # è®¾ç½®æ–‡æœ¬æ ¼å¼
            for col in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                if col in result.columns:
                    col_idx = result.columns.get_loc(col) + 1
                    for row in range(2, len(result) + 2):
                        worksheet.cell(row=row, column=col_idx).number_format = numbers.FORMAT_TEXT

            for col in columns_to_convert_new:
                if col in result.columns and col not in ['ä¸“ä¸šç»„ä»£ç ', 'ä¸“ä¸šä»£ç ', 'æ‹›ç”Ÿä»£ç ']:
                    col_idx = result.columns.get_loc(col) + 1
                    for cell in list(worksheet.iter_cols(min_col=col_idx, max_col=col_idx, min_row=2, values_only=False))[0]:
                        cell.number_format = numbers.FORMAT_TEXT

        return output_path
    except Exception as e:
        raise Exception(f"æ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{e}")



# ============================
# ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†
# ============================

def process_segmentation_file(file_path):
    output_path = os.path.splitext(file_path)[0] + "_æ ¡éªŒç»“æœ.xlsx"
    wb = openpyxl.load_workbook(file_path)
    ws = wb.active

    ws['E7'] = 'ç´¯è®¡äººæ•°æ ¡éªŒç»“æœ'
    ws['F7'] = 'åˆ†æ•°æ ¡éªŒç»“æœ'
    ws['F2'] = 'å¹´ä»½æ ¡éªŒ'

    # æ ¡éªŒ B2 æ˜¯å¦ä¸º 2025
    if ws['B2'].value != 2025:
        ws['G2'] = f"Ã— åº”ä¸º2025ï¼Œå½“å‰ä¸ºï¼š{ws['B2'].value}"
    else:
        ws['G2'] = "âˆš"

    region = ws['B3'].value
    suffix = "-750"
    if region == "ä¸Šæµ·":
        suffix = "-660"
    elif region == "æµ·å—":
        suffix = "-900"

    yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

    # ---------- ç¬¬8è¡Œç‰¹æ®Šå¤„ç† ----------
    row = 8
    curr_score = ws[f"A{row}"].value
    curr_num = ws[f"B{row}"].value
    curr_total = ws[f"C{row}"].value

    try:
        score_int = int(float(str(curr_score).split('-')[0]))
    except:
        score_int = None

    inserted = False
    if curr_total is not None:
        if curr_num is None or curr_num == "":
            # æ²¡æœ‰äººæ•° â†’ è‡ªåŠ¨è®¡ç®—
            if row == 8:
                ws[f"B{row}"] = curr_total
            else:
                prev_total = ws[f"C{row - 1}"].value
                if prev_total is not None:
                    ws[f"B{row}"] = curr_total - prev_total
        else:
            # æœ‰äººæ•°å’Œç´¯è®¡äººæ•°ä¸ä¸€è‡´æ—¶æ’å…¥è¡¥æ–­ç‚¹è¡Œ
            if curr_num != curr_total:
                try:
                    insert_score = score_int + 1
                    insert_num = curr_total - curr_num
                    ws.insert_rows(row)
                    ws[f"A{row}"] = f"{insert_score}{suffix}"  # âœ… ä»…åŠ åç¼€åœ¨æ–°å¢è¡Œ
                    ws[f"B{row}"] = insert_num
                    ws[f"C{row}"] = insert_num
                    for col in ['A', 'B', 'C', 'E', 'F']:
                        ws[f"{col}{row}"].fill = yellow_fill
                    ws[f"E{row}"] = "è¡¥æ–­ç‚¹"
                    ws[f"F{row}"] = "è¡¥æ–­ç‚¹"
                    inserted = True
                except:
                    pass

    # ä»…å½“æ²¡æœ‰æ’å…¥è¡Œæ—¶ï¼Œç¬¬8è¡ŒåŠ åç¼€
    if not inserted and score_int is not None:
        ws[f"A{row}"] = f"{score_int}{suffix}"

    # ---------- è¡¥æ–­ç‚¹é€»è¾‘ ----------
    while row < ws.max_row:
        curr = ws[f"A{row}"].value
        next = ws[f"A{row + 1}"].value
        try:
            curr_score_int = int(str(curr).split('-')[0])
            next_score_int = int(str(next).split('-')[0])
        except:
            row += 1
            continue

        if curr_score_int - next_score_int > 1:
            missing_score = curr_score_int - 1
            ws.insert_rows(row + 1)
            ws[f"A{row + 1}"] = missing_score
            ws[f"B{row + 1}"] = 0
            ws[f"C{row + 1}"] = ws[f"C{row}"].value
            for col in ['A', 'B', 'C', 'E', 'F']:
                ws[f"{col}{row + 1}"].fill = yellow_fill
            ws[f"E{row + 1}"] = "è¡¥æ–­ç‚¹"
            ws[f"F{row + 1}"] = "è¡¥æ–­ç‚¹"
        else:
            row += 1

    # ---------- æ ¡éªŒä¸è‡ªåŠ¨è¡¥äººæ•° ----------
    for row in range(8, ws.max_row + 1):
        curr_score = ws[f"A{row}"].value
        curr_num = ws[f"B{row}"].value
        curr_total = ws[f"C{row}"].value
        prev_total = ws[f"C{row - 1}"].value if row > 8 else None
        prev_score = ws[f"A{row - 1}"].value if row > 8 else None

        # è‡ªåŠ¨è¡¥äººæ•°
        if (curr_num is None or curr_num == "") and curr_total is not None:
            if row == 8:
                ws[f"B{row}"] = curr_total
                curr_num = curr_total
            elif prev_total is not None:
                try:
                    calc = curr_total - prev_total
                    ws[f"B{row}"] = calc
                    curr_num = calc
                except:
                    pass

        # æ ¡éªŒç´¯è®¡äººæ•°
        if row == 8:
            # ç¬¬8è¡Œç›´æ¥æ ‡è®°æ­£ç¡®ï¼ˆå‡è®¾ç¬¬8è¡Œç´¯è®¡äººæ•°æ­£ç¡®ï¼‰
            if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"E{row}"] = "âˆš"
            correct_total = curr_total
        else:
            if curr_num is not None and curr_total is not None and correct_total is not None:
                expected_total = correct_total + curr_num
                if expected_total == curr_total:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = "âˆš"
                    correct_total = curr_total  # æœ¬è¡Œç´¯è®¡æ­£ç¡®ï¼Œç”¨å®ƒæ›´æ–°åŸºå‡†
                else:
                    if ws[f"E{row}"].value != "è¡¥æ–­ç‚¹":
                        ws[f"E{row}"] = f"Ã— åº”ä¸º{expected_total}"
                    correct_total = expected_total

        # æ ¡éªŒåˆ†æ•°å·®
        try:
            curr_score_num = float(str(curr_score).split('-')[0])
            prev_score_num = float(str(prev_score).split('-')[0])
        except:
            curr_score_num = prev_score_num = None

        if curr_score_num is not None and prev_score_num is not None:
            diff = prev_score_num - curr_score_num
            if diff == 1:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = "âˆš"
            else:
                if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                    ws[f"F{row}"] = f"Ã— å·®å€¼{diff}"
        else:
            if ws[f"F{row}"].value != "è¡¥æ–­ç‚¹":
                ws[f"F{row}"] = "Ã— åˆ†æ•°éæ•°å­—ï¼Œæ— æ³•æ ¡éªŒ"

    wb.save(output_path)
    return output_path




# ============================
# ä¸“ä¸šç»„ä»£ç åŒ¹é…
# ============================

tableA_fields = [
    "å­¦æ ¡åç§°", "çœä»½", "æ‹›ç”Ÿä¸“ä¸š", "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰",
    "ä¸€çº§å±‚æ¬¡", "æ‹›ç”Ÿç§‘ç±»", "æ‹›ç”Ÿæ‰¹æ¬¡", "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰"
]

rename_mapping_B = {
    "å­¦æ ¡": "å­¦æ ¡åç§°",
    "çœä»½": "çœä»½",
    "å±‚æ¬¡": "ä¸€çº§å±‚æ¬¡",
    "ç§‘ç±»": "æ‹›ç”Ÿç§‘ç±»",
    "æ‰¹æ¬¡": "æ‹›ç”Ÿæ‰¹æ¬¡",
    "æ‹›ç”Ÿç±»å‹": "æ‹›ç”Ÿç±»å‹ï¼ˆé€‰å¡«ï¼‰",
    "ä¸“ä¸š": "æ‹›ç”Ÿä¸“ä¸š",
    "å¤‡æ³¨": "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"
}


def process_data(dfA, dfB):
    dfB.rename(columns=rename_mapping_B, inplace=True)

    # æ„å»ºç»„åˆé”®ï¼ˆä¸å«å¤‡æ³¨ï¼‰ï¼šå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-æ‹›ç”Ÿç±»å‹-ä¸“ä¸š
    key_fields = [f for f in tableA_fields if f != "ä¸“ä¸šå¤‡æ³¨ï¼ˆé€‰å¡«ï¼‰"]
    dfA["ç»„åˆé”®"] = dfA[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)
    dfB["ç»„åˆé”®"] = dfB[key_fields].fillna("").astype(str).apply(
        lambda x: "|".join([str(i).strip() for i in x]), axis=1)

    # æ£€æŸ¥Aè¡¨å’ŒBè¡¨ä¸­ç»„åˆé”®çš„é‡å¤æ€§
    # ç»Ÿè®¡Aè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    a_key_counts = dfA["ç»„åˆé”®"].value_counts()
    # ç»Ÿè®¡Bè¡¨ä¸­æ¯ä¸ªç»„åˆé”®å‡ºç°çš„æ¬¡æ•°
    b_key_counts = dfB["ç»„åˆé”®"].value_counts()
    
    # æ‰¾å‡ºAè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    a_duplicate_keys = set(a_key_counts[a_key_counts > 1].index)
    # æ‰¾å‡ºBè¡¨ä¸­æœ‰é‡å¤çš„ç»„åˆé”®ï¼ˆå‡ºç°æ¬¡æ•°>1ï¼‰
    b_duplicate_keys = set(b_key_counts[b_key_counts > 1].index)

    # æ„å»ºBè¡¨å­—å…¸ï¼šç»„åˆé”® â†’ è®°å½•åˆ—è¡¨
    b_dict = dfB.groupby("ç»„åˆé”®").apply(lambda x: x.to_dict("records")).to_dict()

    def get_code(row):
        key = row["ç»„åˆé”®"]
        candidates = b_dict.get(key, [])

        # æƒ…å†µ1ï¼šæ— å€™é€‰è®°å½•
        if not candidates:
            return None

        # æ£€æŸ¥è¯¥ç»„åˆé”®åœ¨Aè¡¨æˆ–Bè¡¨ä¸­æ˜¯å¦æœ‰é‡å¤
        has_duplicate_in_a = key in a_duplicate_keys
        has_duplicate_in_b = key in b_duplicate_keys

        # å¦‚æœAè¡¨æˆ–Bè¡¨ä¸­ä»»ä½•ä¸€ä¸ªæœ‰é‡å¤ï¼Œä¸èƒ½æŒ‰è¿™å‡ ä¸ªå­—æ®µç›´æ¥åŒ¹é…ï¼Œè¿”å›None
        if has_duplicate_in_a or has_duplicate_in_b:
            return None

        # Aè¡¨å’ŒBè¡¨ä¸­éƒ½æ²¡æœ‰é‡å¤ï¼Œä¸”Bè¡¨ä¸­åªæœ‰å”¯ä¸€å€™é€‰è®°å½•ï¼Œå¯ä»¥ç›´æ¥åŒ¹é…
        if len(candidates) == 1:
            return candidates[0]["ä¸“ä¸šç»„ä»£ç "]

        # å¦‚æœBè¡¨ä¸­æœ‰å¤šä¸ªå€™é€‰è®°å½•ï¼ˆè¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‡ºç°ï¼Œå› ä¸ºBè¡¨æ²¡æœ‰é‡å¤ï¼‰ï¼Œè¿”å›None
        return None

    dfA["ä¸“ä¸šç»„ä»£ç "] = dfA.apply(get_code, axis=1)

    return dfA


 # ========== å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå– ==========

def fetch_images_static(url, output_folder):
    os.makedirs(output_folder, exist_ok=True)
    image_paths = []
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        imgs = soup.find_all("img")
        for idx, img in enumerate(imgs, 1):
            src = img.get("src")
            if not src:
                continue
            full_url = urljoin(url, src)
            # è·³è¿‡ base64 æˆ– blob ç±»å‹
            if full_url.startswith("data:") or full_url.startswith("blob:"):
                continue
            ext = os.path.splitext(urlparse(full_url).path)[1] or ".jpg"
            filename = f"img_{idx:03d}{ext}"
            path = os.path.join(output_folder, filename)
            try:
                img_resp = requests.get(full_url, timeout=10)
                if img_resp.status_code != 200:
                    continue
                content_type = img_resp.headers.get("content-type", "")
                # ä»…ä¿å­˜çœŸæ­£çš„å›¾ç‰‡ç±»å‹
                if not content_type.startswith("image/"):
                    continue
                img_data = img_resp.content
                # éªŒè¯å›¾ç‰‡æ˜¯å¦å¯è¯†åˆ«
                try:
                    Image.open(io.BytesIO(img_data))
                except Exception:
                    continue
                with open(path, "wb") as f:
                    f.write(img_data)
                image_paths.append(path)
            except Exception:
                continue
    except Exception as e:
        raise Exception(f"é™æ€æ¨¡å¼åŠ è½½å¤±è´¥: {e}")
    return image_paths


def images_to_pdf(image_paths, pdf_path):
    images = []
    for path in sorted(image_paths):
        try:
            img = Image.open(path).convert("RGB")
            images.append(img)
        except Exception:
            continue
    if images:
        images[0].save(pdf_path, save_all=True, append_images=images[1:])
        return True
    return False





# ============================
# Streamlité¡µé¢å¸ƒå±€
# ============================
# é¡µé¢æ ‡é¢˜
st.title("ğŸ“Š æ•°æ®å¤„ç†å·¥å…·")
st.markdown("---")

# åŠŸèƒ½è¯´æ˜
with st.expander("ğŸ“Œ åŠŸèƒ½è¯´æ˜", expanded=True):
    st.markdown("""
    1. ä¸Šä¼ çš„æ–‡ä»¶ä½¿ç”¨åº“ä¸­ä¸“ä¸šåˆ†ã€é™¢æ ¡åˆ†ã€æ‹›ç”Ÿè®¡åˆ’ã€ä¸€åˆ†ä¸€æ®µçš„æ¨¡æ¿ï¼Œç›´æ¥ä¸Šä¼ å³å¯ï¼Œæ— éœ€åˆ å‡
    2. å¤‡æ³¨æ£€æŸ¥ä¸­ï¼Œæ£€æŸ¥å‡ºæ¥æ‹¬å·æœ‰é—®é¢˜çš„å†…å®¹è¿˜éœ€è¦è‡ªå·±å†è¿‡ä¸€éï¼›æ•´ä¸ªæ–‡ä»¶çš„å¤‡æ³¨éœ€è¦å¤§æ¦‚çœ‹çœ‹æœ‰æ²¡æœ‰é”™åˆ«å­—
    3. æ ¡éªŒä¸€åˆ†ä¸€æ®µæ—¶ï¼Œå†…å®¹ä¸èƒ½ä¸ºæ–‡æœ¬æ ¼å¼
    4. ä½¿ç”¨ä¸“ä¸šç»„ä»£ç åŒ¹é…æ—¶ï¼Œä¸¤ä»½æ–‡ä»¶ä¸­çš„â€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹â€è¿™äº›å­—æ®µéœ€è¦ä¿æŒä¸€è‡´
    """)

# æ›´æ–°æ—¥å¿—å¯¹è¯æ¡†
with st.expander("ğŸ“¢ ç‰ˆæœ¬æ›´æ–°ï¼ˆ2025.9.26æ›´æ–°ï¼‰ï¼ˆå¿…çœ‹ï¼ï¼‰", expanded=False):
    st.markdown("""
    ### 2025.9.26æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†ä¸­æœ€é«˜åˆ†çš„æå–é€»è¾‘  
    â€¢ æ–°å¢äº†è‰ºä½“ç±»é™¢æ ¡åˆ†æå–åŠŸèƒ½ï¼Œå¯ä»¥ç›´æ¥ä¸Šä¼ è‰ºä½“ç±»ä¸“ä¸šåˆ†æ¨¡æ¿ï¼ˆå¯æŠŠç‰¹æ®Šç±»å‹<å¦‚ï¼šä¸­å¤–åˆä½œåŠå­¦>çš„å¤‡æ³¨åœ¨ä¸“ä¸šåˆ†ä¸­æ”¾åˆ°ä¸“ä¸šæ–¹å‘å†æå–ï¼‰

    ### å†å²æ›´æ–°

    #### 2025.4.14æ›´æ–°
    â€¢ æ‹›ç”Ÿä»£ç å’Œä¸“ä¸šä»£ç ä¿æŒæ–‡æœ¬æ ¼å¼  
    â€¢ å¢åŠ åŠŸèƒ½è¯´æ˜  
    â€¢ ä¼˜åŒ–å·¥å…·ç•Œé¢  

    #### 2025.4.16æ›´æ–°
    â€¢ ä¼˜åŒ–äº†é™¢æ ¡åˆ†æå–å¤„ç†é€»è¾‘  

    #### 2025.5.22æ›´æ–°
    â€¢ æ›´æ–°äº†é™¢æ ¡åˆ†æå–ä¸­å½•å–äººæ•°çš„å¤„ç†é€»è¾‘ï¼ˆå»ºè®®è¿›è¡ŒæŠ½æŸ¥ï¼‰  
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†æœ€é«˜åˆ†ã€å¹³å‡åˆ†ã€æœ€ä½åˆ†çš„æ ¡éªŒï¼Œä¼šåœ¨æœ€ååŠ ä¸€åˆ—æ ¡éªŒç»“æœ  

    #### 2025.5.23æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­å¢åŠ äº†å­¦æ ¡åç§°å’Œæ‹›ç”Ÿä¸“ä¸šçš„åŒ¹é…  

    #### 2025.5.27æ›´æ–°
    â€¢ å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ä¸­ï¼Œå¢åŠ äº†"æ‹›ç”Ÿç§‘ç±»"ã€"é¦–é€‰ç§‘ç›®"ã€"é€‰ç§‘è¦æ±‚"ï¼Œ"æ¬¡é€‰ç§‘ç›®"çš„å¤„ç†  
      - å­¦ä¸šæ¡¥æä¾›çš„"3+1+2"çœä»½çš„æ‹›ç”Ÿç§‘ç±»ä¸º"ç‰©ç†"ã€"å†å²"ï¼Œå¯ä»¥ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†çš„"ç‰©ç†ç±»"ã€"å†å²ç±»"  
      - "3+1+2"çœä»½çš„é¦–é€‰ç§‘ç›®å¯ä»¥ç›´æ¥æ ¹æ®æ‹›ç”Ÿç§‘ç±»æå–  
      - æ–°å¢äº†é€‰ç§‘è¦æ±‚ã€æ¬¡é€‰ç§‘ç›®çš„å¤„ç†ï¼Œå¯ç›´æ¥è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ï¼ˆå¤„ç†åçš„æ•°æ®åœ¨æ–‡æ¡£æœ€åå‡ åˆ—ï¼‰  

    #### 2025.5.30æ›´æ–°
    æ–°å¢"ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"  
      - å¯ç›´æ¥æ ¡éªŒåˆ†æ•°ã€ç´¯è®¡äººæ•°  
      - è‡ªåŠ¨è¡¥æ–­ç‚¹  
      - è‡ªåŠ¨å¢åŠ "æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  

    ### 2025.6.6æ›´æ–°
    "ä¸€åˆ†ä¸€æ®µæ•°æ®å¤„ç†"ä¼˜åŒ–  
      - è‡ªåŠ¨è¡¥å……"æœ€é«˜åˆ†â€”â€”æ»¡åˆ†"çš„åŒºé—´ï¼ˆä¸Šæµ·æ»¡åˆ†660ï¼Œæµ·å—æ»¡åˆ†900ï¼‰  
      - åªæœ‰ç´¯è®¡äººæ•°æ²¡æœ‰äººæ•°æ—¶ï¼Œå¯è®¡ç®—äººæ•°ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ  
      - è¡¥æ–­ç‚¹çš„åˆ†æ•°æ ‡æ³¨é¢œè‰²ï¼Œå¹¶åœ¨åˆ†æ•°å’Œäººæ•°æ ¡éªŒä¸­æ ‡æ³¨"è¡¥æ–­ç‚¹"

    ### 2025.6.12æ›´æ–°
    é™¢æ ¡åˆ†æå–é€»è¾‘æ›´æ–°  
      - æå–æœ€é«˜åˆ†æ”¹ä¸ºå–åŒä¸€ä¸ªâ€œå­¦æ ¡-çœä»½-å±‚æ¬¡-ç§‘ç±»-æ‰¹æ¬¡-ç±»å‹ï¼ˆ-ä¸“ä¸šç»„ä»£ç ï¼‰â€ä¸‹çš„æœ€é«˜åˆ†
      
    ### 2025.6.14æ›´æ–°
    ä¸“ä¸šç»„ä»£ç åŒ¹é…åŠŸèƒ½  
      - éœ€è¦ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿å’Œåº“ä¸­æ‹›ç”Ÿè®¡åˆ’å¯¼å‡ºæ¨¡æ¿
      - æŠŠåº“ä¸­å¯¼å‡ºæ‹›ç”Ÿè®¡åˆ’ç±»å‹å°½é‡è¡¥å……å®Œæ•´ï¼Œå¦åˆ™å®¹æ˜“å‡ºé”™
      - åŒ¹é…ç»“æœéœ€è¦æ£€æŸ¥
      
    ### 2025.7.7æ›´æ–°
    å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æŠ“å–åŠŸèƒ½  
      - æŠ“å–å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡
      - å¦‚æœæŠ“å–åˆ°çš„å›¾ç‰‡æ¯”è¾ƒå¤šï¼Œâ€œä¸‹è½½PDFâ€çš„å¼¹æ¡†ä¼šå‡ºç°æ¯”è¾ƒæ…¢
      - æ³¨æ„ï¼šåªèƒ½æŠ“å–é™æ€é¡µé¢çš„å›¾ç‰‡ï¼ŒåŠ¨æ€é¡µé¢å’Œæœ‰é™åˆ¶çš„ç½‘é¡µæ— æ³•æŠ“å–
    

    """)

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(
    [
        "é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰",
        "é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰",
        "å­¦ä¸šæ¡¥æ•°æ®å¤„ç†",
        "ä¸€åˆ†ä¸€æ®µæ ¡éªŒ",
        "ä¸“ä¸šç»„ä»£ç åŒ¹é…ï¼ˆå¯ä»¥ç”¨ï¼Œéœ€è¦æ£€æŸ¥ï¼ï¼‰",
        "å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–",
        "æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹"
    ]
)


# ====================== é™¢æ ¡åˆ†æå– ======================
with tab1:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆæ™®é€šç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="score_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_score_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_score_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰ ======================
with tab2:
    st.header("é™¢æ ¡åˆ†æå–ï¼ˆè‰ºä½“ç±»ï¼‰")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file_new = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="new_score_file")

    if uploaded_file_new is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file_new.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_new_score"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_new_score.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file_new.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # è°ƒç”¨æ–°æ¨¡æ¿å¤„ç†å‡½æ•°
                    if percent_complete == 100:
                        output_path = process_new_template_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="é™¢æ ¡åˆ†ï¼ˆè‰ºä½“ç±»ï¼‰æå–ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")



# ====================== å­¦ä¸šæ¡¥æ•°æ®å¤„ç† ======================
with tab3:
    st.header("å­¦ä¸šæ¡¥æ•°æ®å¤„ç†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="remarks_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_remarks"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "temp_remarks.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())


                # è¿›åº¦å›è°ƒå‡½æ•°
                def update_progress(current, total):
                    percent = int((current / total) * 100)
                    progress_bar.progress(percent)
                    status_text.text(f"å¤„ç†ä¸­... {percent}%")


                # å¤„ç†æ–‡ä»¶
                output_path = process_remarks_file(temp_file, progress_callback=update_progress)

                # å¤„ç†å®Œæˆ
                progress_bar.progress(100)
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()
                b64 = base64.b64encode(bytes_data).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="å­¦ä¸šæ¡¥æ•°æ®å¤„ç†ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸€åˆ†ä¸€æ®µæ ¡éªŒ ======================
with tab4:
    st.header("ä¸€åˆ†ä¸€æ®µæ ¡éªŒ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©Excelæ–‡ä»¶", type=["xlsx"], key="segmentation_file")

    if uploaded_file is not None:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name}")

        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("å‡†å¤‡å¤„ç†...")

        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="process_segmentation"):
            try:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
                temp_file = "ä¸€åˆ†ä¸€æ®µ.xlsx"
                with open(temp_file, "wb") as f:
                    f.write(uploaded_file.getbuffer())

                # å¤„ç†æ–‡ä»¶
                for percent_complete in range(0, 101, 10):
                    progress_bar.progress(percent_complete)
                    status_text.text(f"å¤„ç†ä¸­... {percent_complete}%")

                    # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹ï¼Œå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºæ‚¨çš„process_segmentation_fileå‡½æ•°
                    if percent_complete == 100:
                        output_path = process_segmentation_file(temp_file)

                # å¤„ç†å®Œæˆ
                status_text.text("å¤„ç†å®Œæˆï¼")
                st.balloons()

                # æä¾›ä¸‹è½½é“¾æ¥
                with open(output_path, "rb") as f:
                    bytes_data = f.read()

                b64 = base64.b64encode(bytes_data).decode()

                # ä» output_path æå–åŸæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                base_name = os.path.splitext(os.path.basename(output_path))[0]

                # æ‹¼æ¥æ–°æ–‡ä»¶å
                new_filename = f"{base_name}.xlsx"

                # æ„é€ ä¸‹è½½é“¾æ¥
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="{new_filename}">ç‚¹å‡»ä¸‹è½½å¤„ç†ç»“æœ</a>'

                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_file)
                os.remove(output_path)

            except Exception as e:
                st.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")

# ====================== ä¸“ä¸šç»„ä»£ç åŒ¹é… ======================
with tab5:
    st.header("ä¸“ä¸šç»„ä»£ç åŒ¹é…ï¼ˆéœ€è¦æ£€æŸ¥ï¼ï¼‰")

    uploaded_fileA = st.file_uploader("ä¸Šä¼ ä¸“ä¸šåˆ†å¯¼å…¥æ¨¡æ¿", type=["xls", "xlsx"], key="fileA")
    uploaded_fileB = st.file_uploader("ä¸Šä¼ æ‹›ç”Ÿè®¡åˆ’æ•°æ®å¯¼å‡ºæ–‡ä»¶", type=["xls", "xlsx"], key="fileB")

    if uploaded_fileA and uploaded_fileB:
        st.success(f"å·²é€‰æ‹©æ–‡ä»¶ï¼š{uploaded_fileA.name} å’Œ {uploaded_fileB.name}")

        progress_bar = st.progress(0)
        status_text = st.empty()
        status_text.text("ç­‰å¾…å¼€å§‹å¤„ç†...")

        if st.button("å¼€å§‹æ•°æ®å¤„ç†", key="start_match"):
            try:
                # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
                temp_fileA = "tempA.xlsx"
                temp_fileB = "tempB.xlsx"
                with open(temp_fileA, "wb") as f:
                    f.write(uploaded_fileA.getbuffer())
                with open(temp_fileB, "wb") as f:
                    f.write(uploaded_fileB.getbuffer())

                status_text.text("è¯»å–æ–‡ä»¶...")
                progress_bar.progress(10)

                dfA = pd.read_excel(temp_fileA, header=2)
                dfB = pd.read_excel(temp_fileB)

                status_text.text("å¼€å§‹å¤„ç†æ•°æ®...")
                for percent_complete in range(20, 101, 20):
                    progress_bar.progress(percent_complete)
                    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´ï¼Œå¦‚æœä¸éœ€è¦å¯ä»¥å»æ‰
                    # time.sleep(0.2)

                result_df = process_data(dfA, dfB)

                status_text.text("å¤„ç†å®Œæˆï¼å‡†å¤‡å¯¼å‡º...")
                progress_bar.progress(100)

                # å¯¼å‡ºç»“æœåˆ°å†…å­˜
                output = BytesIO()
                result_df.to_excel(output, index=False)
                output.seek(0)

                b64 = base64.b64encode(output.read()).decode()
                href = f'<a href="data:application/octet-stream;base64,{b64}" download="ä¸“ä¸šç»„ä»£ç åŒ¹é…ç»“æœ.xlsx">ç‚¹å‡»ä¸‹è½½åŒ¹é…ç»“æœ</a>'
                st.markdown(href, unsafe_allow_html=True)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(temp_fileA)
                os.remove(temp_fileB)

                status_text.text("å·²å®Œæˆï¼Œç»“æœå¯ä¸‹è½½ã€‚")
                st.balloons()

            except Exception as e:
                st.error(f"å¤„ç†é”™è¯¯ï¼š{e}")
    else:
        st.info("è¯·å…ˆä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶")

# ====================== tab5ï¼šç½‘é¡µå›¾ç‰‡æå–PDF ======================
with tab6:
    st.header("å°±ä¸šè´¨é‡æŠ¥å‘Šå›¾ç‰‡æå–")

    url = st.text_input("è¯·è¾“å…¥å°±ä¸šè´¨é‡æŠ¥å‘Šç½‘é¡µé“¾æ¥", placeholder="ä¾‹å¦‚ï¼šhttps://www.example.com/report.html")

    if st.button("å¼€å§‹æå–å›¾ç‰‡"):
        if not url:
            st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„ç½‘é¡µé“¾æ¥")
        else:
            output_folder = tempfile.mkdtemp()
            with st.spinner("æ­£åœ¨æŠ“å–å›¾ç‰‡..."):
                try:
                    image_paths = fetch_images_static(url, output_folder)
                except Exception as e:
                    st.error(f"æŠ“å–å¤±è´¥: {e}")
                    image_paths = []

            if image_paths:
                st.success(f"æˆåŠŸæå–åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

                with st.expander(f"ç‚¹å‡»æŸ¥çœ‹ {len(image_paths)} å¼ å›¾ç‰‡é¢„è§ˆ", expanded=False):
                    cols = st.columns(5)
                    for i, path in enumerate(image_paths):
                        cols[i % 5].image(path, width=120)

                pdf_path = os.path.join(output_folder, "å›¾ç‰‡åˆé›†.pdf")
                if images_to_pdf(image_paths, pdf_path):
                    with open(pdf_path, "rb") as f:
                        st.download_button("ğŸ“¥ ä¸‹è½½åˆæˆPDF", f, file_name="å°±ä¸šè´¨é‡æŠ¥å‘Š.pdf", mime="application/pdf")
                else:
                    st.warning("PDFåˆæˆå¤±è´¥")
            else:
                st.warning("æœªæŠ“å–åˆ°ä»»ä½•å›¾ç‰‡")


# ====================== tab7ï¼šæ‹›ç”Ÿè®¡åˆ’å·¥å…·======================
with tab7:  # å‡è®¾æ‚¨åœ¨åŸæœ‰åŸºç¡€ä¸Šå¢åŠ äº†ä¸€ä¸ª tab
    st.header("æ‹›ç”Ÿè®¡åˆ’æ•°æ®æ¯”å¯¹ä¸è½¬æ¢å·¥å…·")

    # è·å– HTML æ–‡ä»¶çš„è·¯å¾„
    html_file_path = resource_path("264437b0-a2dc-4d9e-acfb-1f3509057ec1.html")

    try:
        with open(html_file_path, 'r', encoding='utf-8') as f:
            html_content = f.read()

        # ä½¿ç”¨ components.html æ¸²æŸ“ï¼Œè®¾ç½®è¶³å¤Ÿçš„é«˜åº¦
        # scrolling=True å…è®¸ç»„ä»¶å†…éƒ¨æ»šåŠ¨
        components.html(html_content, height=800, scrolling=True)

    except FileNotFoundError:
        st.error("æ‰¾ä¸åˆ° HTML å·¥å…·æ–‡ä»¶ï¼Œè¯·ç¡®ä¿æ–‡ä»¶å·²ä¸Šä¼ å¹¶è·¯å¾„æ­£ç¡®ã€‚")


# é¡µè„š
st.markdown("---")
st.markdown("Â© æ•°æ®å¤„ç†", unsafe_allow_html=True)
